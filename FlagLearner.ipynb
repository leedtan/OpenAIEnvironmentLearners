{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os.path, gym\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import roboschool\n",
    "import pdb\n",
    "\n",
    "def apply_clipped_optimizer(opt_fcn,\n",
    "                            loss,\n",
    "                            clip_norm=.1,\n",
    "                            clip_single=.03,\n",
    "                            clip_global_norm=False,\n",
    "                            var_list=None):\n",
    "    if var_list is None:\n",
    "        gvs = opt_fcn.compute_gradients(loss)\n",
    "    else:\n",
    "        gvs = opt_fcn.compute_gradients(loss, var_list = var_list)\n",
    "        \n",
    "\n",
    "    if clip_global_norm:\n",
    "        gs, vs = zip(*[(g, v) for g, v in gvs if g is not None])\n",
    "        capped_gs, grad_norm_total = tf.clip_by_global_norm([g for g in gs],clip_norm)\n",
    "        capped_gvs = list(zip(capped_gs, vs))\n",
    "    else:\n",
    "        grad_norm_total = tf.sqrt(\n",
    "                tf.reduce_sum([\n",
    "                        tf.reduce_sum(tf.square(grad)) for grad, var in gvs\n",
    "                        if grad is not None\n",
    "                ]))\n",
    "        capped_gvs = [(tf.clip_by_value(grad, -1 * clip_single, clip_single), var)\n",
    "                                    for grad, var in gvs if grad is not None]\n",
    "        capped_gvs = [(tf.clip_by_norm(grad, clip_norm), var)\n",
    "                                    for grad, var in capped_gvs if grad is not None]\n",
    "\n",
    "    optimizer = opt_fcn.apply_gradients(capped_gvs)\n",
    "\n",
    "    return optimizer, grad_norm_total\n",
    "\n",
    "def MLP(x, lshapes, output_units, name_fcn):\n",
    "    h = [x]\n",
    "    h.append(tf.nn.leaky_relu(tf.layers.dense(h[-1], lshapes[0], name=name_fcn())))\n",
    "    for size in lshapes:\n",
    "        h.append(tf.nn.leaky_relu(h[-1] + tf.layers.dense(h[-1], size, name=name_fcn())))\n",
    "    output = tf.layers.dense(h[-1], output_units, name=name_fcn())\n",
    "    if output_units == 1:\n",
    "        output = tf.squeeze(output, -1)\n",
    "    return h, output\n",
    "NUM_HISTORY = 6\n",
    "INPUT_UNITS = 44 * NUM_HISTORY\n",
    "class PolicyLearner(object):\n",
    "    def __init__(self, ob_space, ac_space, take_weights_here=None, \n",
    "                 lshapes = [128]*4, config = None):\n",
    "        self.a_idx = 0\n",
    "        self.c_idx = 0\n",
    "        self.sess = tf.InteractiveSession(config=config)\n",
    "        self.obs = tf.placeholder(tf.float32, (None, None, INPUT_UNITS))\n",
    "        self.metaobs = tf.placeholder(tf.float32, (None, None, 1))\n",
    "        self.returns = tf.placeholder(tf.float32, (None, None))\n",
    "        self.mask = tf.placeholder(tf.float32, (None, None))\n",
    "        self.lr = tf.placeholder_with_default(1e-5, (None))\n",
    "\n",
    "        self.actions_input = tf.concat((self.obs, self.metaobs), axis=-1)\n",
    "        \n",
    "        self.h, pi = MLP(self.actions_input, lshapes, 17, self.a_name)\n",
    "        self.pi = tf.nn.tanh(pi/20) * 5\n",
    "\n",
    "        self.hs, self.state_value_estimate = MLP(self.actions_input, lshapes, 1, self.c_name)\n",
    "        \n",
    "        self.critic_input = tf.concat((self.actions_input, self.pi), -1)\n",
    "        \n",
    "        self.advantage = ((\n",
    "            self.state_value_estimate[:,1:] + self.returns) -\n",
    "            self.state_value_estimate[:,:-1])\n",
    "        \n",
    "        self.hae, self.advantage_estimator = MLP(self.critic_input, lshapes, 1, self.c_name)\n",
    "        \n",
    "        self.t_vars = tf.trainable_variables()\n",
    "        self.c_vars = [var for var in self.t_vars if 'c_' in var.name]\n",
    "        self.a_vars = [var for var in self.t_vars if 'a_' in var.name]\n",
    "        \n",
    "        self.critic_loss = tf.reduce_mean(tf.square(\n",
    "            self.advantage_estimator[:,:-1] - self.advantage) * self.mask)\n",
    "        self.actor_loss = -tf.reduce_mean(\n",
    "            self.advantage_estimator[:,:-1] * self.mask) + tf.reduce_mean(\n",
    "            tf.square(pi[:,:-1,:]) * tf.expand_dims(self.mask, -1))/100\n",
    "        self.total_loss = self.critic_loss + self.actor_loss/10\n",
    "        self.critic_opt = tf.train.AdamOptimizer(self.lr)\n",
    "        self.actor_opt = tf.train.AdamOptimizer(self.lr)\n",
    "        self.copt, self.c_norm = apply_clipped_optimizer(\n",
    "            self.critic_opt, self.critic_loss, var_list = self.c_vars)\n",
    "        self.aopt, self.a_norm = apply_clipped_optimizer(\n",
    "            self.actor_opt, self.actor_loss, var_list = self.a_vars)\n",
    "\n",
    "    def a_name(self):\n",
    "        self.a_idx += 1\n",
    "        return 'a_' + str(self.a_idx)\n",
    "    \n",
    "    def c_name(self):\n",
    "        self.c_idx += 1\n",
    "        return 'c_' + str(self.c_idx)\n",
    "    \n",
    "    def load_weights(self):\n",
    "        feed_dict = {}\n",
    "        for (var, w), ph in zip(self.assigns, self.weight_assignment_placeholders):\n",
    "            feed_dict[ph] = w\n",
    "        self.sess.run(self.weight_assignment_nodes, feed_dict=feed_dict)\n",
    "\n",
    "    def act(self, obs, metaobs, cx):\n",
    "        # Because we need batch dimension, data[None] changes shape from [A] to [1,A]\n",
    "        a = self.sess.run(\n",
    "            self.pi, feed_dict={self.obs:np.reshape(obs, (-1, 1, INPUT_UNITS)),\n",
    "                                self.metaobs:np.reshape(metaobs, (-1, 1, 1))\n",
    "            })\n",
    "        return a[0][0]  # return first in batch\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    inter_op_parallelism_threads=0,\n",
    "    intra_op_parallelism_threads=0,\n",
    "    device_count = { \"GPU\": 0 } )\n",
    "tf.reset_default_graph()\n",
    "\n",
    "env = gym.make(\"RoboschoolHumanoidFlagrun-v1\")\n",
    "pi = PolicyLearner(env.observation_space, env.action_space, config = config)\n",
    "sess = pi.sess\n",
    "self = pi\n",
    "sess.run(tf.global_variables_initializer())\n",
    "ah, sh = [np.zeros((0, 0, i)) for i in [17, INPUT_UNITS]]\n",
    "mh, rh = [np.zeros((0, 0)) for i in [1, 1]]\n",
    "globalframes = []\n",
    "localframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 32.995879736364486  frames 18\n",
      "[19.307692307692307]\n",
      "aloss -2.0195224 closs 22.383434\n",
      "abs action (17,) 0.4686826697561865\n",
      "[19.307692307692307, 19.5]\n",
      "aloss -1.9347465 closs 21.221773\n",
      "abs action (17,) 0.36874489033892965\n",
      "[19.307692307692307, 19.5, 19.0]\n",
      "aloss -1.8922404 closs 22.409315\n",
      "abs action (17,) 0.3915043950649687\n",
      "[19.307692307692307, 19.5, 19.0, 20.0]\n",
      "aloss -1.8276502 closs 21.136396\n",
      "abs action (17,) 0.3188281528690732\n",
      "[19.307692307692307, 19.5, 19.0, 20.0, 19.0]\n",
      "aloss -1.7287114 closs 19.90932\n",
      "abs action (17,) 0.3587886738225638\n",
      "[19.307692307692307, 19.5, 19.0, 20.0, 19.0, 18.5]\n",
      "aloss -1.6484339 closs 19.784727\n",
      "abs action (17,) 0.46917826190012923\n",
      "[19.307692307692307, 19.5, 19.0, 20.0, 19.0, 18.5, 19.5]\n",
      "aloss -1.5703189 closs 19.080061\n",
      "abs action (17,) 0.4607102719414178\n",
      "[19.307692307692307, 19.5, 19.0, 20.0, 19.0, 18.5, 19.5, 19.0]\n",
      "aloss -1.5105034 closs 19.17028\n",
      "abs action (17,) 0.41348595093902935\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-81f455982f3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0msn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetaobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0man\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0man\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-90bfebb77643>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, obs, metaobs, cx)\u001b[0m\n\u001b[1;32m    110\u001b[0m         a = self.sess.run(\n\u001b[1;32m    111\u001b[0m             self.pi, feed_dict={self.obs:np.reshape(obs, (-1, 1, INPUT_UNITS)),\n\u001b[0;32m--> 112\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetaobs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetaobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             })\n\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# return first in batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for ep in range(1000):\n",
    "    an, sn = [np.zeros((0, i)) for i in [17, INPUT_UNITS]]\n",
    "    mn, rn, maskn = [], [], []\n",
    "    frame = 0\n",
    "    score = 0\n",
    "    restart_delay = 0\n",
    "    obs = env.reset()\n",
    "    obs_mat = np.concatenate((obs[None,:],np.zeros((NUM_HISTORY-1, 44))), 0)\n",
    "    metaobs = .000\n",
    "    mn.append(metaobs)\n",
    "    sn = np.concatenate((sn, obs_mat.reshape(1, -1)), 0)\n",
    "    while 1:\n",
    "        a = pi.act(obs_mat.flatten(), metaobs, env)\n",
    "        a = a + np.random.randn(*a.shape)/2\n",
    "        an = np.concatenate((an, a[None,:]), 0)\n",
    "        \n",
    "        obs, r, done, _ = env.step(a)\n",
    "        r = r + 2\n",
    "        obs_mat = np.concatenate((obs[None,:], obs_mat[:-1,:]/1.3), 0)\n",
    "        metaobs = metaobs + .001\n",
    "        mn.append(metaobs)\n",
    "        rn.append(r)\n",
    "        sn = np.concatenate((sn, obs_mat.reshape(1, -1)), 0)\n",
    "        score += r\n",
    "        frame += 1\n",
    "        still_open = env.render(\"human\")\n",
    "        if done:\n",
    "            if ep % 1000 == 0:\n",
    "                print('score', score, ' frames', frame)\n",
    "            break\n",
    "        if still_open==False:\n",
    "            crashhere\n",
    "        if not done: continue\n",
    "        if restart_delay==0:\n",
    "            print(\"score=%0.2f in %i frames\" % (score, frame))\n",
    "            if still_open!=True:      # not True in multiplayer or non-Roboschool environment\n",
    "                break\n",
    "            restart_delay = 200*2  # 2 sec at 60 fps\n",
    "        restart_delay -= 1\n",
    "        if restart_delay==0: \n",
    "            break\n",
    "    localframes.append(frame)\n",
    "    rn = np.array(rn)\n",
    "    second_half_run = len(rn)//2\n",
    "    subtract_fail = np.power(np.arange(len(rn)), 1.2)\n",
    "#     subtract_fail = np.concatenate((\n",
    "#         np.zeros_like(rn[:-second_half_run]), \n",
    "#         2 * np.power(np.arange(second_half_run), 1.2)))\n",
    "    subtract_fail = subtract_fail / subtract_fail.sum()\n",
    "#     print('rn', rn)\n",
    "#     print('subtract_fail', subtract_fail * 50)\n",
    "    rn = 3 + rn - subtract_fail * 100\n",
    "#     print('rn', rn)\n",
    "#     for i in range(15):\n",
    "#         rn[-i] = rn[-i] - (3 * (11 - i))\n",
    "    mn = np.array(mn)\n",
    "    maskn = np.ones_like(rn)\n",
    "    if ep == 0:\n",
    "        ah, sh, mh, rh, maskh = [np.expand_dims(v, 0) for v in [an, sn, mn, rn, maskn]]\n",
    "    else:\n",
    "        def get_updated_h(h, n, third_dim):\n",
    "            hshape = h.shape[1]\n",
    "            nshape = n.shape[0]\n",
    "            if third_dim:\n",
    "                if hshape > nshape:\n",
    "                    n = np.concatenate((n, np.zeros((hshape - nshape, n.shape[-1]))), 0)\n",
    "                if nshape > hshape:\n",
    "                    h = np.concatenate((h, np.zeros((\n",
    "                        h.shape[0], nshape - hshape, h.shape[-1]))), 1)\n",
    "            else:\n",
    "                if hshape > nshape:\n",
    "                    n = np.concatenate((n, np.zeros((hshape - nshape))), 0)\n",
    "                if nshape > hshape:\n",
    "                    h = np.concatenate((h, np.zeros((h.shape[0], nshape - hshape))), 1)\n",
    "            #pdb.set_trace()\n",
    "            h = np.concatenate((h, np.expand_dims(n, 0)), 0)\n",
    "            return h\n",
    "            \n",
    "        ah, sh = [get_updated_h(h, n, 1) for  h, n in zip([ah, sh], [an, sn])]\n",
    "        \n",
    "        mh, rh, maskh = [\n",
    "            get_updated_h(h, n, 0) for h, n in zip([mh, rh, maskh], [mn, rn, maskn])]\n",
    "        \n",
    "    if ep % 2 == 0 and ep > 10:\n",
    "        ah, sh, mh, rh, maskh = [v[-100000:] for v in [ah, sh, mh, rh, maskh]]\n",
    "        globalframes.append(np.mean(localframes))\n",
    "        localframes = []\n",
    "        print(globalframes[-20:])\n",
    "        batch_size = 64\n",
    "        if ep < batch_size:\n",
    "            batch_size = ep\n",
    "        num_hist = ah.shape[0]\n",
    "        total_aloss = 0\n",
    "        total_closs = 0\n",
    "        for itr in range(5):\n",
    "            if num_hist >  batch_size:\n",
    "                forced_hist = 10\n",
    "                samples = np.concatenate((\n",
    "                    np.random.choice(\n",
    "                        num_hist - forced_hist, batch_size - forced_hist, replace=False),\n",
    "                    np.arange(\n",
    "                        num_hist - forced_hist, num_hist)))\n",
    "            else:\n",
    "                np.random.choice(num_hist, batch_size, replace=False)\n",
    "            actions, states, meta, returns, mask = [\n",
    "                v[samples] for v in [ah, sh, mh, rh, maskh]]\n",
    "            feed_dict={\n",
    "                        self.obs:states,\n",
    "                        self.metaobs:meta[:,:,None],\n",
    "                        self.returns:returns,\n",
    "                        self.mask:mask}\n",
    "            _, aloss = sess.run(\n",
    "                [self.aopt, self.actor_loss],\n",
    "                feed_dict = feed_dict\n",
    "                    )\n",
    "            feed_dict[self.pi] = actions\n",
    "            feed_dict[self.obs] = states[:,:-1,:]\n",
    "            feed_dict[self.metaobs] = meta[:,:-1,None]\n",
    "            feed_dict[self.returns] = returns[:,:-1]\n",
    "            feed_dict[self.mask] = mask[:,:-1]\n",
    "            _, closs = sess.run(\n",
    "                [self.copt, self.critic_loss],\n",
    "                    feed_dict=feed_dict)\n",
    "        print('aloss', aloss, 'closs', closs)\n",
    "        print('abs action',np.abs(ah)[-1,0,:].shape, np.abs(ah)[-1,0,:].mean())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ah[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ah[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for itr in range(ep // 10):\n",
    "    #samples = np.random.choice(num_hist, batch_size, replace=False)\n",
    "    actions, states, meta, returns, mask = [v[samples] for v in [ah, sh, mh, rh, maskh]]\n",
    "    feed_dict[self.lr] = 1e-4\n",
    "    feed_dict={\n",
    "                self.obs:states,\n",
    "                self.metaobs:meta[:,:,None],\n",
    "                self.returns:returns,\n",
    "                self.mask:mask}\n",
    "    _, aloss = sess.run(\n",
    "        [self.aopt, self.actor_loss],\n",
    "        feed_dict = feed_dict\n",
    "            )\n",
    "#     feed_dict[self.lr] = 1e-5\n",
    "    feed_dict[self.pi] = actions\n",
    "    feed_dict[self.obs] = states[:,:-1,:]\n",
    "    feed_dict[self.metaobs] = meta[:,:-1,None]\n",
    "    feed_dict[self.returns] = returns[:,:-1]\n",
    "    feed_dict[self.mask] = mask[:,:-1]\n",
    "#     _, closs = sess.run(\n",
    "#         [self.copt, self.critic_loss],\n",
    "#             feed_dict=feed_dict)\n",
    "    print(aloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.shape, states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, aloss = sess.run(\n",
    "                [self.aopt, self.actor_loss],\n",
    "                feed_dict = feed_dict\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2',[v.shape for v in sess.run([self.advantage], feed_dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(ah).mean(-1).mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for itr in range(10):\n",
    "            samples = np.random.choice(num_hist, batch_size, replace=False)\n",
    "            actions, states, meta, returns = [v[samples] for v in [ah, sh, mh, rh]]\n",
    "            feed_dict={\n",
    "                        self.obs:states,\n",
    "                        self.metaobs:meta[:,:,None],\n",
    "                        self.returns:returns}\n",
    "            _, aloss = sess.run(\n",
    "                [self.aopt, self.actor_loss],\n",
    "                feed_dict = feed_dict\n",
    "                    )\n",
    "            feed_dict[self.pi] = actions\n",
    "            feed_dict[self.obs] = states[:,:-1,:]\n",
    "            feed_dict[self.metaobs] = meta[:,:-1,None]\n",
    "            _, closs = sess.run(\n",
    "                [self.copt, self.critic_loss],\n",
    "                    feed_dict=feed_dict)\n",
    "            print('aloss', aloss)\n",
    "            print('closs', closs)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    v.shape for v in sess.run([self.state_value_estimate[:,:-1],\n",
    "                               self.state_value_estimate[:,1:], self.returns], feed_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.concat((self.actions_input, self.pi), -1), feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    v.shape for v in sess.run([self.actions_input, self.pi], feed_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    v.shape for v in sess.run([self.advantage_estimator, self.advantage], feed_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed_dict[self.pi] = actions\n",
    "_, closs = sess.run(\n",
    "    [self.copt, self.critic_loss],\n",
    "        feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.critic_input, feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.actions_input, feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v.shape for v in sess.run([self.advantage, self.advantage_estimator, self.mask], feed_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.advantage_estimator, feed_dict).shape, sess.run(self.mask, feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_mat.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_mat.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, r, d, m, s = [\n",
    "    [h[v] for h in history_sampled]\n",
    "    for v  in ['a','r', 'd', 'm', 's']]\n",
    "\n",
    "batch = {}\n",
    "vec = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = vec[0]\n",
    "longest = max([len(v) for v in vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[np.array(v).shape, np.zeros((longest - len(v), len(v[0]))).shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(history_sampled[i]['s']) for i in range(len(history_sampled))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(v).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(\n",
    "        ([np.stack(np.array(v), 0).shape, np.zeros((longest - len(v), len(v[-1]))).shape]), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch[vname] = np.stack(\n",
    "    ([np.concatenate([np.stack(np.array(v), 0), np.zeros((longest - len(v), len(v[-1])))], 1) for v in vec]), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, r, d, m, s = [\n",
    "    [h[v] for h in history_sampled]\n",
    "    for v  in ['a','r', 'd', 'm', 's']]\n",
    "\n",
    "batch = {}\n",
    "\n",
    "for vname, vec in zip(['a', 's'], [a, s]):\n",
    "    longest = max([len(v) for v in vec])\n",
    "    batch[vname] = np.stack(\n",
    "        ([np.concatenate([np.stack(np.array(v), 0), np.zeros((longest - len(v), len(v[-1])))], 0) for v in vec]), 0)\n",
    "\n",
    "\n",
    "for vname, vec in zip(['r', 'd', 'm'], [r, d, m]):\n",
    "    longest = max([len(v) for v in vec])\n",
    "    batch[vname] = np.stack(\n",
    "        ([np.concatenate([np.array(v), np.zeros((longest - len(v)))], 0) for v in vec]), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, b.shape) for i, b in batch.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch(history_sampled):\n",
    "    a, r, d, m, s = [\n",
    "        [h[v] for h in history_sampled]\n",
    "        for v  in ['a','r', 'd', 'm', 's']]\n",
    "\n",
    "    batch = {}\n",
    "\n",
    "    for vname, vec in zip(['a', 's'], [a, s]):\n",
    "        longest = max([len(v) for v in vec])\n",
    "        batch[vname] = np.stack(\n",
    "            ([np.concatenate([np.array(v), np.zeros((longest - len(v), len(v[0])))], 0) for v in vec]), 0)\n",
    "\n",
    "\n",
    "    for vname, vec in zip(['r', 'd', 'm'], [r, d, m]):\n",
    "        longest = max([len(v) for v in vec])\n",
    "        batch[vname] = np.stack(\n",
    "            ([np.concatenate([np.array(v), np.zeros((longest - len(v)))], 0) for v in vec]), 0)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_sampled = [history[s] for s in states_sampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[len(h[blah]) for h in history_sampled] for blah in ['a','r', 's', 'd', 'm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[h[blah][0].shape for h in history_sampled] for blah in ['a', 's']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, r, d, m, s = [\n",
    "    [h[v] for h in history_sampled]\n",
    "    for v  in ['a','r', 'd', 'm', 's']]\n",
    "\n",
    "batch = {}\n",
    "\n",
    "for vname, vec in zip(['a', 's'], [a, s]):\n",
    "    longest = max([len(v) for v in vec])\n",
    "    batch[vname] = np.stack(\n",
    "        ([np.concatenate([np.array(v), np.zeros((longest - len(v), len(v[0])))], 0) for v in vec]), 0)\n",
    "    \n",
    "\n",
    "for vname, vec in zip(['r', 'd', 'm'], [r, d, m]):\n",
    "    longest = max([len(v) for v in vec])\n",
    "    batch[vname] = np.stack(\n",
    "        ([np.concatenate([np.array(v), np.zeros((longest - len(v)))], 0) for v in vec]), 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[b.shape for b in batch.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(x) for x in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hist = len(history)\n",
    "states_sampled = np.random.choice(num_hist, batch_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(pi, history, n_steps = 100, batch_size = 5):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.shape, obs_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[h['r'] for h in history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
