{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os.path, gym\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import roboschool\n",
    "import pdb\n",
    "\n",
    "def apply_clipped_optimizer(opt_fcn,\n",
    "                            loss,\n",
    "                            clip_norm=.1,\n",
    "                            clip_single=.03,\n",
    "                            clip_global_norm=False,\n",
    "                            var_list=None):\n",
    "    if var_list is None:\n",
    "        gvs = opt_fcn.compute_gradients(loss)\n",
    "    else:\n",
    "        gvs = opt_fcn.compute_gradients(loss, var_list = var_list)\n",
    "        \n",
    "\n",
    "    if clip_global_norm:\n",
    "        gs, vs = zip(*[(g, v) for g, v in gvs if g is not None])\n",
    "        capped_gs, grad_norm_total = tf.clip_by_global_norm([g for g in gs],clip_norm)\n",
    "        capped_gvs = list(zip(capped_gs, vs))\n",
    "    else:\n",
    "        grad_norm_total = tf.sqrt(\n",
    "                tf.reduce_sum([\n",
    "                        tf.reduce_sum(tf.square(grad)) for grad, var in gvs\n",
    "                        if grad is not None\n",
    "                ]))\n",
    "        capped_gvs = [(tf.clip_by_value(grad, -1 * clip_single, clip_single), var)\n",
    "                                    for grad, var in gvs if grad is not None]\n",
    "        capped_gvs = [(tf.clip_by_norm(grad, clip_norm), var)\n",
    "                                    for grad, var in capped_gvs if grad is not None]\n",
    "\n",
    "    optimizer = opt_fcn.apply_gradients(capped_gvs)\n",
    "\n",
    "    return optimizer, grad_norm_total\n",
    "\n",
    "def MLP(x, lshapes, output_units, name_fcn):\n",
    "    h = [x]\n",
    "    h.append(tf.nn.leaky_relu(tf.layers.dense(h[-1], lshapes[0], name=name_fcn())))\n",
    "    for size in lshapes:\n",
    "        h.append(tf.nn.leaky_relu(h[-1] + tf.layers.dense(h[-1], size, name=name_fcn())))\n",
    "    output = tf.layers.dense(h[-1], output_units, name=name_fcn())\n",
    "    if output_units == 1:\n",
    "        output = tf.squeeze(output, -1)\n",
    "    return h, output\n",
    "NUM_HISTORY = 6\n",
    "INPUT_UNITS = 44 * NUM_HISTORY\n",
    "class PolicyLearner(object):\n",
    "    def __init__(self, ob_space, ac_space, take_weights_here=None, \n",
    "                 lshapes = [128]*4, config = None):\n",
    "        self.a_idx = 0\n",
    "        self.c_idx = 0\n",
    "        self.sess = tf.InteractiveSession(config=config)\n",
    "        self.obs = tf.placeholder(tf.float32, (None, None, INPUT_UNITS))\n",
    "        self.metaobs = tf.placeholder(tf.float32, (None, None, 1))\n",
    "        self.returns = tf.placeholder(tf.float32, (None, None))\n",
    "        self.mask = tf.placeholder(tf.float32, (None, None))\n",
    "        self.lr = tf.placeholder_with_default(1e-5, (None))\n",
    "\n",
    "        self.actions_input = tf.concat((self.obs, self.metaobs), axis=-1)\n",
    "        \n",
    "        self.h, pi = MLP(self.actions_input, lshapes, 17, self.a_name)\n",
    "        self.pi = tf.nn.tanh(pi/20) * 5\n",
    "\n",
    "        self.hs, self.state_value_estimate = MLP(self.actions_input, lshapes, 1, self.c_name)\n",
    "        \n",
    "        self.critic_input = tf.concat((self.actions_input, self.pi), -1)\n",
    "        \n",
    "        self.advantage = ((\n",
    "            self.state_value_estimate[:,1:] + self.returns) -\n",
    "            self.state_value_estimate[:,:-1])\n",
    "        \n",
    "        self.hae, self.advantage_estimator = MLP(self.critic_input, lshapes, 1, self.c_name)\n",
    "        \n",
    "        self.t_vars = tf.trainable_variables()\n",
    "        self.c_vars = [var for var in self.t_vars if 'c_' in var.name]\n",
    "        self.a_vars = [var for var in self.t_vars if 'a_' in var.name]\n",
    "        \n",
    "        self.critic_loss = tf.reduce_mean(tf.square(\n",
    "            self.advantage_estimator[:,:-1] - self.advantage) * self.mask)\n",
    "        self.actor_loss = -tf.reduce_mean(\n",
    "            self.advantage_estimator[:,:-1] * self.mask) + tf.reduce_mean(\n",
    "            tf.square(pi[:,:-1,:]) * tf.expand_dims(self.mask, -1))/100\n",
    "        self.total_loss = self.critic_loss + self.actor_loss/10\n",
    "        self.critic_opt = tf.train.AdamOptimizer(self.lr)\n",
    "        self.actor_opt = tf.train.AdamOptimizer(self.lr)\n",
    "        self.copt, self.c_norm = apply_clipped_optimizer(\n",
    "            self.critic_opt, self.critic_loss, var_list = self.c_vars)\n",
    "        self.aopt, self.a_norm = apply_clipped_optimizer(\n",
    "            self.actor_opt, self.actor_loss, var_list = self.a_vars)\n",
    "\n",
    "    def a_name(self):\n",
    "        self.a_idx += 1\n",
    "        return 'a_' + str(self.a_idx)\n",
    "    \n",
    "    def c_name(self):\n",
    "        self.c_idx += 1\n",
    "        return 'c_' + str(self.c_idx)\n",
    "    \n",
    "    def load_weights(self):\n",
    "        feed_dict = {}\n",
    "        for (var, w), ph in zip(self.assigns, self.weight_assignment_placeholders):\n",
    "            feed_dict[ph] = w\n",
    "        self.sess.run(self.weight_assignment_nodes, feed_dict=feed_dict)\n",
    "\n",
    "    def act(self, obs, metaobs, cx):\n",
    "        # Because we need batch dimension, data[None] changes shape from [A] to [1,A]\n",
    "        a = self.sess.run(\n",
    "            self.pi, feed_dict={self.obs:np.reshape(obs, (-1, 1, INPUT_UNITS)),\n",
    "                                self.metaobs:np.reshape(metaobs, (-1, 1, 1))\n",
    "            })\n",
    "        return a[0][0]  # return first in batch\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    inter_op_parallelism_threads=0,\n",
    "    intra_op_parallelism_threads=0,\n",
    "    device_count = { \"GPU\": 0 } )\n",
    "tf.reset_default_graph()\n",
    "\n",
    "env = gym.make(\"RoboschoolHumanoidFlagrun-v1\")\n",
    "pi = PolicyLearner(env.observation_space, env.action_space, config = config)\n",
    "sess = pi.sess\n",
    "self = pi\n",
    "sess.run(tf.global_variables_initializer())\n",
    "ah, sh = [np.zeros((0, 0, i)) for i in [17, INPUT_UNITS]]\n",
    "mh, rh = [np.zeros((0, 0)) for i in [1, 1]]\n",
    "globalframes = []\n",
    "localframes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 35.34306198161939  frames 19\n",
      "[18.384615384615383]\n",
      "aloss -1.4411881 closs 30.495092\n",
      "abs action (17,) 0.33372392564907705\n",
      "[18.384615384615383, 22.0]\n",
      "aloss -1.1061453 closs 24.078268\n",
      "abs action (17,) 0.46755397056561704\n",
      "[18.384615384615383, 22.0, 18.0]\n",
      "aloss -1.0396961 closs 22.92205\n",
      "abs action (17,) 0.4558505516016753\n",
      "[18.384615384615383, 22.0, 18.0, 17.5]\n",
      "aloss -1.0443251 closs 23.697693\n",
      "abs action (17,) 0.3563947519432529\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5]\n",
      "aloss -0.95643574 closs 23.379435\n",
      "abs action (17,) 0.29425181115931337\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5]\n",
      "aloss -0.78101104 closs 18.692287\n",
      "abs action (17,) 0.3748931490256366\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5]\n",
      "aloss -0.68741184 closs 17.9957\n",
      "abs action (17,) 0.3857542025161543\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0]\n",
      "aloss -0.6049819 closs 17.187897\n",
      "abs action (17,) 0.4113741155389475\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0]\n",
      "aloss -0.53674215 closs 16.353048\n",
      "abs action (17,) 0.38319579875554455\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5]\n",
      "aloss -0.47718522 closs 16.022486\n",
      "abs action (17,) 0.2715186334461596\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5]\n",
      "aloss -0.43653354 closs 15.408066\n",
      "abs action (17,) 0.4983006749763608\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0]\n",
      "aloss -0.3803323 closs 15.0745535\n",
      "abs action (17,) 0.38201778214357723\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5]\n",
      "aloss -0.33127582 closs 14.767714\n",
      "abs action (17,) 0.39638959754834463\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0]\n",
      "aloss -0.2625936 closs 14.316371\n",
      "abs action (17,) 0.3167589703926928\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0]\n",
      "aloss -0.22251646 closs 13.848502\n",
      "abs action (17,) 0.3359833289306765\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0]\n",
      "aloss -0.17635651 closs 13.389653\n",
      "abs action (17,) 0.31008533951274103\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0]\n",
      "aloss -0.13325381 closs 13.14497\n",
      "abs action (17,) 0.3233312414301162\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5]\n",
      "aloss -0.09339746 closs 12.885108\n",
      "abs action (17,) 0.5303364269152427\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5]\n",
      "aloss -0.047806818 closs 12.637487\n",
      "abs action (17,) 0.4900695996852305\n",
      "[18.384615384615383, 22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5]\n",
      "aloss -0.010202963 closs 12.303831\n",
      "abs action (17,) 0.3795570043514175\n",
      "[22.0, 18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5]\n",
      "aloss 0.036472302 closs 11.937507\n",
      "abs action (17,) 0.3450326051550122\n",
      "[18.0, 17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5]\n",
      "aloss 0.07577774 closs 11.649747\n",
      "abs action (17,) 0.42267336647349235\n",
      "[17.5, 17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5]\n",
      "aloss 0.11231905 closs 11.349775\n",
      "abs action (17,) 0.2478865456330716\n",
      "[17.5, 24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5]\n",
      "aloss 0.14145465 closs 10.900672\n",
      "abs action (17,) 0.5011784421534619\n",
      "[24.5, 19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5]\n",
      "aloss 0.16479917 closs 10.666241\n",
      "abs action (17,) 0.31300623197774025\n",
      "[19.5, 18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5]\n",
      "aloss 0.20111902 closs 10.538307\n",
      "abs action (17,) 0.35788502620964496\n",
      "[18.0, 19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5]\n",
      "aloss 0.22788522 closs 10.214974\n",
      "abs action (17,) 0.5155592838218342\n",
      "[19.0, 18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0]\n",
      "aloss 0.25852764 closs 9.981318\n",
      "abs action (17,) 0.30591404112538795\n",
      "[18.5, 21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0]\n",
      "aloss 0.28329232 closs 9.710526\n",
      "abs action (17,) 0.31216919449100017\n",
      "[21.5, 17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0]\n",
      "aloss 0.31890357 closs 9.380979\n",
      "abs action (17,) 0.40820221203367413\n",
      "[17.0, 17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5]\n",
      "aloss 0.37630033 closs 9.231028\n",
      "abs action (17,) 0.42227209737368887\n",
      "[17.5, 18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0]\n",
      "aloss 0.3808953 closs 8.751673\n",
      "abs action (17,) 0.47194631920332064\n",
      "[18.0, 18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0]\n",
      "aloss 0.3999907 closs 8.637889\n",
      "abs action (17,) 0.35939087383869317\n",
      "[18.0, 17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5]\n",
      "aloss 0.436177 closs 8.490119\n",
      "abs action (17,) 0.4749112681761911\n",
      "[17.0, 17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5]\n",
      "aloss 0.4438207 closs 8.057502\n",
      "abs action (17,) 0.42653838619577905\n",
      "[17.0, 17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0]\n",
      "aloss 0.48545408 closs 7.818489\n",
      "abs action (17,) 0.5749313488203119\n",
      "[17.5, 16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5]\n",
      "aloss 0.47495937 closs 7.533516\n",
      "abs action (17,) 0.5617458461352841\n",
      "[16.5, 17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0]\n",
      "aloss 0.53520817 closs 7.1242\n",
      "abs action (17,) 0.3123024202166121\n",
      "[17.5, 16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0]\n",
      "aloss 0.54915524 closs 7.0072455\n",
      "abs action (17,) 0.3198523771794407\n",
      "[16.5, 16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0]\n",
      "aloss 0.52899444 closs 6.882541\n",
      "abs action (17,) 0.5434550182409011\n",
      "[16.5, 17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5]\n",
      "aloss 0.54545814 closs 6.5443997\n",
      "abs action (17,) 0.43257492468871683\n",
      "[17.5, 18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0]\n",
      "aloss 0.5881287 closs 6.2851524\n",
      "abs action (17,) 0.3506644469166978\n",
      "[18.5, 17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5]\n",
      "aloss 0.6200386 closs 6.1421924\n",
      "abs action (17,) 0.4209129974764548\n",
      "[17.5, 15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0]\n",
      "aloss 0.5493324 closs 5.9590554\n",
      "abs action (17,) 0.3500778902394072\n",
      "[15.5, 17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0]\n",
      "aloss 0.6391964 closs 5.5562544\n",
      "abs action (17,) 0.43565189529757786\n",
      "[17.5, 16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0]\n",
      "aloss 0.62451816 closs 5.321955\n",
      "abs action (17,) 0.35925035515391995\n",
      "[16.0, 18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0]\n",
      "aloss 0.69088644 closs 5.4563346\n",
      "abs action (17,) 0.43668155998733943\n",
      "[18.0, 15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aloss 0.7171728 closs 5.3726153\n",
      "abs action (17,) 0.41602478061391024\n",
      "[15.0, 16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5]\n",
      "aloss 0.7152106 closs 5.197206\n",
      "abs action (17,) 0.4636597413486032\n",
      "[16.5, 17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5]\n",
      "aloss 0.71914685 closs 4.7113137\n",
      "abs action (17,) 0.439145444530118\n",
      "[17.0, 16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0]\n",
      "aloss 0.7695294 closs 5.094054\n",
      "abs action (17,) 0.5115134575922626\n",
      "[16.0, 16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0]\n",
      "aloss 0.750018 closs 4.921681\n",
      "abs action (17,) 0.42120368972083877\n",
      "[16.5, 17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0]\n",
      "aloss 0.8229827 closs 4.990606\n",
      "abs action (17,) 0.47939106554580635\n",
      "[17.5, 17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5]\n",
      "aloss 0.77951986 closs 4.727688\n",
      "abs action (17,) 0.35752939696141134\n",
      "[17.0, 17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5, 17.5]\n",
      "aloss 0.8248485 closs 4.3368745\n",
      "abs action (17,) 0.32912327014832304\n",
      "[17.5, 17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5, 17.5, 17.0]\n",
      "aloss 0.81517524 closs 4.4034677\n",
      "abs action (17,) 0.40846052897214685\n",
      "[17.0, 17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5, 17.5, 17.0, 16.0]\n",
      "aloss 0.708944 closs 4.4453135\n",
      "abs action (17,) 0.4471068732205712\n",
      "[17.0, 17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5, 17.5, 17.0, 16.0, 19.0]\n",
      "aloss 0.8359415 closs 4.1011615\n",
      "abs action (17,) 0.401349128506192\n",
      "[17.0, 16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5, 17.5, 17.0, 16.0, 19.0, 17.5]\n",
      "aloss 0.9024921 closs 4.535285\n",
      "abs action (17,) 0.3448453326883851\n",
      "[16.5, 16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5, 17.5, 17.0, 16.0, 19.0, 17.5, 16.5]\n",
      "aloss 0.9270772 closs 4.2886767\n",
      "abs action (17,) 0.5261386207725146\n",
      "[16.0, 15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5, 17.5, 17.0, 16.0, 19.0, 17.5, 16.5, 16.5]\n",
      "aloss 0.8845464 closs 4.2792125\n",
      "abs action (17,) 0.3865248200160069\n",
      "[15.5, 16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5, 17.5, 17.0, 16.0, 19.0, 17.5, 16.5, 16.5, 16.5]\n",
      "aloss 0.9340652 closs 4.2766795\n",
      "abs action (17,) 0.38509603699147194\n",
      "[16.0, 16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5, 17.5, 17.0, 16.0, 19.0, 17.5, 16.5, 16.5, 16.5, 15.0]\n",
      "aloss 0.8813764 closs 4.3644114\n",
      "abs action (17,) 0.40794789068602433\n",
      "[16.0, 17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5, 17.5, 17.0, 16.0, 19.0, 17.5, 16.5, 16.5, 16.5, 15.0, 17.0]\n",
      "aloss 0.92417794 closs 4.3440347\n",
      "abs action (17,) 0.3394991491045385\n",
      "[17.0, 17.0, 14.5, 16.5, 17.5, 22.0, 17.0, 17.0, 16.5, 17.5, 17.0, 16.0, 19.0, 17.5, 16.5, 16.5, 16.5, 15.0, 17.0, 17.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ep in range(1000):\n",
    "    an, sn = [np.zeros((0, i)) for i in [17, INPUT_UNITS]]\n",
    "    mn, rn, maskn = [], [], []\n",
    "    frame = 0\n",
    "    score = 0\n",
    "    restart_delay = 0\n",
    "    obs = env.reset()\n",
    "    obs_mat = np.concatenate((obs[None,:],np.zeros((NUM_HISTORY-1, 44))), 0)\n",
    "    metaobs = .000\n",
    "    mn.append(metaobs)\n",
    "    sn = np.concatenate((sn, obs_mat.reshape(1, -1)), 0)\n",
    "    while 1:\n",
    "        a = pi.act(obs_mat.flatten(), metaobs, env)\n",
    "        a = a + np.random.randn(*a.shape)/2\n",
    "        an = np.concatenate((an, a[None,:]), 0)\n",
    "        \n",
    "        obs, r, done, _ = env.step(a)\n",
    "        r = r + 2\n",
    "        obs_mat = np.concatenate((obs[None,:], obs_mat[:-1,:]/1.3), 0)\n",
    "        metaobs = metaobs + .001\n",
    "        mn.append(metaobs)\n",
    "        rn.append(r)\n",
    "        sn = np.concatenate((sn, obs_mat.reshape(1, -1)), 0)\n",
    "        score += r\n",
    "        frame += 1\n",
    "        still_open = env.render(\"human\")\n",
    "        if done:\n",
    "            if ep % 1000 == 0:\n",
    "                print('score', score, ' frames', frame)\n",
    "            break\n",
    "        if still_open==False:\n",
    "            crashhere\n",
    "        if not done: continue\n",
    "        if restart_delay==0:\n",
    "            print(\"score=%0.2f in %i frames\" % (score, frame))\n",
    "            if still_open!=True:      # not True in multiplayer or non-Roboschool environment\n",
    "                break\n",
    "            restart_delay = 200*2  # 2 sec at 60 fps\n",
    "        restart_delay -= 1\n",
    "        if restart_delay==0: \n",
    "            break\n",
    "    localframes.append(frame)\n",
    "    rn = np.array(rn)\n",
    "    second_half_run = len(rn)//2\n",
    "    subtract_fail = np.power(np.arange(len(rn)), 1.2)\n",
    "#     subtract_fail = np.concatenate((\n",
    "#         np.zeros_like(rn[:-second_half_run]), \n",
    "#         2 * np.power(np.arange(second_half_run), 1.2)))\n",
    "    subtract_fail = subtract_fail / subtract_fail.sum()\n",
    "#     print('rn', rn)\n",
    "#     print('subtract_fail', subtract_fail * 50)\n",
    "    rn = 3 + rn - subtract_fail * 100\n",
    "#     print('rn', rn)\n",
    "#     for i in range(15):\n",
    "#         rn[-i] = rn[-i] - (3 * (11 - i))\n",
    "    mn = np.array(mn)\n",
    "    maskn = np.ones_like(rn)\n",
    "    if ep == 0:\n",
    "        ah, sh, mh, rh, maskh = [np.expand_dims(v, 0) for v in [an, sn, mn, rn, maskn]]\n",
    "    else:\n",
    "        def get_updated_h(h, n, third_dim):\n",
    "            hshape = h.shape[1]\n",
    "            nshape = n.shape[0]\n",
    "            if third_dim:\n",
    "                if hshape > nshape:\n",
    "                    n = np.concatenate((n, np.zeros((hshape - nshape, n.shape[-1]))), 0)\n",
    "                if nshape > hshape:\n",
    "                    h = np.concatenate((h, np.zeros((\n",
    "                        h.shape[0], nshape - hshape, h.shape[-1]))), 1)\n",
    "            else:\n",
    "                if hshape > nshape:\n",
    "                    n = np.concatenate((n, np.zeros((hshape - nshape))), 0)\n",
    "                if nshape > hshape:\n",
    "                    h = np.concatenate((h, np.zeros((h.shape[0], nshape - hshape))), 1)\n",
    "            #pdb.set_trace()\n",
    "            h = np.concatenate((h, np.expand_dims(n, 0)), 0)\n",
    "            return h\n",
    "            \n",
    "        ah, sh = [get_updated_h(h, n, 1) for  h, n in zip([ah, sh], [an, sn])]\n",
    "        \n",
    "        mh, rh, maskh = [\n",
    "            get_updated_h(h, n, 0) for h, n in zip([mh, rh, maskh], [mn, rn, maskn])]\n",
    "        \n",
    "    if ep % 2 == 0 and ep > 10:\n",
    "        ah, sh, mh, rh, maskh = [v[-100000:] for v in [ah, sh, mh, rh, maskh]]\n",
    "        globalframes.append(np.mean(localframes))\n",
    "        localframes = []\n",
    "        print(globalframes[-20:])\n",
    "        batch_size = 64\n",
    "        if ep < batch_size:\n",
    "            batch_size = ep\n",
    "        num_hist = ah.shape[0]\n",
    "        total_aloss = 0\n",
    "        total_closs = 0\n",
    "        for itr in range(5):\n",
    "            if num_hist >  batch_size:\n",
    "                forced_hist = 10\n",
    "                samples = np.concatenate((\n",
    "                    np.random.choice(\n",
    "                        num_hist - forced_hist, batch_size - forced_hist, replace=False),\n",
    "                    np.arange(\n",
    "                        num_hist - forced_hist, num_hist)))\n",
    "            else:\n",
    "                np.random.choice(num_hist, batch_size, replace=False)\n",
    "            actions, states, meta, returns, mask = [\n",
    "                v[samples] for v in [ah, sh, mh, rh, maskh]]\n",
    "            feed_dict={\n",
    "                        self.obs:states,\n",
    "                        self.metaobs:meta[:,:,None],\n",
    "                        self.returns:returns,\n",
    "                        self.mask:mask}\n",
    "            _, aloss = sess.run(\n",
    "                [self.aopt, self.actor_loss],\n",
    "                feed_dict = feed_dict\n",
    "                    )\n",
    "            feed_dict[self.pi] = actions\n",
    "            feed_dict[self.obs] = states[:,:-1,:]\n",
    "            feed_dict[self.metaobs] = meta[:,:-1,None]\n",
    "            feed_dict[self.returns] = returns[:,:-1]\n",
    "            feed_dict[self.mask] = mask[:,:-1]\n",
    "            _, closs = sess.run(\n",
    "                [self.copt, self.critic_loss],\n",
    "                    feed_dict=feed_dict)\n",
    "        print('aloss', aloss, 'closs', closs)\n",
    "        print('abs action',np.abs(ah)[-1,0,:].shape, np.abs(ah)[-1,0,:].mean())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rh[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ah[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ah[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for itr in range(ep // 10):\n",
    "    #samples = np.random.choice(num_hist, batch_size, replace=False)\n",
    "    actions, states, meta, returns, mask = [v[samples] for v in [ah, sh, mh, rh, maskh]]\n",
    "    feed_dict[self.lr] = 1e-4\n",
    "    feed_dict={\n",
    "                self.obs:states,\n",
    "                self.metaobs:meta[:,:,None],\n",
    "                self.returns:returns,\n",
    "                self.mask:mask}\n",
    "    _, aloss = sess.run(\n",
    "        [self.aopt, self.actor_loss],\n",
    "        feed_dict = feed_dict\n",
    "            )\n",
    "#     feed_dict[self.lr] = 1e-5\n",
    "    feed_dict[self.pi] = actions\n",
    "    feed_dict[self.obs] = states[:,:-1,:]\n",
    "    feed_dict[self.metaobs] = meta[:,:-1,None]\n",
    "    feed_dict[self.returns] = returns[:,:-1]\n",
    "    feed_dict[self.mask] = mask[:,:-1]\n",
    "#     _, closs = sess.run(\n",
    "#         [self.copt, self.critic_loss],\n",
    "#             feed_dict=feed_dict)\n",
    "    print(aloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.shape, states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, aloss = sess.run(\n",
    "                [self.aopt, self.actor_loss],\n",
    "                feed_dict = feed_dict\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('2',[v.shape for v in sess.run([self.advantage], feed_dict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(ah).mean(-1).mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for itr in range(10):\n",
    "            samples = np.random.choice(num_hist, batch_size, replace=False)\n",
    "            actions, states, meta, returns = [v[samples] for v in [ah, sh, mh, rh]]\n",
    "            feed_dict={\n",
    "                        self.obs:states,\n",
    "                        self.metaobs:meta[:,:,None],\n",
    "                        self.returns:returns}\n",
    "            _, aloss = sess.run(\n",
    "                [self.aopt, self.actor_loss],\n",
    "                feed_dict = feed_dict\n",
    "                    )\n",
    "            feed_dict[self.pi] = actions\n",
    "            feed_dict[self.obs] = states[:,:-1,:]\n",
    "            feed_dict[self.metaobs] = meta[:,:-1,None]\n",
    "            _, closs = sess.run(\n",
    "                [self.copt, self.critic_loss],\n",
    "                    feed_dict=feed_dict)\n",
    "            print('aloss', aloss)\n",
    "            print('closs', closs)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    v.shape for v in sess.run([self.state_value_estimate[:,:-1],\n",
    "                               self.state_value_estimate[:,1:], self.returns], feed_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.concat((self.actions_input, self.pi), -1), feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    v.shape for v in sess.run([self.actions_input, self.pi], feed_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    v.shape for v in sess.run([self.advantage_estimator, self.advantage], feed_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feed_dict[self.pi] = actions\n",
    "_, closs = sess.run(\n",
    "    [self.copt, self.critic_loss],\n",
    "        feed_dict=feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.critic_input, feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.actions_input, feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[v.shape for v in sess.run([self.advantage, self.advantage_estimator, self.mask], feed_dict)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.advantage_estimator, feed_dict).shape, sess.run(self.mask, feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(rn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_mat.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_mat.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, r, d, m, s = [\n",
    "    [h[v] for h in history_sampled]\n",
    "    for v  in ['a','r', 'd', 'm', 's']]\n",
    "\n",
    "batch = {}\n",
    "vec = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = vec[0]\n",
    "longest = max([len(v) for v in vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "[np.array(v).shape, np.zeros((longest - len(v), len(v[0]))).shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(history_sampled[i]['s']) for i in range(len(history_sampled))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.array(v).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack(\n",
    "        ([np.stack(np.array(v), 0).shape, np.zeros((longest - len(v), len(v[-1]))).shape]), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch[vname] = np.stack(\n",
    "    ([np.concatenate([np.stack(np.array(v), 0), np.zeros((longest - len(v), len(v[-1])))], 1) for v in vec]), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, r, d, m, s = [\n",
    "    [h[v] for h in history_sampled]\n",
    "    for v  in ['a','r', 'd', 'm', 's']]\n",
    "\n",
    "batch = {}\n",
    "\n",
    "for vname, vec in zip(['a', 's'], [a, s]):\n",
    "    longest = max([len(v) for v in vec])\n",
    "    batch[vname] = np.stack(\n",
    "        ([np.concatenate([np.stack(np.array(v), 0), np.zeros((longest - len(v), len(v[-1])))], 0) for v in vec]), 0)\n",
    "\n",
    "\n",
    "for vname, vec in zip(['r', 'd', 'm'], [r, d, m]):\n",
    "    longest = max([len(v) for v in vec])\n",
    "    batch[vname] = np.stack(\n",
    "        ([np.concatenate([np.array(v), np.zeros((longest - len(v)))], 0) for v in vec]), 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(i, b.shape) for i, b in batch.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_batch(history_sampled):\n",
    "    a, r, d, m, s = [\n",
    "        [h[v] for h in history_sampled]\n",
    "        for v  in ['a','r', 'd', 'm', 's']]\n",
    "\n",
    "    batch = {}\n",
    "\n",
    "    for vname, vec in zip(['a', 's'], [a, s]):\n",
    "        longest = max([len(v) for v in vec])\n",
    "        batch[vname] = np.stack(\n",
    "            ([np.concatenate([np.array(v), np.zeros((longest - len(v), len(v[0])))], 0) for v in vec]), 0)\n",
    "\n",
    "\n",
    "    for vname, vec in zip(['r', 'd', 'm'], [r, d, m]):\n",
    "        longest = max([len(v) for v in vec])\n",
    "        batch[vname] = np.stack(\n",
    "            ([np.concatenate([np.array(v), np.zeros((longest - len(v)))], 0) for v in vec]), 0)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_sampled = [history[s] for s in states_sampled]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[len(h[blah]) for h in history_sampled] for blah in ['a','r', 's', 'd', 'm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[h[blah][0].shape for h in history_sampled] for blah in ['a', 's']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, r, d, m, s = [\n",
    "    [h[v] for h in history_sampled]\n",
    "    for v  in ['a','r', 'd', 'm', 's']]\n",
    "\n",
    "batch = {}\n",
    "\n",
    "for vname, vec in zip(['a', 's'], [a, s]):\n",
    "    longest = max([len(v) for v in vec])\n",
    "    batch[vname] = np.stack(\n",
    "        ([np.concatenate([np.array(v), np.zeros((longest - len(v), len(v[0])))], 0) for v in vec]), 0)\n",
    "    \n",
    "\n",
    "for vname, vec in zip(['r', 'd', 'm'], [r, d, m]):\n",
    "    longest = max([len(v) for v in vec])\n",
    "    batch[vname] = np.stack(\n",
    "        ([np.concatenate([np.array(v), np.zeros((longest - len(v)))], 0) for v in vec]), 0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[b.shape for b in batch.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(x) for x in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hist = len(history)\n",
    "states_sampled = np.random.choice(num_hist, batch_size, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(pi, history, n_steps = 100, batch_size = 5):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.shape, obs_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[h['r'] for h in history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
