{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path, gym\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import roboschool\n",
    "import pdb\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "GAMMA = .95\n",
    "from functools import partial\n",
    "NUM_HISTORY = 6\n",
    "TESTING_GRAD_NORMS = 1\n",
    "env = gym.make(\"RoboschoolInvertedPendulum-v1\")\n",
    "N_OBS, N_ACT = [v.shape[0] for v in [env.observation_space, env.action_space]]\n",
    "\n",
    "N_STATE = (N_OBS + N_ACT) * 2\n",
    "INPUT_UNITS = N_STATE * NUM_HISTORY\n",
    "ADV_ENABLED = True\n",
    "\n",
    "\n",
    "def apply_clipped_optimizer(opt_fcn,\n",
    "                            loss,\n",
    "                            clip_norm=.1,\n",
    "                            clip_single=.03,\n",
    "                            clip_global_norm=False,\n",
    "                            var_list=None):\n",
    "    if var_list is None:\n",
    "        gvs = opt_fcn.compute_gradients(loss)\n",
    "    else:\n",
    "        gvs = opt_fcn.compute_gradients(loss, var_list = var_list)\n",
    "        \n",
    "\n",
    "    if clip_global_norm:\n",
    "        gs, vs = zip(*[(g, v) for g, v in gvs if g is not None])\n",
    "        capped_gs, grad_norm_total = tf.clip_by_global_norm([g for g in gs],clip_norm)\n",
    "        capped_gvs = list(zip(capped_gs, vs))\n",
    "    else:\n",
    "        grad_norm_total = tf.sqrt(\n",
    "                tf.reduce_sum([\n",
    "                        tf.reduce_sum(tf.square(grad)) for grad, var in gvs\n",
    "                        if grad is not None\n",
    "                ]))\n",
    "        capped_gvs = [(tf.clip_by_value(grad, -1 * clip_single, clip_single), var)\n",
    "                                    for grad, var in gvs if grad is not None]\n",
    "        capped_gvs = [(tf.clip_by_norm(grad, clip_norm), var)\n",
    "                                    for grad, var in capped_gvs if grad is not None]\n",
    "\n",
    "    optimizer = opt_fcn.apply_gradients(capped_gvs)\n",
    "\n",
    "    return optimizer, grad_norm_total\n",
    "\n",
    "def MLP(x, lshapes, output_units, name_fcn, is_train):\n",
    "    h = [x]\n",
    "    h.append(tf.nn.leaky_relu(tf.layers.dense(h[-1], lshapes[0], name=name_fcn())))\n",
    "    init = 0\n",
    "    for size in lshapes:\n",
    "        if not init:\n",
    "            init = 1\n",
    "            h2 = h[-1]\n",
    "        h.append(tf.nn.leaky_relu(h[-1] + tf.layers.dense(\n",
    "            h2, size, name=name_fcn(),\n",
    "            kernel_initializer = tf.keras.initializers.Orthogonal(gain=0.01))\n",
    "        ))\n",
    "        #h[-1] = tf.layers.batch_normalization(h[-1], momentum = .9, training = is_train)\n",
    "        h2 = tf.concat((h[-1], x), -1)\n",
    "    hout = tf.concat((h[len(h)//2:]), -1)\n",
    "    output = tf.layers.dense(\n",
    "        hout, output_units, name=name_fcn(), \n",
    "        kernel_initializer = tf.keras.initializers.Orthogonal(gain=0.01),\n",
    "        bias_initializer = tf.keras.initializers.zeros())\n",
    "    #output = tf.layers.batch_normalization(output, momentum = .9, training = is_train)\n",
    "    if output_units == 1:\n",
    "        output = tf.squeeze(output, -1)\n",
    "    return h, output\n",
    "class PolicyLearner(object):\n",
    "    def __init__(self, ob_space, ac_space, take_weights_here=None, \n",
    "                 lshapes = [128] * 16, config = None, lshapes_small = [64] * 16):\n",
    "        self.a_idx = 0\n",
    "        self.c_idx = 0\n",
    "        self.v_idx = 0\n",
    "        self.sess = tf.InteractiveSession(config=config)\n",
    "        self.obs = tf.placeholder(tf.float32, (None, None, INPUT_UNITS))\n",
    "        self.metaobs = tf.placeholder(tf.float32, (None, None, 1))\n",
    "        self.returns = tf.placeholder(tf.float32, (None, None))\n",
    "        self.returnsdecayed = tf.placeholder(tf.float32, (None, None))\n",
    "        self.mask = tf.placeholder(tf.float32, (None, None))\n",
    "        self.lr = tf.placeholder_with_default(1e-3, (None))\n",
    "\n",
    "        self.is_train = tf.placeholder_with_default(True, (None))\n",
    "\n",
    "        \n",
    "        self.actions_input = tf.concat((self.obs, self.metaobs), axis=-1)\n",
    "        self.actions_input = tf.nn.tanh(self.actions_input*100) / 10 + tf.nn.tanh(\n",
    "            self.actions_input) + self.actions_input * .1\n",
    "        self.h, self.pi = MLP(\n",
    "            self.actions_input, lshapes, N_ACT, self.a_name, self.is_train)\n",
    "        self.pi = tf.nn.tanh(\n",
    "            self.pi)/5 + tf.nn.tanh(self.pi/5)/2 + tf.nn.tanh(\n",
    "            self.pi/100) + self.pi * 1e-3\n",
    "        if len(self.pi.shape) == 2:\n",
    "            self.pi = tf.expand_dims(self.pi, -1)\n",
    "        self.hs, self.state_value_estimate = MLP(\n",
    "            self.actions_input, lshapes_small, 1, self.v_name, self.is_train)\n",
    "        self.critic_input = tf.concat((self.actions_input, self.pi), -1)\n",
    "        \n",
    "        self.advantage = ((\n",
    "            self.state_value_estimate[:,1:] * GAMMA + self.returns) -\n",
    "            self.state_value_estimate[:,:-1])\n",
    "        \n",
    "        self.hae, self.advantage_estimator = MLP(\n",
    "            self.critic_input, lshapes_small, 1, self.c_name, self.is_train)\n",
    "        \n",
    "        self.t_vars = tf.trainable_variables()\n",
    "        self.c_vars = [var for var in self.t_vars if 'c_' in var.name]\n",
    "        self.a_vars = [var for var in self.t_vars if 'a_' in var.name]\n",
    "        self.v_vars = [var for var in self.t_vars if 'v_' in var.name]\n",
    "        \n",
    "        self.creg, self.areg, self.vreg = [\n",
    "            tf.reduce_mean([tf.reduce_mean(tf.square(v)) for v in optvars]) * 1e-1\n",
    "            for optvars in [self.c_vars, self.a_vars, self.v_vars]]\n",
    "#         self.diff_actions = self.pi[:,1:,:] - self.pi[:,:-1,:]\n",
    "        self.maskexpanded = tf.expand_dims(self.mask, -1)\n",
    "        self.actionmean = tf.reduce_sum(\n",
    "            self.pi[:,:-1,:] * self.maskexpanded, 1) / tf.reduce_sum(\n",
    "            self.maskexpanded, 1)\n",
    "        self.actdiffsquared = tf.square(\n",
    "            self.pi[:,:-1,:] - tf.expand_dims(self.actionmean, 1))\n",
    "        self.actvar = tf.reduce_sum(\n",
    "            self.actdiffsquared * self.maskexpanded, 1)/ tf.reduce_sum(\n",
    "            self.maskexpanded, 1)\n",
    "        self.actstd = tf.sqrt(self.actvar)\n",
    "        self.actstdpenalty = tf.reduce_mean(tf.square(self.actstd - 1)) * 1\n",
    "        \n",
    "        self.v_loss_raw = tf.reduce_mean(tf.square(\n",
    "            self.returnsdecayed - self.state_value_estimate[:,1:]) * self.mask)\n",
    "        self.v_loss =  self.v_loss_raw + self.vreg\n",
    "        self.c_loss_raw = tf.reduce_mean(tf.square(\n",
    "            self.advantage_estimator[:,:-1] - self.advantage) * self.mask)\n",
    "        self.c_loss =  self.c_loss_raw + self.creg\n",
    "        \n",
    "        self.aregmagnitude = tf.reduce_mean(\n",
    "            tf.square(tf.reduce_mean(\n",
    "            tf.abs(self.pi[:,:-1,:]) * self.maskexpanded, [1, 2]))/tf.reduce_mean(\n",
    "                self.maskexpanded, 1)) * .1 + tf.reduce_mean(\n",
    "            tf.square(tf.square(self.pi[:,:-1,:] * self.maskexpanded)))/1000 + tf.reduce_mean(\n",
    "            tf.square(self.pi[:,:-1,:] * self.maskexpanded)) * 3\n",
    "        self.aregmean = tf.square(tf.reduce_mean(self.pi[:,:-1,:] * self.maskexpanded))\n",
    "        self.aregtotal = self.aregmagnitude  + self.areg + self.actstdpenalty + self.aregmean\n",
    "        self.a_loss_raw = -tf.reduce_mean(\n",
    "            self.advantage_estimator[:,:-1] * self.mask)\n",
    "        self.a_loss = self.a_loss_raw + self.aregtotal\n",
    "        \n",
    "        self.grad_norm_a = tf.reduce_mean(tf.square(tf.gradients(\n",
    "            self.pi, self.actions_input)[0])) * .001\n",
    "        self.grad_norm_v = tf.reduce_mean(tf.square(tf.gradients(\n",
    "            self.state_value_estimate[:,1:], self.actions_input)[0])) * .01\n",
    "        self.grad_norm_c = tf.reduce_mean(tf.square(tf.gradients(\n",
    "            self.advantage_estimator[:,:-1], self.critic_input)[0])) * .01\n",
    "        \n",
    "        self.a_loss_minimize = self.a_loss + self.grad_norm_a\n",
    "        self.c_loss_minimize = self.c_loss + self.grad_norm_c\n",
    "        self.v_loss_minimize = self.v_loss + self.grad_norm_v\n",
    "        \n",
    "        self.v_obs_grad = tf.gradients(self.v_loss, self.obs)\n",
    "        self.c_obs_grad = tf.gradients(self.c_loss, self.obs)\n",
    "        self.c_pi_grad = tf.gradients(self.c_loss, self.pi)\n",
    "        self.a_obs_grad = tf.gradients(self.a_loss, self.obs)\n",
    "        \n",
    "        self.total_loss = self.c_loss + self.a_loss/100\n",
    "        self.critic_opt = tf.train.AdamOptimizer(self.lr, beta1= .8)\n",
    "        self.value_opt = tf.train.AdamOptimizer(self.lr, beta1= .8)\n",
    "        self.actor_opt = tf.train.AdamOptimizer(self.lr, beta1= .8)\n",
    "        \n",
    "        def get_grad_norm(optimizer, loss):\n",
    "            gvs = optimizer.compute_gradients(loss)\n",
    "            grad_norm = tf.reduce_mean(\n",
    "                [tf.reduce_mean(tf.square(grad)) for grad, var in gvs if grad is not None])\n",
    "            return grad_norm\n",
    "        \n",
    "        \n",
    "        self.a_grads = [\n",
    "            get_grad_norm(self.actor_opt, l) for l in [\n",
    "            self.a_loss_minimize, self.a_loss_raw, self.aregmagnitude, self.aregmean,\n",
    "            self.actstdpenalty, self.areg, self.grad_norm_a\n",
    "        ]]\n",
    "        self.v_grads = [get_grad_norm(self.value_opt, l) for l in [\n",
    "            self.v_loss_minimize, self.v_loss_raw, self.vreg, self.grad_norm_v\n",
    "        ]]\n",
    "        self.c_grads = [get_grad_norm(self.critic_opt, l) for l in [\n",
    "            self.c_loss_minimize, self.c_loss_raw, self.creg, self.grad_norm_c\n",
    "        ]]\n",
    "        \n",
    "        self.copt, self.c_norm = apply_clipped_optimizer(\n",
    "            self.critic_opt, self.c_loss_minimize, var_list = self.c_vars)\n",
    "        self.vopt, self.v_norm = apply_clipped_optimizer(\n",
    "            self.value_opt, self.v_loss_minimize, var_list = self.v_vars)\n",
    "        self.aopt, self.a_norm = apply_clipped_optimizer(\n",
    "            self.actor_opt, self.a_loss_minimize, var_list = self.a_vars)\n",
    "\n",
    "    def a_name(self):\n",
    "        self.a_idx += 1\n",
    "        return 'a_' + str(self.a_idx)\n",
    "    \n",
    "    def c_name(self):\n",
    "        self.c_idx += 1\n",
    "        return 'c_' + str(self.c_idx)\n",
    "    def v_name(self):\n",
    "        self.v_idx += 1\n",
    "        return 'v_' + str(self.v_idx)\n",
    "    \n",
    "    def load_weights(self):\n",
    "        feed_dict = {}\n",
    "        for (var, w), ph in zip(\n",
    "            self.assigns, self.weight_assignment_placeholders):\n",
    "            feed_dict[ph] = w\n",
    "        self.sess.run(self.weight_assignment_nodes, feed_dict=feed_dict)\n",
    "\n",
    "    def act(self, obs, metaobs, cx):\n",
    "        # Because we need batch dimension, \n",
    "        # data[None] changes shape from [A] to [1,A]\n",
    "        a = self.sess.run(\n",
    "            self.pi, feed_dict={\n",
    "                self.obs:np.reshape(obs, (1, 1, INPUT_UNITS)),\n",
    "                self.metaobs:np.reshape(metaobs, (1, 1, 1)),\n",
    "                self.is_train:False\n",
    "            })\n",
    "        return a[0][0]  # return first in batch\n",
    "\n",
    "    \n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    inter_op_parallelism_threads=0,\n",
    "    intra_op_parallelism_threads=0,\n",
    "    device_count = { \"GPU\": 0 } )\n",
    "tf.reset_default_graph()\n",
    "\n",
    "pi = PolicyLearner(env.observation_space, env.action_space, config = config)\n",
    "\n",
    "sess = pi.sess\n",
    "self = pi\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#trainer = ZooPolicyTensorflow(\n",
    "# \"mymodel1\", env.observation_space, env.action_space)\n",
    "saver = tf.train.Saver()\n",
    "ah, sh = [np.zeros((0, 0, i)) for i in [N_ACT, INPUT_UNITS]]\n",
    "mh, rh, rdecayedh = [np.zeros((0, 0)) for i in [None, None, None]]\n",
    "globalframes = []\n",
    "localframes = []\n",
    "ep = 0\n",
    "trained = 0\n",
    "ongoing = 0\n",
    "obj_fname = 'saveobjs_unguided.pkl'\n",
    "tffile = \"tmp/unguided_trained.ckpt\"\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adv(v, mag = 1, adv_type = 0):\n",
    "    if adv_type == 0:\n",
    "        return mag * v / np.abs(v).sum() * 2\n",
    "    elif adv_type == 1:\n",
    "        return mag * np.sign(v).astype(float) * .0002\n",
    "    elif adv_type == 2:\n",
    "        sign_v = np.sign(v)\n",
    "        v = np.sqrt(np.abs(v))\n",
    "        v = v / v.sum() * 20\n",
    "        return mag * v * sign_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ongoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ongoing:\n",
    "    \n",
    "    save_path = saver.save(sess, tffile)\n",
    "    print('saved at epoch', ep)\n",
    "    with open(obj_fname,\"wb\") as f:\n",
    "        pickle.dump(\n",
    "            [ah[-1000:], sh[-1000:], mh[-1000:],\n",
    "             rh[-1000:], rdecayedh[-1000:], maskh[-1000:], ep, globalframes\n",
    "            ], f)\n",
    "    trained = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if trained:\n",
    "    try:\n",
    "        saver.restore(sess, tffile)\n",
    "        with open(obj_fname, \"rb\") as f:\n",
    "            ah, sh, mh, rh, rdecayedh, maskh, ep, globalframes = pickle.load(f)\n",
    "        print('restored from save file')\n",
    "    except:\n",
    "        print('no save file detected')\n",
    "MAX_SEQ_LEN = 5000\n",
    "for ep in range(ep, 10000000):\n",
    "    if ep % 100 == 0 and trained and ep > 0:\n",
    "        save_path = saver.save(sess, tffile)\n",
    "        print('saved at epoch', ep)\n",
    "        with open(obj_fname,\"wb\") as f:\n",
    "            pickle.dump(\n",
    "                [ah[-1000:], sh[-1000:], mh[-1000:],\n",
    "                 rh[-1000:], rdecayedh[-1000:], maskh[-1000:], ep, globalframes\n",
    "                ], f)\n",
    "    trained = 1\n",
    "    ongoing = 1\n",
    "    an, sn = [np.zeros((0, i)) for i in [N_ACT, INPUT_UNITS]]\n",
    "    mn, rn, maskn = [], [], []\n",
    "    frame = 0\n",
    "    score = 0\n",
    "    restart_delay = 5\n",
    "    obs = env.reset()\n",
    "    obs = np.concatenate((obs, np.zeros((N_ACT))))\n",
    "    obs = np.concatenate((obs, np.zeros_like(obs)))\n",
    "    obs_mat = np.concatenate((\n",
    "        obs[None,:],np.zeros((NUM_HISTORY-1, N_STATE))), 0)\n",
    "    done_ctr = 0\n",
    "    metaobs = .00\n",
    "    mn.append(metaobs)\n",
    "    sn = np.concatenate((sn, obs_mat.reshape(1, -1)), 0)\n",
    "    step_num = 0\n",
    "    step_shifted = -1\n",
    "    show_shift = 0\n",
    "    while 1:\n",
    "        prob_random = .95#1 - 1/np.sqrt(ep+1)\n",
    "        step_num += 1\n",
    "        a = pi.act(obs_mat.flatten(), metaobs, env)\n",
    "        if step_shifted == -1: #always act on your own\n",
    "            shifted = 1\n",
    "            if np.random.rand() > prob_random:\n",
    "                a = np.random.randn(*a.shape)*.01\n",
    "            elif np.random.rand() > prob_random:\n",
    "                a = a + np.random.randn(*a.shape) * .5\n",
    "                #a = a + np.random.randn(*a.shape)/np.sqrt(np.sqrt(ep + 2))*4\n",
    "            elif np.random.rand() > prob_random:\n",
    "                impact = np.random.binomial(size=a.shape, n=1, p= 0.5) * 2\n",
    "                if np.random.rand() > .5:\n",
    "                    a = a + impact\n",
    "                else:\n",
    "                    a = a - impact\n",
    "            elif np.random.rand() > prob_random:\n",
    "                impact = np.random.binomial(size=a.shape, n=1, p= 0.5) * 2 - 1\n",
    "                a = a + impact\n",
    "            elif np.random.rand() > prob_random:\n",
    "                a = a * .5\n",
    "            elif np.random.rand() > prob_random:\n",
    "                a = a * 2\n",
    "            else:\n",
    "                shifted = 0\n",
    "            if shifted:\n",
    "                step_shifted = step_num\n",
    "            t = a\n",
    "#         else:\n",
    "#             if step_shifted > -1:\n",
    "#                 if not show_shift:\n",
    "#                     show_shift = 1\n",
    "#                     print('step_shifted', step_shifted)\n",
    "        an = np.concatenate((an, a[None,:]), 0)\n",
    "        last_obs = obs\n",
    "        obs, r, done, _ = env.step(a)\n",
    "        obs = np.concatenate((obs, a))\n",
    "        obs = np.concatenate((obs, obs - last_obs[:last_obs.shape[0]//2]))\n",
    "        obs_mat = np.concatenate((obs[None,:], obs_mat[:-1,:]/1.3), 0)\n",
    "        metaobs = metaobs + .01\n",
    "        mn.append(metaobs)\n",
    "        rn.append(r)\n",
    "        sn = np.concatenate((sn, obs_mat.reshape(1, -1)), 0)\n",
    "        score += r\n",
    "        frame += 1\n",
    "        still_open = env.render(\"human\")\n",
    "        if done:\n",
    "            done_ctr += 1\n",
    "            if done_ctr > 3:\n",
    "                if ep % MAX_SEQ_LEN == 0:\n",
    "                    print('score', score, ' frames', frame)\n",
    "                break\n",
    "        if still_open==False:\n",
    "            crashhere\n",
    "        if not done: continue\n",
    "        if restart_delay==0:\n",
    "            print(\"score=%0.2f in %i frames\" % (score, frame))\n",
    "            if still_open!=True:      # not True in multiplayer or non-Roboschool \n",
    "                break\n",
    "            restart_delay = 2000*2  # 2 sec at 60 fps\n",
    "        restart_delay -= 1\n",
    "        if restart_delay==0: \n",
    "            break\n",
    "    localframes.append(frame)\n",
    "    rn = np.array(rn)\n",
    "    rn[-1] = rn[-1] - 20\n",
    "    rewards = [0]\n",
    "    for ir in rn[::-1]:\n",
    "        rewards.append(rewards[-1] * GAMMA + ir)\n",
    "    rdecayedn = np.array(rewards)[:0:-1]\n",
    "    lenrdec = len(rdecayedn)\n",
    "#     rdecayedn = rdecayedn + lenrdec\n",
    "#     rdecayedn = rdecayedn - np.arange(lenrdec) * 1.8\n",
    "    mn = np.array(mn)\n",
    "    maskn = np.ones_like(rn)\n",
    "    if step_shifted > -1:\n",
    "        if step_shifted == 0:\n",
    "            raise ValueError('step shifted not allowed 0')\n",
    "        maskn[:step_shifted - 1] = 0\n",
    "    if ep == 0:\n",
    "        ah, sh, mh, rh, rdecayedh, maskh = [\n",
    "            np.expand_dims(v, 0) for v in [an, sn, mn, rn,rdecayedn, maskn]]\n",
    "    else:\n",
    "        def get_updated_h(h, n, third_dim):\n",
    "            hshape = h.shape[1]\n",
    "            nshape = n.shape[0]\n",
    "            if third_dim:\n",
    "                if hshape > nshape:\n",
    "                    n = np.concatenate((n, np.zeros((hshape - nshape, n.shape[-1]))), 0)\n",
    "                if nshape > hshape:\n",
    "                    h = np.concatenate((h, np.zeros((\n",
    "                        h.shape[0], nshape - hshape, h.shape[-1]))), 1)\n",
    "            else:\n",
    "                if hshape > nshape:\n",
    "                    n = np.concatenate((n, np.zeros((hshape - nshape))), 0)\n",
    "                if nshape > hshape:\n",
    "                    h = np.concatenate((h, np.zeros((h.shape[0], nshape - hshape))), 1)\n",
    "            h = np.concatenate((h, np.expand_dims(n, 0)), 0)\n",
    "            return h\n",
    "            \n",
    "        ah, sh = [get_updated_h(h, n, 1) for  h, n in zip([ah, sh], [an, sn])]\n",
    "        \n",
    "        mh, rh, rdecayedh, maskh = [\n",
    "            get_updated_h(h, n, 0) for h, n in zip(\n",
    "                [mh, rh, rdecayedh, maskh], [mn, rn, rdecayedn, maskn])]\n",
    "        \n",
    "    if ep % 1 == 0 and ep > 5:\n",
    "        ah, sh, mh, rh,rdecayedh, maskh = [\n",
    "            v[-400:] for v in [ah, sh, mh, rh,rdecayedh, maskh]]\n",
    "        globalframes.append(np.mean(localframes))\n",
    "        localframes = []\n",
    "        batch_size = 16\n",
    "        if ep < batch_size:\n",
    "            batch_size = ep\n",
    "        num_hist = ah.shape[0]\n",
    "        total_aloss = 0\n",
    "        total_closs = 0\n",
    "        for itr in range(1):\n",
    "            if num_hist >  batch_size:\n",
    "                forced_hist = 2\n",
    "                #probability = np.arange(num_hist - forced_hist)\n",
    "                probability = num_steps_per_run = (\n",
    "                    maskh.shape[1] - maskh[:,::-1].argmax(1))[:-forced_hist]\n",
    "                probability = np.square(probability)\n",
    "                probability = probability / probability.sum()\n",
    "                samples = np.concatenate((\n",
    "                    np.random.choice(\n",
    "                        num_hist - forced_hist, batch_size - forced_hist, \n",
    "                        replace=False, p=probability),\n",
    "                    np.arange(\n",
    "                        num_hist - forced_hist, num_hist)))\n",
    "            else:\n",
    "                samples = np.random.choice(num_hist, num_hist, replace=False)\n",
    "            actions, states, meta, returns, returnsdecayed, mask = [\n",
    "                v[samples] for v in [ah, sh, mh, rh,rdecayedh, maskh]]\n",
    "            feed_dict={\n",
    "                        self.metaobs:meta[:,:,None],\n",
    "                        self.returns:returns,\n",
    "                        self.returnsdecayed:returnsdecayed,\n",
    "                        self.lr: .05 / np.power(ep + 10, .5),\n",
    "                        self.mask:mask}\n",
    "            if ADV_ENABLED:\n",
    "                adv_sample = np.random.rand() > .3\n",
    "            else:\n",
    "                adv_sample = 0\n",
    "            if adv_sample:\n",
    "                a_type = np.random.choice(3)\n",
    "                feed_dict[self.obs] = states\n",
    "                a_obs_grad, aloss_pre = sess.run(\n",
    "                    [self.a_obs_grad, self.a_loss], feed_dict)\n",
    "                a_obs_grad = normalize_adv(a_obs_grad[0], mag = 3, adv_type = a_type)\n",
    "                feed_dict[self.obs] = states + a_obs_grad\n",
    "            else:\n",
    "                feed_dict[self.obs] = states + np.random.rand(*states.shape) * .1\n",
    "            _, aloss = sess.run(\n",
    "                [self.aopt, self.a_loss],\n",
    "                feed_dict = feed_dict\n",
    "                    )\n",
    "            if TESTING_GRAD_NORMS and ep % 10 == 0 and adv_sample:\n",
    "                a_grad_norms = self.sess.run(self.a_grads, feed_dict)\n",
    "                print('a grad norms', a_grad_norms)\n",
    "            if adv_sample:\n",
    "                feed_dict[self.pi] = actions\n",
    "                feed_dict[self.obs] = states[:,:-1,:]\n",
    "            else:\n",
    "                feed_dict[self.pi] = actions + np.random.rand(*actions.shape) * .1\n",
    "                feed_dict[self.obs] = states[:,:-1,:] + np.random.rand(\n",
    "                    *states[:,:-1,:].shape) * .1\n",
    "            feed_dict[self.metaobs] = meta[:,:-1,None]\n",
    "            feed_dict[self.returns] = returns[:,:-1]\n",
    "            feed_dict[self.returnsdecayed] = returnsdecayed[:,:-1]\n",
    "            feed_dict[self.mask] = mask[:,:-1]\n",
    "            if adv_sample:\n",
    "                feed_dict[self.pi] = actions\n",
    "                feed_dict[self.obs] = states[:,:-1,:]\n",
    "                v_obs_grad, vloss_pre = sess.run(\n",
    "                    [self.v_obs_grad, self.v_loss], feed_dict)\n",
    "                v_type = np.random.choice(3)\n",
    "                v_obs_grad = normalize_adv(v_obs_grad[0], mag = .1, adv_type = v_type)\n",
    "                feed_dict[self.obs] = states[:,:-1,:] + v_obs_grad\n",
    "                _, vloss = sess.run(\n",
    "                    [self.vopt, self.v_loss],\n",
    "                        feed_dict=feed_dict)\n",
    "                if TESTING_GRAD_NORMS and ep % 10 == 0:\n",
    "                    v_grad_norms = self.sess.run(self.v_grads, feed_dict)\n",
    "                    print('v grad norms', v_grad_norms)\n",
    "                \n",
    "                feed_dict[self.pi] = actions\n",
    "                feed_dict[self.obs] = states[:,:-1,:]\n",
    "                c_obs_grad, c_pi_grad, closs_pre = sess.run(\n",
    "                    [self.c_obs_grad, self.c_pi_grad, self.c_loss], feed_dict)\n",
    "                c_type = np.random.choice(3)\n",
    "                c_obs_grad, c_pi_grad = [\n",
    "                    normalize_adv(v[0], mag = .1, adv_type = c_type) \n",
    "                    for v in [c_obs_grad, c_pi_grad]]\n",
    "                feed_dict[self.pi] = actions + c_pi_grad\n",
    "                feed_dict[self.obs] = states[:,:-1,:] + c_obs_grad\n",
    "                \n",
    "                _,closs = sess.run(\n",
    "                    [self.copt, self.c_loss],\n",
    "                        feed_dict=feed_dict)\n",
    "                if TESTING_GRAD_NORMS and ep % 10 == 0:\n",
    "                    c_grad_norms = self.sess.run(self.c_grads, feed_dict)\n",
    "                    print('c grad norms', c_grad_norms)\n",
    "                \n",
    "            else:\n",
    "                _,_, closs, vloss = sess.run(\n",
    "                    [self.copt,self.vopt, self.c_loss, self.v_loss],\n",
    "                        feed_dict=feed_dict)\n",
    "            if 0:\n",
    "                if ep % 10 == 0:('aloss', aloss, 'closs', closs, 'vloss', vloss)\n",
    "        if ep % 10 == 0:\n",
    "            if adv_sample:\n",
    "                print('aloss', aloss - aloss_pre, 'atype', a_type,\n",
    "                      'closs', closs - closs_pre,  'ctype', c_type,\n",
    "                      'vloss', vloss - vloss_pre,  'vtype', v_type,)\n",
    "            print(' ep, ', ep, ' avg frames',np.mean(globalframes[-20:]))\n",
    "            print('abs action',np.abs(ah)[-1,0,:].shape, np.abs(ah)[-1,0,:].mean())\n",
    "            print('max reward',np.max(rh[-10:,10:]))\n",
    "        if ep % 10000 == 0:\n",
    "            clear_output()\n",
    "        if ep % 100 == 0:\n",
    "            ysmoothed = gaussian_filter1d(globalframes, sigma=4)\n",
    "            plt.plot(ysmoothed)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ah[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.arange(\n",
    "            num_hist - 4, num_hist)\n",
    "actions, states, meta, returns, returnsdecayed, mask = [\n",
    "    v[samples] for v in [ah, sh, mh, rh,rdecayedh, maskh]]\n",
    "feed_dict={\n",
    "            self.metaobs:meta[:,:,None],\n",
    "            self.returns:returns,\n",
    "            self.returnsdecayed:returnsdecayed,\n",
    "            self.lr: .01 / np.power(ep + 10, .7),\n",
    "            self.mask:mask,\n",
    "            self.obs:states}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.sess.run(self.pi, feed_dict)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ah[-4].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.sess.run(self.actstdpenalty, feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ah[-8].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.sess.run(self.pi, feed_dict)[-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        self.a_grads = [\n",
    "            get_grad_norm(self.actor_opt, l) for l in [\n",
    "            self.a_loss_minimize, self.a_loss_raw, self.aregmagnitude, self.aregmean,\n",
    "            self.actstdpenalty, self.areg, self.grad_norm_a\n",
    "        ]]\n",
    "        self.v_grads = [get_grad_norm(self.value_opt, l) for l in [\n",
    "            self.v_loss_minimize, self.v_loss_raw, self.vreg, self.grad_norm_v\n",
    "        ]]\n",
    "        self.c_grads = [get_grad_norm(self.critic_opt, l) for l in [\n",
    "            self.c_loss_minimize, self.c_loss_raw, self.creg, self.grad_norm_c\n",
    "        ]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "\n",
    "ysmoothed = gaussian_filter1d(globalframes, sigma=4)\n",
    "plt.plot(ysmoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = saver.save(sess, tffile)\n",
    "print('saved at epoch', ep)\n",
    "with open(obj_fname,\"wb\") as f:\n",
    "    pickle.dump(\n",
    "        [ah[-1000:], sh[-1000:], mh[-1000:],\n",
    "         rh[-1000:], rdecayedh[-1000:], maskh[-1000:], ep, globalframes\n",
    "        ], f)\n",
    "trained = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdecayedh[-2][np.where(mask[2])]\n",
    "\n",
    "# sess.run(self.state_value_estimate,feed_dict)[2][np.where(mask[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.run(self.state_value_estimate,feed_dict)[1][np.where(mask[1])].shape\n",
    "\n",
    "# sess.run(self.state_value_estimate,feed_dict)[1][np.where(mask[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ah[-2][:5].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
