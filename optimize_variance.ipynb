{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/py35/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import os.path, gym\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import roboschool\n",
    "import pdb\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "GAMMA = .97\n",
    "from functools import partial\n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "if 1:\n",
    "    envname = \"RoboschoolInvertedPendulum-v1\"\n",
    "    SIZE_MULT = 1\n",
    "    REWARD_MULT = 1\n",
    "    N_LAYERS = 10\n",
    "    N_DROP = 5\n",
    "    NUM_DROP_PARALLEL = 5\n",
    "    NUM_HISTORY = N_HISTORY = 3\n",
    "else:\n",
    "    envname = \"RoboschoolHumanoidFlagrun-v1\"\n",
    "    SIZE_MULT = 8\n",
    "    REWARD_MULT = 4\n",
    "    N_LAYERS = 20\n",
    "    N_DROP = 6\n",
    "    NUM_DROP_PARALLEL = 6\n",
    "    NUM_HISTORY = N_HISTORY = 6\n",
    "INIT_LEN = 200\n",
    "N_PRETRAIN = 1\n",
    "NUM_KEEP = 300\n",
    "PERCENT_CHOOSE_OPTIMAL = 2\n",
    "env = gym.make(envname)\n",
    "N_OBS, N_ACT = [v.shape[0] for v in [env.observation_space, env.action_space]]\n",
    "N_STATE = (N_OBS + N_ACT) * 2\n",
    "REWARD_IN_STATE = 0\n",
    "if REWARD_IN_STATE:\n",
    "    N_STATE += 2\n",
    "INPUT_UNITS = N_STATE * NUM_HISTORY\n",
    "STATE_DECAY = .7\n",
    "TESTING_GRAD_NORMS = 1\n",
    "ADV_ENABLED = 0\n",
    "STORED_MODELS = {}\n",
    "FCNS = {'np':{\n",
    "    'concat':np.concatenate,\n",
    "    'reshape':np.reshape,\n",
    "    'expand':np.expand_dims\n",
    "},'tf':{\n",
    "    'concat':tf.concat,\n",
    "    'reshape':tf.reshape,\n",
    "    'expand':tf.expand_dims\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xb2f11c470>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-100, 100, .01)\n",
    "\n",
    "y = np.log(np.abs(x)+1) * np.sign(x)\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_clipped_optimizer(opt_fcn,\n",
    "                            loss,\n",
    "                            clip_norm=.1,\n",
    "                            clip_single=.03,\n",
    "                            clip_global_norm=False,\n",
    "                            var_list=None):\n",
    "    if var_list is None:\n",
    "        gvs = opt_fcn.compute_gradients(loss)\n",
    "    else:\n",
    "        gvs = opt_fcn.compute_gradients(loss, var_list = var_list)\n",
    "        \n",
    "\n",
    "    if clip_global_norm:\n",
    "        gs, vs = zip(*[(g, v) for g, v in gvs if g is not None])\n",
    "        capped_gs, grad_norm_total = tf.clip_by_global_norm([g for g in gs],clip_norm)\n",
    "        capped_gvs = list(zip(capped_gs, vs))\n",
    "    else:\n",
    "        grad_norm_total = tf.sqrt(\n",
    "                tf.reduce_sum([\n",
    "                        tf.reduce_sum(tf.square(grad)) for grad, var in gvs\n",
    "                        if grad is not None\n",
    "                ]))\n",
    "        capped_gvs = [(tf.clip_by_value(grad, -1 * clip_single, clip_single), var)\n",
    "                                    for grad, var in gvs if grad is not None]\n",
    "        capped_gvs = [(tf.clip_by_norm(grad, clip_norm), var)\n",
    "                                    for grad, var in capped_gvs if grad is not None]\n",
    "\n",
    "    optimizer = opt_fcn.apply_gradients(capped_gvs)\n",
    "\n",
    "    return optimizer, grad_norm_total\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self,\n",
    "                x, lshapes, output_units, namebase, squeeze = True,\n",
    "                lshapes_drop = None, drop_rate = .2, reuse = False,\n",
    "                residual = None\n",
    "                ):\n",
    "        self.namebase = namebase\n",
    "        self.reuse = reuse\n",
    "        self.lidx = 0\n",
    "        name_fcn = self.get_name\n",
    "        h = [tf.nn.leaky_relu(tf.layers.dense(\n",
    "            x, lshapes[0], name=self.get_name(), reuse = self.reuse))]\n",
    "        h2 = h[-1]\n",
    "        for size in lshapes:\n",
    "            h.append(tf.nn.leaky_relu(h[-1] + tf.layers.dense(\n",
    "                h2, size, name=name_fcn(), reuse = self.reuse)))\n",
    "            h2 = h[-1]#tf.concat((x, h[-1]), -1)\n",
    "        if lshapes_drop is None:\n",
    "            hout = tf.concat((h[-1:]), -1)\n",
    "            output = tf.layers.dense(\n",
    "                hout, output_units, name=name_fcn(), reuse = self.reuse)\n",
    "            if output_units == 1 and squeeze:\n",
    "                output = tf.squeeze(output, -1)\n",
    "            self.raw_output = output\n",
    "            self.output = leaky_tanh(self.raw_output)\n",
    "            if residual is not None:\n",
    "                self.output = self.output + residual\n",
    "        else:\n",
    "            drop_outs = []\n",
    "            x_drop = tf.concat((h[-1:]), -1)\n",
    "            name_fcn = self.get_name_drop\n",
    "            self.lidx_drop = 0\n",
    "            for drop_idx, drop_try in enumerate(range(NUM_DROP_PARALLEL)):\n",
    "                h_drop = [x_drop]\n",
    "                for lsize in lshapes_drop:\n",
    "                    new_layer = tf.nn.dropout(tf.nn.leaky_relu(tf.layers.dense(\n",
    "                        h_drop[-1], size, name=name_fcn(), reuse = self.reuse)), keep_prob = 1-drop_rate)\n",
    "                    h_drop.append(new_layer)\n",
    "                output = tf.layers.dense(h_drop[-1], output_units)\n",
    "                if output_units == 1 and squeeze:\n",
    "                    output = tf.squeeze(output, -1)\n",
    "                output = output\n",
    "                if residual is not None:\n",
    "                    output = output + residual\n",
    "                drop_outs.append(output)\n",
    "                self.reuse = True\n",
    "                self.lidx_drop = 0\n",
    "            self.output = tf.stack(drop_outs, -1)\n",
    "            self.output_mean, self.variance = tf.nn.moments(self.output, -1)\n",
    "    def get_name(self):\n",
    "        self.lidx = self.lidx + 1\n",
    "        return self.namebase + str(self.lidx)\n",
    "    def get_name_drop(self):\n",
    "        self.lidx_drop = self.lidx_drop + 1\n",
    "        return self.namebase + '_drop_' + str(self.lidx_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_state(state, action, style = 'np'):\n",
    "    together = FCNS[style]['concat']((state, action), -1)\n",
    "    if style == 'tf':\n",
    "        return together\n",
    "#         expanded = FCNS[style]['expand'](\n",
    "#             together, 1)\n",
    "    else:\n",
    "        expanded = FCNS[style]['expand'](\n",
    "            together, 0)\n",
    "    return expanded\n",
    "    return FCNS[style]['reshape'](\n",
    "        together, (state.shape[0], -1, state.shape[-1] + action.shape[-1]))\n",
    "        \n",
    "    \n",
    "\n",
    "def accumulate_state(state, action, old_state, statedecay, style = 'np'):\n",
    "    new_state = make_state(state, action, style)\n",
    "    new_state_len = new_state.shape[-1]\n",
    "    if style == 'tf':\n",
    "        vel = new_state - old_state[:,:,0,:new_state_len]\n",
    "    else:\n",
    "        vel = new_state - old_state[0,:new_state_len]\n",
    "    new_state = FCNS[style]['concat']((new_state, vel), -1)\n",
    "    if style == 'tf':\n",
    "        return FCNS[style]['concat']((tf.expand_dims(new_state, 2), old_state[:,:,:-1,:]*statedecay), 2)\n",
    "    return FCNS[style]['concat']((new_state, old_state[:-1,:]*statedecay), 0)\n",
    "\n",
    "def leaky_tanh(x):\n",
    "    return tf.log(tf.abs(x)+1) * tf.sign(x)*.7\n",
    "    #return tf.nn.tanh(x*30)/10 + tf.nn.tanh(x*2)/2 + tf.nn.tanh(x/20) * 2 + x * 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_grad_norm(optimizer, loss, optname):\n",
    "    gvs = optimizer.compute_gradients(loss)\n",
    "    grad_norm = tf.reduce_mean(\n",
    "        [tf.reduce_mean(tf.square(grad)) for\n",
    "         grad, var in gvs if grad is not None and optname in var.name])\n",
    "    return grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class PolicyLearner(object):\n",
    "    def __init__(self, ob_space, ac_space, take_weights_here=None, \n",
    "                 lshapes = [32 * SIZE_MULT] * N_LAYERS, config = None, \n",
    "                 lshapes_small = [16 * SIZE_MULT] * (N_LAYERS//2),\n",
    "                 lshapes_smaller = [16 * SIZE_MULT] * (N_LAYERS//2),\n",
    "                 lshapes_drop = [16 * SIZE_MULT] * N_DROP,\n",
    "                reuse = False):\n",
    "        self.sess = tf.InteractiveSession(config=config)\n",
    "        self.obs_raw = tf.placeholder(tf.float32, (None, None, NUM_HISTORY, N_STATE))\n",
    "        self.returns = tf.placeholder(tf.float32, (None, None))\n",
    "        self.returnsdecayed = tf.placeholder(tf.float32, (None, None))\n",
    "        self.mask = tf.placeholder(tf.float32, (None, None))\n",
    "        self.lr = tf.placeholder_with_default(1e-3, (None))\n",
    "        self.statesraw = tf.placeholder(tf.float32, (None, None, N_OBS))\n",
    "        self.is_train = tf.placeholder_with_default(True, (None))\n",
    "        self.is_exploit = tf.placeholder(tf.float32, (None))\n",
    "        self.is_exploit2d = tf.expand_dims(self.is_exploit, -1)\n",
    "        self.is_exploit3d = tf.expand_dims(self.is_exploit2d, -1)\n",
    "        self.statesraw_expanded = tf.expand_dims(self.statesraw, -1)\n",
    "        self.obs_raw_expanded = tf.expand_dims(self.obs_raw, -1)\n",
    "        self.maskexpanded = tf.expand_dims(self.mask, -1)\n",
    "        self.maskexpanded2 = tf.expand_dims(self.maskexpanded, -1)\n",
    "        self.obs = tf.reshape(\n",
    "            self.obs_raw, (\n",
    "                tf.shape(self.obs_raw)[0], tf.shape(self.obs_raw)[1], N_STATE * NUM_HISTORY))\n",
    "        self.actor = MLP(\n",
    "            self.obs, lshapes, N_ACT, 'a_', squeeze = False, reuse = reuse)\n",
    "        self.explorer = MLP(\n",
    "            self.obs, lshapes, N_ACT, 'e_', squeeze = False, reuse = reuse, residual = self.actor.output)\n",
    "        self.actions = self.actor.output\n",
    "        self.explorer_actions = self.explorer.output\n",
    "        self.state_value_estimator = MLP(\n",
    "            self.obs, lshapes_smaller, 1, 'v_', reuse = reuse)\n",
    "        self.state_value_estimate = self.state_value_estimator.output\n",
    "        \n",
    "        self.advantage = ((\n",
    "            self.state_value_estimate[:,1:] * GAMMA + self.returns[:,:-1]) -\n",
    "            self.state_value_estimate[:,:-1])\n",
    "        \n",
    "        self.critic_input = tf.concat((self.obs, self.actions), -1)\n",
    "        self.explorer_critic_input = tf.concat((self.obs, self.explorer.output), -1)\n",
    "        \n",
    "        self.advantage_estimator = MLP(\n",
    "            self.critic_input, lshapes_small, 1, 'c_', lshapes_drop = lshapes_drop, reuse = reuse)\n",
    "        self.model_estimator = MLP(\n",
    "            self.critic_input, lshapes_small, N_OBS, 'm_', lshapes_drop = lshapes_drop, reuse = reuse,\n",
    "            residual = self.statesraw\n",
    "        )\n",
    "        self.explorer_advantage_estimator = MLP(\n",
    "            self.explorer_critic_input, lshapes_small, 1, 'c_', lshapes_drop = lshapes_drop, reuse = True)\n",
    "        self.explorer_model_estimator = MLP(\n",
    "            self.explorer_critic_input, lshapes_small, N_OBS, 'm_', lshapes_drop = lshapes_drop, reuse = True,\n",
    "            residual = self.statesraw\n",
    "        )\n",
    "        self.advantage_estimate = self.advantage_estimator.output_mean\n",
    "        self.model_estimate = self.model_estimator.output_mean\n",
    "        self.future_obs_raw = accumulate_state(\n",
    "            self.model_estimate, self.actions, self.obs_raw, STATE_DECAY, style = 'tf')\n",
    "        self.explorer_future_obs_raw = accumulate_state(\n",
    "            self.explorer_model_estimator.output_mean, self.explorer_actions,\n",
    "            self.obs_raw, STATE_DECAY, style = 'tf')\n",
    "        \n",
    "        self.future_obs = tf.reshape(self.future_obs_raw, \n",
    "            (tf.shape(self.future_obs_raw)[0],tf.shape(self.future_obs_raw)[1], N_STATE * NUM_HISTORY))\n",
    "        self.explorer_future_obs = tf.reshape(self.explorer_future_obs_raw, \n",
    "            (tf.shape(self.explorer_future_obs_raw)[0],\n",
    "             tf.shape(self.explorer_future_obs_raw)[1], N_STATE * NUM_HISTORY))\n",
    "        \n",
    "        self.future_value = MLP(\n",
    "            self.future_obs, lshapes_smaller, 1, 'v_', reuse = True)\n",
    "        \n",
    "\n",
    "        self.future_actor = MLP(\n",
    "            self.future_obs, lshapes, N_ACT, 'a_', reuse = True, squeeze = False)\n",
    "        self.future_actions = self.future_actor.output\n",
    "        \n",
    "        self.future_critic_input = tf.concat((self.future_obs, self.future_actions), -1)\n",
    "        self.future_advantage_estimator = MLP(\n",
    "            self.future_critic_input, lshapes_small, 1, 'c_', lshapes_drop = lshapes_drop, reuse = True)\n",
    "        \n",
    "        if len(self.future_actions.shape) == 2:\n",
    "            self.future_actions = tf.expand_dims(self.future_actions, -1)\n",
    "        \n",
    "        self.t_vars = tf.trainable_variables()\n",
    "        self.a_vars = [var for var in self.t_vars if 'a_' in var.name]\n",
    "        self.v_vars = [var for var in self.t_vars if 'v_' in var.name]\n",
    "        self.c_vars = [var for var in self.t_vars if 'c_' in var.name]\n",
    "        self.e_vars = [var for var in self.t_vars if 'e_' in var.name]\n",
    "        self.m_vars = [var for var in self.t_vars if 'm_' in var.name]\n",
    "        \n",
    "        self.creg, self.areg, self.vreg, self.mreg, self.ereg = [\n",
    "            tf.reduce_mean([tf.reduce_mean(tf.square(v)) for v in optvars]) * 1e0\n",
    "            for optvars in \n",
    "            [self.c_vars, self.a_vars, self.v_vars, self.m_vars, self.e_vars]]\n",
    "        \n",
    "        def mplusv(x):\n",
    "            return x.variance + x.output_mean\n",
    "        \n",
    "        \n",
    "        self.explorer_adv_loss = -tf.reduce_mean(tf.square(mplusv(\n",
    "            self.explorer_advantage_estimator) * self.mask))\n",
    "        self.explorer_mdl_loss = -tf.reduce_mean(tf.square(\n",
    "            self.explorer_model_estimator.variance * self.maskexpanded))\n",
    "        self.e_mse = tf.reduce_mean(\n",
    "            tf.square(self.explorer.raw_output) * self.maskexpanded) * 1e-1\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.model_state_estimate = self.model_estimator.output_mean\n",
    "        \n",
    "        self.v_loss_raw = tf.reduce_mean(tf.square(\n",
    "            self.returnsdecayed - self.state_value_estimate) * self.mask * self.is_exploit2d) * 3\n",
    "        \n",
    "        self.m_loss_raw = tf.reduce_mean(tf.square(\n",
    "            self.model_estimator.output[:,:-1] - self.statesraw_expanded[:,1:]\n",
    "        ) * self.maskexpanded2[:,:-1]) * 10000\n",
    "        \n",
    "        self.c_loss_raw = tf.reduce_mean(tf.square(\n",
    "            self.advantage_estimate[:,:-1] - self.advantage) * self.mask[:,:-1]) * 3\n",
    "        \n",
    "        \n",
    "        self.actionmean = tf.reduce_sum(\n",
    "            self.actions * self.maskexpanded, 1) / tf.reduce_sum(\n",
    "            self.maskexpanded, 1) + tf.reduce_sum(\n",
    "            self.future_actions * self.maskexpanded, 1) / tf.reduce_sum(\n",
    "            self.maskexpanded, 1) \n",
    "        \n",
    "        \n",
    "        self.actionmean = tf.reduce_sum(\n",
    "            self.actions * self.maskexpanded, 1) / tf.reduce_sum(\n",
    "            self.maskexpanded, 1)\n",
    "        self.actdiffsquared = tf.square(\n",
    "            self.actions - tf.expand_dims(self.actionmean, 1))\n",
    "        self.actvar = tf.reduce_sum(\n",
    "            self.actdiffsquared * self.maskexpanded, 1)/ tf.reduce_sum(\n",
    "            self.maskexpanded, 1)\n",
    "        self.actstd = self.actvar\n",
    "        self.actstdpenalty = -tf.reduce_mean(\n",
    "            tf.log(self.actstd + .00001)* .00001 + tf.square(self.actstd)) * .001\n",
    "        \n",
    "        self.aregmeanbyaction = tf.reduce_mean(\n",
    "            tf.square(self.actionmean)) * .01\n",
    "        self.a_mse = tf.reduce_mean(tf.square(\n",
    "            self.actions + self.future_actions/1000) * self.maskexpanded) * 1e-4 + tf.reduce_mean(\n",
    "            tf.square(self.actor.raw_output + self.future_actor.raw_output/1000) * self.maskexpanded) * 1e-2\n",
    "        \n",
    "        self.frac_not_masked = tf.reduce_mean(self.mask)\n",
    "        \n",
    "        self.a_loss_critic = -tf.reduce_mean(\n",
    "            self.advantage_estimator.output_mean * self.mask)/self.frac_not_masked * 2000\n",
    "        self.a_loss_model = -tf.reduce_mean(\n",
    "            self.future_value.output * self.mask)/self.frac_not_masked * 1.\n",
    "        self.a_loss_secondaction = -tf.reduce_mean(\n",
    "            self.future_advantage_estimator.output_mean * self.mask)/self.frac_not_masked * .1\n",
    "        \n",
    "        self.grad_v = tf.square(tf.gradients(\n",
    "            self.state_value_estimator.output * self.mask, self.obs)[0])\n",
    "        self.grad_m = tf.square(tf.gradients(\n",
    "            self.model_estimator.output * self.maskexpanded2, self.critic_input)[0])\n",
    "        self.grad_c = tf.square(tf.gradients(\n",
    "            self.advantage_estimator.output * self.maskexpanded, self.critic_input)[0])\n",
    "        \n",
    "        self.grad_norm_m = tf.reduce_mean(self.grad_m) * 1e-2\n",
    "        self.grad_norm_v = tf.reduce_mean(self.grad_v) * 1e-4\n",
    "        self.grad_norm_c = tf.reduce_mean(self.grad_c) * 1e-2\n",
    "    \n",
    "        slopes = tf.reduce_sum(tf.square(self.grad_c), reduction_indices=[2])\n",
    "        self.grad_c_1 = tf.reduce_mean(self.mask * (slopes - .2) ** 2) * 1e-3\n",
    "        slopes = tf.reduce_sum(tf.square(self.grad_m), reduction_indices=[2])\n",
    "        self.grad_m_1 = tf.reduce_mean(self.mask * (slopes - .2) ** 2) * 1e-5\n",
    "        \n",
    "        \n",
    "        self.critic_opt = tf.train.AdamOptimizer(self.lr, beta1= .8)\n",
    "        self.value_opt = tf.train.AdamOptimizer(self.lr, beta1= .8)\n",
    "        self.actor_opt = tf.train.AdamOptimizer(self.lr, beta1= .8)\n",
    "        self.model_opt = tf.train.AdamOptimizer(self.lr, beta1= .8)\n",
    "        self.explorer_opt = tf.train.AdamOptimizer(self.lr, beta1= .8)\n",
    "        \n",
    "        \n",
    "        self.actor_current_mult = []\n",
    "        self.critic_current_mult = []\n",
    "        self.actor_loss_mults = []\n",
    "        self.critic_loss_mults = []\n",
    "        self.critic_loss_grads = []\n",
    "        self.actor_loss_grads = []\n",
    "        self.actor_loss_targets = np.array([30., 1., .1,1e-6, .1, .01, .01,\n",
    "                                           10., 1., 1e-6, .01])\n",
    "        self.actor_loss_names = ['a_loss_critic', 'a_loss_model', 'a_loss_secondaction', \n",
    "                    'areg', 'aregmeanbyaction', 'actstdpenalty', 'a_mse',\n",
    "                    'explorer_adv_loss', 'explorer_mdl_loss', 'ereg',\n",
    "                     'e_mse'\n",
    "                                ]\n",
    "        self.critic_loss_targets = np.array(\n",
    "            [10, 10, 10,\n",
    "             .001, .001, .001, \n",
    "            .001, .001,\n",
    "            1e-8, 1e-8, 1e-8])\n",
    "        self.critic_loss_names = [\n",
    "            'v_loss_raw','m_loss_raw', 'c_loss_raw',\n",
    "            'grad_norm_c',  'grad_norm_v', 'grad_norm_m', \n",
    "            'grad_m_1', 'grad_c_1',\n",
    "             'creg','vreg', 'mreg']\n",
    "        self.aopts = [self.actor_opt] * 7 + [self.explorer_opt] * 4\n",
    "        self.aoptnames = ['a_'] * 7 + ['e_'] * 4\n",
    "        self.copts = [self.value_opt, self.model_opt, self.critic_opt, \n",
    "                      self.critic_opt, self.value_opt,\n",
    "                      self.model_opt, self.model_opt, self.critic_opt, \n",
    "                      self.critic_opt, self.value_opt,self.model_opt]\n",
    "        self.coptnames = [v + '_' for v in ['v', 'm', 'c', 'c', 'v', 'm', 'm', 'c', 'c', 'v', 'm']]\n",
    "        for lidx, loss in enumerate(self.actor_loss_names):\n",
    "            opt = self.aopts[lidx]\n",
    "            optname = self.aoptnames[lidx]\n",
    "            loss_mult = tf.placeholder_with_default(1., (None))\n",
    "            self.actor_loss_mults.append(loss_mult)\n",
    "            setattr(self, loss, getattr(self, loss) * loss_mult)\n",
    "            self.actor_loss_grads.append(get_grad_norm(opt, getattr(self, loss), optname))\n",
    "            self.actor_current_mult.append(1)\n",
    "        for lidx, loss in enumerate(self.critic_loss_names):\n",
    "            opt = self.copts[lidx]\n",
    "            optname = self.coptnames[lidx]\n",
    "            loss_mult = tf.placeholder_with_default(1., (None))\n",
    "            self.critic_loss_mults.append(loss_mult)\n",
    "            setattr(self, loss, getattr(self, loss) * loss_mult)\n",
    "            self.critic_loss_grads.append(get_grad_norm(opt, getattr(self, loss), optname))\n",
    "            self.critic_current_mult.append(1)\n",
    "        self.actor_current_mult = np.array(self.actor_current_mult)\n",
    "        self.critic_current_mult = np.array(self.critic_current_mult)\n",
    "        \n",
    "        self.v_loss =  self.v_loss_raw + self.vreg\n",
    "        self.m_loss = self.m_loss_raw + self.mreg\n",
    "        self.c_loss =  self.c_loss_raw + self.creg\n",
    "        self.aregtotal = self.areg + self.aregmeanbyaction + self.actstdpenalty + self.a_mse\n",
    "        self.a_loss_raw = self.a_loss_critic + self.a_loss_model + \\\n",
    "            self.a_loss_secondaction\n",
    "        self.a_loss = self.a_loss_raw + self.aregtotal\n",
    "        \n",
    "        \n",
    "        self.e_loss_minimize = self.explorer_adv_loss + self.explorer_mdl_loss + self.e_mse + self.ereg\n",
    "        self.a_loss_minimize = self.a_loss\n",
    "        self.c_loss_minimize = self.c_loss + self.grad_norm_c + self.grad_c_1\n",
    "        self.v_loss_minimize = self.v_loss + self.grad_norm_v\n",
    "        self.m_loss_minimize = self.m_loss + self.grad_norm_m + self.grad_m_1\n",
    "        \n",
    "        \n",
    "#         if TESTING_GRAD_NORMS:\n",
    "#             self.a_grads = [\n",
    "#                 get_grad_norm(self.actor_opt, l) for l in [\n",
    "#                 self.a_loss_minimize, self.a_loss_raw, self.a_loss_critic,self.a_loss_model,\n",
    "#                 self.a_loss_secondaction,\n",
    "#                 self.areg, self.aregmeanbyaction, self.actstdpenalty, self.a_mse\n",
    "#             ]]\n",
    "#             self.v_grads = [get_grad_norm(self.value_opt, l) for l in [\n",
    "#                 self.v_loss_minimize, self.v_loss_raw, \n",
    "#                 self.vreg, self.grad_norm_v\n",
    "#             ]]\n",
    "#             self.c_grads = [get_grad_norm(self.critic_opt, l) for l in [\n",
    "#                 self.c_loss_minimize, self.c_loss_raw, \n",
    "#                 self.creg, self.grad_norm_c, self.grad_c_1\n",
    "\n",
    "#             ]]\n",
    "#             self.m_grads = [get_grad_norm(self.critic_opt, l) for l in [\n",
    "#                 self.m_loss_minimize, self.m_loss_raw, \n",
    "#                 self.mreg, self.grad_norm_m, self.grad_m_1\n",
    "#             ]]\n",
    "        \n",
    "        self.copt, self.c_norm = apply_clipped_optimizer(\n",
    "            self.critic_opt, self.c_loss_minimize, var_list = self.c_vars)\n",
    "        self.vopt, self.v_norm = apply_clipped_optimizer(\n",
    "            self.value_opt, self.v_loss_minimize, var_list = self.v_vars)\n",
    "        self.aopt, self.a_norm = apply_clipped_optimizer(\n",
    "            self.actor_opt, self.a_loss_minimize, var_list = self.a_vars)\n",
    "        self.mopt, self.m_norm = apply_clipped_optimizer(\n",
    "            self.model_opt, self.m_loss_minimize, var_list = self.m_vars)\n",
    "        self.eopt, self.e_norm = apply_clipped_optimizer(\n",
    "            self.explorer_opt, self.e_loss_minimize, var_list = self.e_vars)\n",
    "\n",
    "    def a_name(self):\n",
    "        self.a_idx += 1\n",
    "        return 'a_' + str(self.a_idx)\n",
    "    def c_name(self):\n",
    "        self.c_idx += 1\n",
    "        return 'c_' + str(self.c_idx)\n",
    "    def v_name(self):\n",
    "        self.v_idx += 1\n",
    "        return 'v_' + str(self.v_idx)\n",
    "    def m_name(self):\n",
    "        self.m_idx += 1\n",
    "        return 'm_' + str(self.m_idx)\n",
    "    def e_name(self):\n",
    "        self.e_idx += 1\n",
    "        return 'e_' + str(self.e_idx)\n",
    "    \n",
    "    def load_weights(self):\n",
    "        feed_dict = {}\n",
    "        for (var, w), ph in zip(\n",
    "            self.assigns, self.weight_assignment_placeholders):\n",
    "            feed_dict[ph] = w\n",
    "        self.sess.run(self.weight_assignment_nodes, feed_dict=feed_dict)\n",
    "\n",
    "    def act(self, obs, exploit = True):\n",
    "        # Because we need batch dimension, \n",
    "        # data[None] changes shape from [A] to [1,A]\n",
    "        if exploit:\n",
    "            act = self.actions\n",
    "        else:\n",
    "            act = self.explorer_actions\n",
    "        a = self.sess.run(\n",
    "            act, feed_dict={\n",
    "                self.obs_raw:np.reshape(obs, (1, 1, N_HISTORY, N_STATE)),\n",
    "                self.is_train:False\n",
    "            })\n",
    "        return a[0][0]  # return first in batch\n",
    "\n",
    "\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    inter_op_parallelism_threads=0,\n",
    "    intra_op_parallelism_threads=0,\n",
    "    device_count = { \"GPU\": 0 } )\n",
    "tf.reset_default_graph()\n",
    "\n",
    "pi = PolicyLearner(env.observation_space, env.action_space, config = config)\n",
    "\n",
    "sess = pi.sess\n",
    "self = pi\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#trainer = ZooPolicyTensorflow(\n",
    "# \"mymodel1\", env.observation_space, env.action_space)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()\n",
    "\n",
    "\n",
    "# env = gym.make(envname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.actor_current_mult = np.ones_like(self.actor_current_mult,dtype=np.float32)\n",
    "self.critic_current_mult = np.ones_like(self.critic_current_mult,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#         self.advantage = ((\n",
    "#             self.stateraw_value_estimate[:,1:] * GAMMA + self.returns) -\n",
    "#             self.state_value_estimate[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ah, sh, shraw, rh, rdecayedh, maskh = [\n",
    "    np.zeros((0, 0, i)) for i in [N_ACT, INPUT_UNITS, N_OBS, 1, 1, 1]]\n",
    "isexploit = []\n",
    "globalframes = []\n",
    "localframes = []\n",
    "ep = 0\n",
    "trained = 0\n",
    "ongoing = 0\n",
    "printfreq = 20\n",
    "obj_fname = envname + str(PERCENT_CHOOSE_OPTIMAL) + 'saveobjs_unguided.pkl'\n",
    "tffile = \"tmp/\" + envname + str(PERCENT_CHOOSE_OPTIMAL) + \"unguided_trained.ckpt\"\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ongoing = 0\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ongoing:\n",
    "    \n",
    "    save_path = saver.save(sess, tffile)\n",
    "    print('saved at epoch', ep)\n",
    "    with open(obj_fname,\"wb\") as f:\n",
    "        pickle.dump(\n",
    "            [ah, sh, rh, rdecayedh, maskh, ep, globalframes, isexploit\n",
    "            ], f)\n",
    "    trained = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_actor(self, feed_dict, printon):\n",
    "    _, _, aloss = sess.run(\n",
    "        [self.aopt, self.eopt, self.a_loss],\n",
    "        feed_dict = feed_dict\n",
    "            )\n",
    "    if TESTING_GRAD_NORMS and ep % printfreq == 0 and printon and ep > INIT_LEN:\n",
    "        cur_grad_norms = sess.run(self.actor_loss_grads, feed_dict)\n",
    "        target = self.actor_loss_targets\n",
    "        problem_factor = cur_grad_norms / target\n",
    "        for fidx, factor in enumerate(problem_factor):\n",
    "            if fidx == len(problem_factor) - 1:\n",
    "                pass#pdb.set_trace()\n",
    "            if factor > 100:\n",
    "                self.actor_current_mult[fidx] = self.actor_current_mult[fidx] / 10\n",
    "            elif factor > 10:\n",
    "                self.actor_current_mult[fidx] = self.actor_current_mult[fidx] / 2\n",
    "            elif factor < .01:\n",
    "                self.actor_current_mult[fidx] = self.actor_current_mult[fidx] * 10\n",
    "            elif factor < .1:\n",
    "                self.actor_current_mult[fidx] = self.actor_current_mult[fidx] * 2\n",
    "        print(list(zip(self.actor_loss_names, cur_grad_norms, target, self.actor_current_mult)))\n",
    "    return aloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(actor = True, value = True, n_steps = 1, forced_hist = 2):\n",
    "    for itr in range(n_steps):\n",
    "        if num_hist >  batch_size:\n",
    "            #probability = np.arange(num_hist - forced_hist)\n",
    "            probability = num_steps_per_run = (\n",
    "                maskh.shape[1] - maskh[:,::-1].argmax(1))\n",
    "            if forced_hist:\n",
    "                probability = probability[:-forced_hist]\n",
    "            probability = np.square(probability)\n",
    "            probability = probability / probability.sum()\n",
    "            rnd = np.random.choice(\n",
    "                    num_hist - forced_hist, batch_size - forced_hist, \n",
    "                    replace=False, p=probability)\n",
    "            if forced_hist:\n",
    "                samples = np.concatenate((rnd,\n",
    "                    np.arange( num_hist - forced_hist, num_hist)))\n",
    "            else:\n",
    "                samples=rnd\n",
    "        else:\n",
    "            samples = np.random.choice(num_hist, num_hist, replace=False)\n",
    "        #samples = np.array([-2, -1])\n",
    "        actions, states, statesraw, returns, returnsdecayed, mask, exploit = [\n",
    "            v[samples] for v in [ah, sh, shraw, rh,rdecayedh, maskh, np.array(isexploit)]]\n",
    "        \n",
    "        feed_dict={\n",
    "                    self.returns:returns,\n",
    "                    self.statesraw: statesraw,\n",
    "                    self.returnsdecayed:returnsdecayed,\n",
    "                    self.lr: .02 / np.power(ep + 20, .4),\n",
    "                    self.mask:mask,\n",
    "                    self.obs_raw: states.reshape(*states.shape[:2], N_HISTORY, N_STATE),\n",
    "                    self.is_exploit:exploit,\n",
    "                    self.actions:actions\n",
    "        }\n",
    "        for lph, lmult in zip(self.actor_loss_mults, self.actor_current_mult):\n",
    "            feed_dict[lph] = lmult\n",
    "        for lph, lmult in zip(self.critic_loss_mults, self.critic_current_mult):\n",
    "            feed_dict[lph] = lmult\n",
    "        if value:\n",
    "            if exploit.sum() > 1:\n",
    "                _,_, _, mloss, closs, vloss = sess.run(\n",
    "                    [self.mopt, self.copt,self.vopt, self.m_loss, self.c_loss, self.v_loss],\n",
    "                        feed_dict=feed_dict)\n",
    "            else:\n",
    "                _, mloss = sess.run(\n",
    "                    [self.mopt, self.m_loss],\n",
    "                        feed_dict=feed_dict)\n",
    "                closs = vloss = 0\n",
    "        else:\n",
    "            mloss = closs =  vloss = 0\n",
    "        del feed_dict[self.actions]\n",
    "        if actor and exploit.sum() > 1:\n",
    "            aloss = train_actor(self, feed_dict, printon = itr == 0)\n",
    "        else:\n",
    "            aloss = 0\n",
    "    if 1:\n",
    "        if ep % printfreq == 0 and exploit.sum() > 1:\n",
    "            print('aloss', aloss, 'closs', closs, 'vloss', vloss, 'mloss', mloss)\n",
    "            if TESTING_GRAD_NORMS and ep > INIT_LEN:\n",
    "                \n",
    "                cur_grad_norms = sess.run(self.critic_loss_grads, feed_dict)\n",
    "                target = self.critic_loss_targets\n",
    "                problem_factor = cur_grad_norms / target\n",
    "                for fidx, factor in enumerate(problem_factor):\n",
    "                    if factor > 100:\n",
    "                        self.critic_current_mult[fidx] = self.critic_current_mult[fidx] / 10\n",
    "                    elif factor > 10:\n",
    "                        self.critic_current_mult[fidx] = self.critic_current_mult[fidx] / 2\n",
    "                    elif factor < .01:\n",
    "                        self.critic_current_mult[fidx] = self.critic_current_mult[fidx] * 10\n",
    "                    elif factor < .1:\n",
    "                        self.critic_current_mult[fidx] = self.critic_current_mult[fidx] * 2\n",
    "                print(list(zip(\n",
    "                    self.critic_loss_names, cur_grad_norms, target, self.critic_current_mult)))\n",
    "    if ep % printfreq == 0:\n",
    "        print(' ep, ', ep, ' avg frames',np.mean(globalframes[-20:]))\n",
    "        print('abs action',np.abs(ah)[-1,0,:].shape, np.abs(ah)[-1,0,:].mean())\n",
    "        print('max reward',np.max(rh[-10:,10:]))\n",
    "    if ep % 10000 == 0:\n",
    "        clear_output()\n",
    "    if ep % 100 == 0:\n",
    "        ysmoothed = gaussian_filter1d(globalframes, sigma=4)\n",
    "        plt.plot(ysmoothed)\n",
    "        plt.show()\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(1):\n",
    "#     feed_dict = train(actor = True, value = True, n_steps = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploit = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 34.0  frames 17\n",
      "saved at epoch 100\n",
      "saved at epoch 200\n",
      "[('a_loss_critic', 0.37051138, 30.0, 2.0), ('a_loss_model', 9.499673e-06, 1.0, 10.0), ('a_loss_secondaction', 1.933286e-08, 0.1, 10.0), ('areg', 4.301248e-08, 1e-06, 2.0), ('aregmeanbyaction', 7.708643e-06, 0.1, 10.0), ('actstdpenalty', 2.590824e-12, 0.01, 10.0), ('a_mse', 0.23405235, 0.01, 0.5), ('explorer_adv_loss', 0.00045247347, 10.0, 10.0), ('explorer_mdl_loss', 6.2871008e-15, 1.0, 10.0), ('ereg', 7.715327e-08, 1e-06, 2.0), ('e_mse', 6.3640147e-07, 0.01, 10.0)]\n",
      "aloss 0.65347505 closs 15.491903 vloss 3.4106243 mloss 307.61865\n",
      "[('v_loss_raw', 0.0015157583, 10.0, 10.0), ('m_loss_raw', 0.8054966, 10.0, 2.0), ('c_loss_raw', 0.004590514, 10.0, 10.0), ('grad_norm_c', 4.73444e-10, 0.001, 10.0), ('grad_norm_v', 5.090717e-13, 0.001, 10.0), ('grad_norm_m', 6.122054e-13, 0.001, 10.0), ('grad_m_1', 1.4928165e-19, 0.001, 10.0), ('grad_c_1', 2.3281032e-07, 0.001, 10.0), ('creg', 6.0376006e-09, 1e-08, 1.0), ('vreg', 1.0816551e-06, 1e-08, 0.1), ('mreg', 1.1017705e-08, 1e-08, 1.0)]\n",
      " ep,  220  avg frames 17.449257425742577\n",
      "abs action (1,) 1.5135771036148071\n",
      "max reward 2.0\n",
      "[('a_loss_critic', 117.43908, 30.0, 2.0), ('a_loss_model', 0.030280104, 1.0, 20.0), ('a_loss_secondaction', 1.5560205e-07, 0.1, 100.0), ('areg', 3.104278e-07, 1e-06, 2.0), ('aregmeanbyaction', 0.0010993184, 0.1, 20.0), ('actstdpenalty', 1.7947968e-09, 0.01, 100.0), ('a_mse', 14.353443, 0.01, 0.05), ('explorer_adv_loss', 0.56208456, 10.0, 20.0), ('explorer_mdl_loss', 8.916054e-12, 1.0, 100.0), ('ereg', 7.089653e-07, 1e-06, 2.0), ('e_mse', 0.090255134, 0.01, 10.0)]\n",
      "aloss -1487.5803 closs 126.76929 vloss 35.56813 mloss 601.8186\n",
      "[('v_loss_raw', 0.0898803, 10.0, 100.0), ('m_loss_raw', 3.7890716, 10.0, 2.0), ('c_loss_raw', 0.38184443, 10.0, 20.0), ('grad_norm_c', 2.1923891e-07, 0.001, 100.0), ('grad_norm_v', 1.9678395e-10, 0.001, 100.0), ('grad_norm_m', 2.0928236e-10, 0.001, 100.0), ('grad_m_1', 1.4834446e-12, 0.001, 100.0), ('grad_c_1', 0.011385218, 0.001, 5.0), ('creg', 2.798662e-08, 1e-08, 1.0), ('vreg', 4.7217355e-08, 1e-08, 0.1), ('mreg', 1.6767597e-08, 1e-08, 1.0)]\n",
      " ep,  240  avg frames 12.45\n",
      "abs action (1,) 2.50327730178833\n",
      "max reward 2.0\n",
      "[('a_loss_critic', 105.16128, 30.0, 2.0), ('a_loss_model', 0.08988122, 1.0, 40.0), ('a_loss_secondaction', 0.00017516404, 0.1, 1000.0), ('areg', 1.3662167e-06, 1e-06, 2.0), ('aregmeanbyaction', 0.0045666527, 0.1, 40.0), ('actstdpenalty', 2.4633164e-09, 0.01, 1000.0), ('a_mse', 73.516045, 0.01, 0.005), ('explorer_adv_loss', 1038.8978, 10.0, 2.0), ('explorer_mdl_loss', 1.5203171e-06, 1.0, 1000.0), ('ereg', 1.7254812e-06, 1e-06, 2.0), ('e_mse', 17.215235, 0.01, 1.0)]\n",
      "aloss -3061.791 closs 200.47746 vloss 613.94147 mloss 668.9172\n",
      "[('v_loss_raw', 23.581682, 10.0, 100.0), ('m_loss_raw', 25.604364, 10.0, 2.0), ('c_loss_raw', 1.286271, 10.0, 20.0), ('grad_norm_c', 9.108318e-05, 0.001, 200.0), ('grad_norm_v', 1.1141249e-06, 0.001, 1000.0), ('grad_norm_m', 3.8357663e-07, 0.001, 1000.0), ('grad_m_1', 2.0569532e-05, 0.001, 200.0), ('grad_c_1', 8.7515, 0.001, 0.5), ('creg', 7.296862e-08, 1e-08, 1.0), ('vreg', 1.2397793e-07, 1e-08, 0.05), ('mreg', 2.8965133e-08, 1e-08, 1.0)]\n",
      " ep,  260  avg frames 12.0\n",
      "abs action (1,) 5.213169574737549\n",
      "max reward 2.0\n",
      "[('a_loss_critic', 32.541103, 30.0, 2.0), ('a_loss_model', 0.27213582, 1.0, 40.0), ('a_loss_secondaction', 0.0009480696, 0.1, 10000.0), ('areg', 2.472495e-06, 1e-06, 2.0), ('aregmeanbyaction', 0.02096259, 0.1, 40.0), ('actstdpenalty', 3.2634826e-08, 0.01, 10000.0), ('a_mse', 40.13247, 0.01, 0.00049999997), ('explorer_adv_loss', 135.84921, 10.0, 1.0), ('explorer_mdl_loss', 0.014968099, 1.0, 2000.0), ('ereg', 3.089562e-06, 1e-06, 2.0), ('e_mse', 2.6998475, 0.01, 0.1)]\n",
      "aloss -3176.729 closs 186.1152 vloss 307.71994 mloss 670.95966\n",
      "[('v_loss_raw', 3.3393958, 10.0, 100.0), ('m_loss_raw', 125.78694, 10.0, 1.0), ('c_loss_raw', 5.861012, 10.0, 20.0), ('grad_norm_c', 0.0003866775, 0.001, 200.0), ('grad_norm_v', 0.010429365, 0.001, 500.0), ('grad_norm_m', 0.00014198908, 0.001, 1000.0), ('grad_m_1', 0.055294514, 0.001, 100.0), ('grad_c_1', 0.13989054, 0.001, 0.05), ('creg', 1.1854599e-07, 1e-08, 0.5), ('vreg', 5.1415583e-08, 1e-08, 0.05), ('mreg', 4.0498318e-08, 1e-08, 1.0)]\n",
      " ep,  280  avg frames 13.3\n",
      "abs action (1,) 6.742617130279541\n",
      "max reward 2.0\n",
      "saved at epoch 300\n",
      "[('a_loss_critic', 192.7401, 30.0, 2.0), ('a_loss_model', 0.19737737, 1.0, 40.0), ('a_loss_secondaction', 4.52178, 0.1, 5000.0), ('areg', 3.1279108e-06, 1e-06, 2.0), ('aregmeanbyaction', 0.02386839, 0.1, 40.0), ('actstdpenalty', 4.8739894e-06, 0.01, 100000.0), ('a_mse', 68.65792, 0.01, 4.9999995e-05), ('explorer_adv_loss', 1999.5092, 10.0, 0.1), ('explorer_mdl_loss', 22.488995, 1.0, 1000.0), ('ereg', 4.888298e-06, 1e-06, 2.0), ('e_mse', 2.5372155, 0.01, 0.01)]\n",
      "aloss -4458.098 closs 157.44801 vloss 392.37817 mloss 328.69522\n",
      "[('v_loss_raw', 85.56355, 10.0, 100.0), ('m_loss_raw', 73.38935, 10.0, 1.0), ('c_loss_raw', 10.726208, 10.0, 20.0), ('grad_norm_c', 0.0004703004, 0.001, 200.0), ('grad_norm_v', 0.53632295, 0.001, 50.0), ('grad_norm_m', 0.0004963733, 0.001, 1000.0), ('grad_m_1', 0.007425416, 0.001, 100.0), ('grad_c_1', 0.032641478, 0.001, 0.025), ('creg', 3.6075956e-08, 1e-08, 0.5), ('vreg', 8.5742506e-08, 1e-08, 0.05), ('mreg', 4.710486e-08, 1e-08, 1.0)]\n",
      " ep,  300  avg frames 12.85\n",
      "abs action (1,) 8.555004119873047\n",
      "max reward 2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a_loss_critic', 182.45366, 30.0, 2.0), ('a_loss_model', 0.048357476, 1.0, 80.0), ('a_loss_secondaction', 0.39145353, 0.1, 5000.0), ('areg', 3.251719e-06, 1e-06, 2.0), ('aregmeanbyaction', 0.02657391, 0.1, 40.0), ('actstdpenalty', 0.0036552045, 0.01, 100000.0), ('a_mse', 199.60071, 0.01, 4.9999994e-06), ('explorer_adv_loss', 1036.5724, 10.0, 0.01), ('explorer_mdl_loss', 550.14825, 1.0, 100.0), ('ereg', 7.32907e-06, 1e-06, 2.0), ('e_mse', 6.752416, 0.01, 0.0009999999)]\n",
      "aloss -6164.607 closs 143.61543 vloss 446.5122 mloss 321.6187\n",
      "[('v_loss_raw', 4.2247124, 10.0, 100.0), ('m_loss_raw', 267.69846, 10.0, 0.5), ('c_loss_raw', 53.599392, 10.0, 20.0), ('grad_norm_c', 0.0011557936, 0.001, 200.0), ('grad_norm_v', 0.00018098216, 0.001, 50.0), ('grad_norm_m', 0.0007211275, 0.001, 1000.0), ('grad_m_1', 0.12853616, 0.001, 10.0), ('grad_c_1', 1.102547, 0.001, 0.0025), ('creg', 4.129173e-08, 1e-08, 0.5), ('vreg', 1.2166896e-07, 1e-08, 0.025), ('mreg', 5.42179e-08, 1e-08, 1.0)]\n",
      " ep,  320  avg frames 12.6\n",
      "abs action (1,) 10.789902687072754\n",
      "max reward 2.0\n",
      "[('a_loss_critic', 205.08098, 30.0, 2.0), ('a_loss_model', 0.16599844, 1.0, 80.0), ('a_loss_secondaction', 356.0303, 0.1, 500.0), ('areg', 2.1303426e-06, 1e-06, 2.0), ('aregmeanbyaction', 0.030260613, 0.1, 40.0), ('actstdpenalty', 30584.154, 0.01, 10000.0), ('a_mse', 128.38918, 0.01, 4.9999994e-07), ('explorer_adv_loss', 24.504929, 10.0, 0.01), ('explorer_mdl_loss', 291.64072, 1.0, 10.0), ('ereg', 1.0404162e-05, 1e-06, 1.0), ('e_mse', 0.102015786, 0.01, 0.00049999997)]\n",
      "aloss -6404.8354 closs 172.21986 vloss 401.31577 mloss 155.82925\n",
      "[('v_loss_raw', 14.830948, 10.0, 100.0), ('m_loss_raw', 307.62863, 10.0, 0.25), ('c_loss_raw', 42.53513, 10.0, 20.0), ('grad_norm_c', 0.0006751748, 0.001, 200.0), ('grad_norm_v', 5.310509, 0.001, 5.0), ('grad_norm_m', 0.0013007824, 0.001, 1000.0), ('grad_m_1', 0.00565106, 0.001, 10.0), ('grad_c_1', 0.0012810688, 0.001, 0.0025), ('creg', 4.28814e-08, 1e-08, 0.5), ('vreg', 3.5764202e-08, 1e-08, 0.025), ('mreg', 6.1181936e-08, 1e-08, 1.0)]\n",
      " ep,  340  avg frames 12.95\n",
      "abs action (1,) 11.639540672302246\n",
      "max reward 2.0\n",
      "[('a_loss_critic', 132.76057, 30.0, 2.0), ('a_loss_model', 0.09812019, 1.0, 160.0), ('a_loss_secondaction', 0.005776042, 0.1, 1000.0), ('areg', 1.7153728e-07, 1e-06, 2.0), ('aregmeanbyaction', 0.017926574, 0.1, 40.0), ('actstdpenalty', 8908.177, 0.01, 1000.0), ('a_mse', 26863.564, 0.01, 4.9999993e-08), ('explorer_adv_loss', 89136.02, 10.0, 0.0009999999), ('explorer_mdl_loss', 1.5163692, 1.0, 10.0), ('ereg', 3.5162338e-06, 1e-06, 1.0), ('e_mse', 27.133347, 0.01, 4.9999995e-05)]\n",
      "aloss -14258.607 closs 293.3867 vloss 5397.7773 mloss 64.57444\n",
      "[('v_loss_raw', 147.68773, 10.0, 50.0), ('m_loss_raw', 13.749951, 10.0, 0.25), ('c_loss_raw', 30.60196, 10.0, 20.0), ('grad_norm_c', 0.0009271085, 0.001, 200.0), ('grad_norm_v', 0.016410993, 0.001, 2.5), ('grad_norm_m', 0.00041749224, 0.001, 1000.0), ('grad_m_1', 0.0006218859, 0.001, 10.0), ('grad_c_1', 0.00050412095, 0.001, 0.0025), ('creg', 4.285297e-08, 1e-08, 0.5), ('vreg', 4.796447e-08, 1e-08, 0.025), ('mreg', 6.6893136e-08, 1e-08, 1.0)]\n",
      " ep,  360  avg frames 26.15\n",
      "abs action (1,) 12.955092430114746\n",
      "max reward 2.0\n",
      "[('a_loss_critic', 74.77615, 30.0, 2.0), ('a_loss_model', 0.24509513, 1.0, 160.0), ('a_loss_secondaction', 0.0011142438, 0.1, 2000.0), ('areg', 8.43083e-07, 1e-06, 2.0), ('aregmeanbyaction', 0.009684208, 0.1, 80.0), ('actstdpenalty', 492.77866, 0.01, 100.0), ('a_mse', 902.9495, 0.01, 4.9999995e-09), ('explorer_adv_loss', 0.25243053, 10.0, 0.0019999999), ('explorer_mdl_loss', 2.3534186, 1.0, 10.0), ('ereg', 4.5660254e-06, 1e-06, 1.0), ('e_mse', 0.00045565376, 0.01, 9.999999e-05)]\n",
      "aloss -8040.6875 closs 280.70856 vloss 6975.3467 mloss 59.1513\n",
      "[('v_loss_raw', 172.09819, 10.0, 25.0), ('m_loss_raw', 2.177434, 10.0, 0.25), ('c_loss_raw', 13.813816, 10.0, 20.0), ('grad_norm_c', 0.00028768883, 0.001, 200.0), ('grad_norm_v', 0.017401557, 0.001, 1.25), ('grad_norm_m', 0.0004970392, 0.001, 1000.0), ('grad_m_1', 0.07407008, 0.001, 5.0), ('grad_c_1', 7.5133215e-07, 0.001, 0.024999999), ('creg', 5.1307737e-08, 1e-08, 0.5), ('vreg', 6.3121334e-08, 1e-08, 0.025), ('mreg', 7.739159e-08, 1e-08, 1.0)]\n",
      " ep,  380  avg frames 29.15\n",
      "abs action (1,) 11.950498580932617\n",
      "max reward 2.0\n",
      "saved at epoch 400\n",
      "[('a_loss_critic', 203.16939, 30.0, 2.0), ('a_loss_model', 0.036109183, 1.0, 320.0), ('a_loss_secondaction', 0.008857399, 0.1, 4000.0), ('areg', 7.0716214e-07, 1e-06, 2.0), ('aregmeanbyaction', 0.02226893, 0.1, 80.0), ('actstdpenalty', 13.763675, 0.01, 10.0), ('a_mse', 200.63301, 0.01, 4.9999993e-10), ('explorer_adv_loss', 5.221019, 10.0, 0.0019999999), ('explorer_mdl_loss', 14.47069, 1.0, 5.0), ('ereg', 5.742245e-06, 1e-06, 1.0), ('e_mse', 0.8127244, 0.01, 4.9999995e-05)]\n",
      "aloss -4872.916 closs 290.18604 vloss 6233.946 mloss 54.034615\n",
      "[('v_loss_raw', 103.82869, 10.0, 12.5), ('m_loss_raw', 29.046465, 10.0, 0.25), ('c_loss_raw', 462.62155, 10.0, 10.0), ('grad_norm_c', 0.0010986296, 0.001, 200.0), ('grad_norm_v', 4.3461363e-08, 0.001, 12.5), ('grad_norm_m', 0.00035884976, 0.001, 1000.0), ('grad_m_1', 0.002429902, 0.001, 5.0), ('grad_c_1', 0.014942565, 0.001, 0.012499999), ('creg', 5.6789748e-08, 1e-08, 0.5), ('vreg', 8.1758245e-08, 1e-08, 0.025), ('mreg', 8.354421e-08, 1e-08, 1.0)]\n",
      " ep,  400  avg frames 29.45\n",
      "abs action (1,) 13.692980766296387\n",
      "max reward 2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a_loss_critic', 116.08364, 30.0, 2.0), ('a_loss_model', 0.40756217, 1.0, 320.0), ('a_loss_secondaction', 70.39311, 0.1, 400.0), ('areg', 5.660297e-07, 1e-06, 2.0), ('aregmeanbyaction', 0.020360384, 0.1, 80.0), ('actstdpenalty', 0.19188058, 0.01, 5.0), ('a_mse', 77.64372, 0.01, 4.9999994e-11), ('explorer_adv_loss', 23.891638, 10.0, 0.0019999999), ('explorer_mdl_loss', 201.6431, 1.0, 0.5), ('ereg', 7.0404235e-06, 1e-06, 1.0), ('e_mse', 0.24200237, 0.01, 2.4999998e-05)]\n",
      "aloss -6176.7954 closs 148.5527 vloss 2842.8325 mloss 60.37535\n",
      "[('v_loss_raw', 15.455544, 10.0, 12.5), ('m_loss_raw', 89.96409, 10.0, 0.25), ('c_loss_raw', 15.753632, 10.0, 10.0), ('grad_norm_c', 0.00037896345, 0.001, 200.0), ('grad_norm_v', 0.0032138543, 0.001, 12.5), ('grad_norm_m', 0.0002337742, 0.001, 1000.0), ('grad_m_1', 0.0006148161, 0.001, 5.0), ('grad_c_1', 0.015102922, 0.001, 0.0062499996), ('creg', 6.078074e-08, 1e-08, 0.5), ('vreg', 1.0039934e-07, 1e-08, 0.0125), ('mreg', 8.9616975e-08, 1e-08, 1.0)]\n",
      " ep,  420  avg frames 29.7\n",
      "abs action (1,) 14.465149879455566\n",
      "max reward 2.0\n",
      "[('a_loss_critic', 107.0137, 30.0, 2.0), ('a_loss_model', 0.07048113, 1.0, 640.0), ('a_loss_secondaction', 0.0003819986, 0.1, 4000.0), ('areg', 5.211805e-07, 1e-06, 2.0), ('aregmeanbyaction', 0.011106244, 0.1, 80.0), ('actstdpenalty', 0.09454132, 0.01, 5.0), ('a_mse', 92.63657, 0.01, 4.9999995e-12), ('explorer_adv_loss', 55.43145, 10.0, 0.0019999999), ('explorer_mdl_loss', 1.7810158, 1.0, 0.5), ('ereg', 8.449705e-06, 1e-06, 1.0), ('e_mse', 0.57755077, 0.01, 1.2499999e-05)]\n",
      "aloss -7071.396 closs 148.19144 vloss 2866.1929 mloss 51.327663\n",
      "[('v_loss_raw', 10.899038, 10.0, 12.5), ('m_loss_raw', 29.310717, 10.0, 0.25), ('c_loss_raw', 9.802429, 10.0, 10.0), ('grad_norm_c', 0.00031545546, 0.001, 200.0), ('grad_norm_v', 0.0013053789, 0.001, 12.5), ('grad_norm_m', 0.00033250407, 0.001, 1000.0), ('grad_m_1', 0.0085489685, 0.001, 5.0), ('grad_c_1', 0.00038329788, 0.001, 0.0062499996), ('creg', 6.6047825e-08, 1e-08, 0.5), ('vreg', 3.0079594e-08, 1e-08, 0.0125), ('mreg', 9.629422e-08, 1e-08, 1.0)]\n",
      " ep,  440  avg frames 23.4\n",
      "abs action (1,) 15.831117630004883\n",
      "max reward 2.0\n",
      "[('a_loss_critic', 144.25497, 30.0, 2.0), ('a_loss_model', 0.0741322, 1.0, 1280.0), ('a_loss_secondaction', 0.0756019, 0.1, 4000.0), ('areg', 5.339777e-07, 1e-06, 2.0), ('aregmeanbyaction', 0.005049295, 0.1, 160.0), ('actstdpenalty', 0.18072087, 0.01, 2.5), ('a_mse', 365.74377, 0.01, 4.9999994e-13), ('explorer_adv_loss', 407.36926, 10.0, 0.0009999999), ('explorer_mdl_loss', 5.912854, 1.0, 0.5), ('ereg', 9.967593e-06, 1e-06, 1.0), ('e_mse', 2.0552936, 0.01, 1.2499999e-06)]\n",
      "aloss -8944.158 closs 142.91867 vloss 4935.489 mloss 37.45483\n",
      "[('v_loss_raw', 30.359453, 10.0, 12.5), ('m_loss_raw', 40.284496, 10.0, 0.25), ('c_loss_raw', 134.75299, 10.0, 5.0), ('grad_norm_c', 0.0012361351, 0.001, 200.0), ('grad_norm_v', 5.7529387e-10, 0.001, 125.0), ('grad_norm_m', 8.493484e-05, 0.001, 2000.0), ('grad_m_1', 0.0029655932, 0.001, 5.0), ('grad_c_1', 0.032113254, 0.001, 0.0031249998), ('creg', 7.137532e-08, 1e-08, 0.5), ('vreg', 3.3264406e-08, 1e-08, 0.0125), ('mreg', 1.0426641e-07, 1e-08, 0.5)]\n",
      " ep,  460  avg frames 33.1\n",
      "abs action (1,) 17.25937843322754\n",
      "max reward 2.0\n",
      "[('a_loss_critic', 232.87212, 30.0, 2.0), ('a_loss_model', 0.1275535, 1.0, 1280.0), ('a_loss_secondaction', 0.08711759, 0.1, 4000.0), ('areg', 5.622067e-07, 1e-06, 2.0), ('aregmeanbyaction', 0.0041236184, 0.1, 320.0), ('actstdpenalty', 0.074724205, 0.01, 2.5), ('a_mse', 187.7978, 0.01, 4.9999996e-14), ('explorer_adv_loss', 53.955917, 10.0, 0.0009999999), ('explorer_mdl_loss', 0.015759578, 1.0, 1.0), ('ereg', 1.1588096e-05, 1e-06, 0.5), ('e_mse', 0.676826, 0.01, 6.249999e-07)]\n",
      "aloss -11438.627 closs 70.44857 vloss 3690.9836 mloss 36.308754\n",
      "[('v_loss_raw', 15.853411, 10.0, 12.5), ('m_loss_raw', 138.39781, 10.0, 0.125), ('c_loss_raw', 278.9648, 10.0, 2.5), ('grad_norm_c', 0.0041492893, 0.001, 200.0), ('grad_norm_v', 5.92383e-09, 0.001, 1250.0), ('grad_norm_m', 7.578206e-05, 0.001, 4000.0), ('grad_m_1', 3.887728e-07, 0.001, 50.0), ('grad_c_1', 0.400937, 0.001, 0.0003125), ('creg', 7.431325e-08, 1e-08, 0.5), ('vreg', 3.431695e-08, 1e-08, 0.0125), ('mreg', 2.8666731e-08, 1e-08, 0.5)]\n",
      " ep,  480  avg frames 27.3\n",
      "abs action (1,) 18.118406295776367\n",
      "max reward 2.0\n",
      "saved at epoch 500\n"
     ]
    }
   ],
   "source": [
    "if trained:\n",
    "    try:\n",
    "        saver.restore(sess, tffile)\n",
    "        with open(obj_fname, \"rb\") as f:\n",
    "            ah, sh, shraw, rh, rdecayedh, maskh, ep, globalframes, isexploit = pickle.load(f)\n",
    "        print('restored from save file')\n",
    "    except:\n",
    "        print('no save file detected')\n",
    "        trained = 0\n",
    "MAX_SEQ_LEN = 5000\n",
    "for ep in range(ep, 10000000):\n",
    "    if ep % 100 == 0 and trained and ep > 0:\n",
    "        save_path = saver.save(sess, tffile)\n",
    "        print('saved at epoch', ep)\n",
    "        with open(obj_fname,\"wb\") as f:\n",
    "            pickle.dump(\n",
    "                [ah[-NUM_KEEP:], sh[-NUM_KEEP:], shraw[-NUM_KEEP:],\n",
    "                 rh[-NUM_KEEP:], rdecayedh[-NUM_KEEP:], maskh[-NUM_KEEP:], ep, globalframes, isexploit[-NUM_KEEP:]\n",
    "                ], f)\n",
    "    trained = 1\n",
    "    ongoing = 1\n",
    "    \n",
    "    an, sn, snraw, rn, rdecayedn, maskn = [\n",
    "        np.zeros((0, i)) for i in [N_ACT, INPUT_UNITS, N_OBS, 1, 1, 1]]\n",
    "    frame = 0\n",
    "    score = 0\n",
    "    restart_delay = 5\n",
    "    obs = env.reset()\n",
    "    obsraw = obs\n",
    "    snraw = np.concatenate((snraw, obs.reshape(1, -1)), 0)\n",
    "    obs = np.concatenate((obs, np.zeros(N_ACT)))\n",
    "    obs = np.concatenate((obs, np.zeros_like(obs)))\n",
    "    obs_mat = np.concatenate((\n",
    "        obs[None,:],np.zeros((NUM_HISTORY-1, N_STATE))), 0)\n",
    "    rn = [0]\n",
    "    done_ctr = 0\n",
    "    sn = np.concatenate((sn, obs_mat.reshape(1, -1)), 0)\n",
    "    step_num = 0\n",
    "    step_shifted = -1\n",
    "    show_shift = 0\n",
    "    if ep <= INIT_LEN or exploit:\n",
    "        exploit = 0\n",
    "    else:\n",
    "        exploit = 1\n",
    "    if np.random.rand() > .5:\n",
    "        prob_random = PERCENT_CHOOSE_OPTIMAL#2#.95#1 - 1/np.sqrt(ep+1)\n",
    "    else:\n",
    "        prob_random = 2\n",
    "    while 1:\n",
    "        step_num += 1\n",
    "        if ep < INIT_LEN:\n",
    "            a = np.random.rand(N_ACT)\n",
    "        else:\n",
    "            a = pi.act(obs_mat.flatten(), exploit = exploit)\n",
    "            if np.random.rand() < 0.01:\n",
    "                a = np.random.randn(*a.shape)/10\n",
    "            if not exploit and np.random.rand() < .1:\n",
    "                a = np.random.randn(*a.shape)\n",
    "        an = np.concatenate((an, a[None,:]), 0)\n",
    "        snraw = np.concatenate((snraw, obsraw[None,:]), 0)\n",
    "        last_obs = obs\n",
    "#         last_obsraw = obsraw\n",
    "        obs, r, done, _ = env.step(a)\n",
    "        obsraw = obs\n",
    "        r = r + 1 * REWARD_MULT\n",
    "\n",
    "        obs_mat = accumulate_state(\n",
    "            obs, a, obs_mat, STATE_DECAY, style = 'np')\n",
    "        \n",
    "        rn.append(r)\n",
    "        sn = np.concatenate((sn, obs_mat.reshape(1, -1)), 0)\n",
    "        score += r\n",
    "        frame += 1\n",
    "        if ep > INIT_LEN:\n",
    "            still_open = env.render(\"human\")\n",
    "        else:\n",
    "            still_open = 1\n",
    "        if done:\n",
    "            done_ctr += 1\n",
    "            if done_ctr > 3:\n",
    "                if ep % MAX_SEQ_LEN == 0:\n",
    "                    print('score', score, ' frames', frame)\n",
    "                break\n",
    "        if still_open==False:\n",
    "            crashhere\n",
    "        if not done: continue\n",
    "        if restart_delay==0:\n",
    "            print(\"score=%0.2f in %i frames\" % (score, frame))\n",
    "            if still_open!=True:      # not True in multiplayer or non-Roboschool \n",
    "                break\n",
    "            restart_delay = 2000*2  # 2 sec at 60 fps\n",
    "        restart_delay -= 1\n",
    "        if restart_delay==0: \n",
    "            break\n",
    "    a = pi.act(obs_mat.flatten())\n",
    "    an = np.concatenate((an, a[None,:]), 0)\n",
    "    localframes.append(frame)\n",
    "    rn = np.array(rn)\n",
    "    rn[-1] = rn[-1] - 20 * REWARD_MULT\n",
    "    rewards = [0]\n",
    "    for ir in rn[::-1]:\n",
    "        rewards.append(rewards[-1] * GAMMA + ir)\n",
    "    rdecayedn = np.array(rewards)[:0:-1]\n",
    "    lenrdec = len(rdecayedn)\n",
    "#     rdecayedn = rdecayedn + lenrdec\n",
    "#     rdecayedn = rdecayedn - np.arange(lenrdec) * 1.8\n",
    "    maskn = np.ones_like(rn)\n",
    "    if step_shifted > -1:\n",
    "        if step_shifted == 0:\n",
    "            raise ValueError('step shifted not allowed 0')\n",
    "        maskn[:step_shifted - 1] = 0\n",
    "    if ep == 0:\n",
    "        ah, sh, shraw, rh, rdecayedh, maskh = [\n",
    "            np.expand_dims(v, 0) for v in [an, sn, snraw, rn,rdecayedn, maskn]]\n",
    "        isexploit = [exploit]\n",
    "    else:\n",
    "        def get_updated_h(h, n, third_dim):\n",
    "            hshape = h.shape[1]\n",
    "            nshape = n.shape[0]\n",
    "            if third_dim:\n",
    "                if hshape > nshape:\n",
    "                    n = np.concatenate((n, np.zeros((hshape - nshape, n.shape[-1]))), 0)\n",
    "                if nshape > hshape:\n",
    "                    h = np.concatenate((h, np.zeros((\n",
    "                        h.shape[0], nshape - hshape, h.shape[-1]))), 1)\n",
    "            else:\n",
    "                if hshape > nshape:\n",
    "                    n = np.concatenate((n, np.zeros((hshape - nshape))), 0)\n",
    "                if nshape > hshape:\n",
    "                    h = np.concatenate((h, np.zeros((h.shape[0], nshape - hshape))), 1)\n",
    "            h = np.concatenate((h, np.expand_dims(n, 0)), 0)\n",
    "            return h\n",
    "            \n",
    "        ah, sh, shraw = [get_updated_h(h, n, 1) for  h, n in zip(\n",
    "            [ah, sh, shraw], [an, sn, snraw])]\n",
    "        \n",
    "        rh, rdecayedh, maskh = [\n",
    "            get_updated_h(h, n, 0) for h, n in zip(\n",
    "                [rh, rdecayedh, maskh], [rn, rdecayedn, maskn])]\n",
    "        isexploit.append(exploit)\n",
    "    if ep % 1 == 0 and ep > INIT_LEN:\n",
    "        ah, sh, shraw, rh,rdecayedh, maskh, isexploit = [\n",
    "            v[-NUM_KEEP:] for v in [ah, sh, shraw, rh,rdecayedh, maskh, isexploit]]\n",
    "        globalframes.append(np.mean(localframes))\n",
    "        localframes = []\n",
    "        batch_size = 32\n",
    "        if ep < batch_size:\n",
    "            batch_size = ep\n",
    "        num_hist = ah.shape[0]\n",
    "        if ep == INIT_LEN + 1 or sum(isexploit) < 2:\n",
    "            train(actor = False, n_steps = N_PRETRAIN, forced_hist=0)\n",
    "            #train(value = False, n_steps = 20, forced_hist=0)\n",
    "        else:\n",
    "            feed_dict = train(actor = True, value = True, n_steps = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        self.v_loss_raw = tf.reduce_mean(tf.square(\n",
    "            self.returnsdecayed - self.state_value_estimate) * self.mask * self.is_exploit2d)\n",
    "        self.v_loss =  self.v_loss_raw + self.vreg\n",
    "        \n",
    "        self.m_loss_raw = tf.reduce_mean(tf.square(\n",
    "            self.model_estimator.output[:,:-1] - self.statesraw_expanded[:,1:]\n",
    "        ) * self.maskexpanded[:,:-1]) * 100\n",
    "        self.m_loss = self.m_loss_raw + self.mreg\n",
    "        \n",
    "        self.c_loss_raw = tf.reduce_mean(tf.square(\n",
    "            self.advantage_estimate[:,:-1] - self.advantage) * self.mask[:,:-1])\n",
    "        self.c_loss =  self.c_loss_raw + self.creg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            self.a_grads = [\n",
    "                get_grad_norm(self.actor_opt, l) for l in [\n",
    "                self.a_loss_minimize, self.a_loss_raw, self.a_loss_critic,self.a_loss_model,\n",
    "                self.a_loss_secondaction,\n",
    "                self.areg, self.aregmeanbyaction, self.actstdpenalty\n",
    "            ]]\n",
    "            self.v_grads = [get_grad_norm(self.value_opt, l) for l in [\n",
    "                self.v_loss_minimize, self.v_loss_raw, \n",
    "                self.vreg, self.grad_norm_v\n",
    "            ]]\n",
    "            self.c_grads = [get_grad_norm(self.critic_opt, l) for l in [\n",
    "                self.c_loss_minimize, self.c_loss_raw, \n",
    "                self.creg, self.grad_norm_c, self.grad_c_1\n",
    "\n",
    "            ]]\n",
    "            self.m_grads = [get_grad_norm(self.critic_opt, l) for l in [\n",
    "                self.m_loss_minimize, self.m_loss_raw, \n",
    "                self.mreg, self.grad_norm_m, self.grad_m_1\n",
    "            ]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
