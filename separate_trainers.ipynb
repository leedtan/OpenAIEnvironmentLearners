{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path, gym\n",
    "import numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import roboschool\n",
    "import pdb\n",
    "from IPython.display import clear_output, display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "GAMMA = .97\n",
    "from functools import partial\n",
    "try:\n",
    "    env.close()\n",
    "except:\n",
    "    pass\n",
    "if 0:\n",
    "    envname = \"RoboschoolInvertedPendulum-v1\"\n",
    "    SIZE_MULT = 1\n",
    "    REWARD_MULT = 1\n",
    "    N_LAYERS = 10\n",
    "    NUM_HISTORY = N_HISTORY = 2\n",
    "else:\n",
    "    envname = \"RoboschoolHumanoidFlagrun-v1\"\n",
    "    SIZE_MULT = 4\n",
    "    REWARD_MULT = 4\n",
    "    N_LAYERS = 10\n",
    "    NUM_HISTORY = N_HISTORY = 3\n",
    "N_EPISODES = 100\n",
    "N_STEPS = 100\n",
    "BATCH_SIZE = 16\n",
    "DROP_RATE = .1\n",
    "INIT_LEN = 100\n",
    "NUM_KEEP = 100\n",
    "PERCENT_CHOOSE_OPTIMAL = 2\n",
    "env = gym.make(envname)\n",
    "N_OBS, N_ACT = [v.shape[0] for v in [env.observation_space, env.action_space]]\n",
    "N_STATE = (N_OBS + N_ACT) * 2\n",
    "REWARD_IN_STATE = 0\n",
    "if REWARD_IN_STATE:\n",
    "    N_STATE += 2\n",
    "INPUT_UNITS = N_STATE * NUM_HISTORY\n",
    "STATE_DECAY = .7\n",
    "TESTING_GRAD_NORMS = 0\n",
    "ADV_ENABLED = 0\n",
    "STORED_MODELS = {}\n",
    "FCNS = {'np':{\n",
    "    'concat':np.concatenate,\n",
    "    'reshape':np.reshape,\n",
    "    'expand':np.expand_dims\n",
    "},'tf':{\n",
    "    'concat':tf.concat,\n",
    "    'reshape':tf.reshape,\n",
    "    'expand':tf.expand_dims\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb3598bfcc0>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(-100, 100, .01)\n",
    "\n",
    "y = np.log(np.abs(x)+1) * np.sign(x)\n",
    "\n",
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adv(v, mag = 1, adv_type = 0):\n",
    "    size= np.sqrt(np.prod(v.shape))\n",
    "    if adv_type == 0:\n",
    "        return mag * v / np.abs(v).sum() * size * 3\n",
    "    elif adv_type == 1:\n",
    "        return mag * np.sign(v).astype(float) * .001\n",
    "    elif adv_type == 2:\n",
    "        sign_v = np.sign(v)\n",
    "        v = np.sqrt(np.abs(v))\n",
    "        v = v / v.sum() * size\n",
    "        return mag * v * sign_v * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_clipped_optimizer(opt_fcn,\n",
    "                            loss,\n",
    "                            clip_norm=.1,\n",
    "                            clip_single=.03,\n",
    "                            clip_global_norm=False,\n",
    "                            var_list=None):\n",
    "    if var_list is None:\n",
    "        gvs = opt_fcn.compute_gradients(loss)\n",
    "    else:\n",
    "        gvs = opt_fcn.compute_gradients(loss, var_list = var_list)\n",
    "        \n",
    "\n",
    "    if clip_global_norm:\n",
    "        gs, vs = zip(*[(g, v) for g, v in gvs if g is not None])\n",
    "        capped_gs, grad_norm_total = tf.clip_by_global_norm([g for g in gs],clip_norm)\n",
    "        capped_gvs = list(zip(capped_gs, vs))\n",
    "    else:\n",
    "        grad_norm_total = tf.sqrt(\n",
    "                tf.reduce_sum([\n",
    "                        tf.reduce_sum(tf.square(grad)) for grad, var in gvs\n",
    "                        if grad is not None\n",
    "                ]))\n",
    "        capped_gvs = [(tf.clip_by_value(grad, -1 * clip_single, clip_single), var)\n",
    "                                    for grad, var in gvs if grad is not None]\n",
    "        capped_gvs = [(tf.clip_by_norm(grad, clip_norm), var)\n",
    "                                    for grad, var in capped_gvs if grad is not None]\n",
    "\n",
    "    optimizer = opt_fcn.apply_gradients(capped_gvs)\n",
    "\n",
    "    return optimizer, grad_norm_total\n",
    "\n",
    "class MLP:\n",
    "    def __init__(self,\n",
    "                x, lshapes, output_units, namebase, tanh_out = False, sigmoid = False, squeeze = True,\n",
    "                reuse = False,residual = None, use_bias = True, is_train = True\n",
    "                ):\n",
    "        x = x * 10 - 5\n",
    "        self.namebase = namebase\n",
    "        self.reuse = reuse\n",
    "        self.lidx = 0\n",
    "        name_fcn = self.get_name\n",
    "        trainable = True\n",
    "        self.h = [tf.nn.crelu(tf.layers.batch_normalization(tf.layers.dense(\n",
    "            x, lshapes[0], name=self.get_name(), reuse = self.reuse\n",
    "        ), training = is_train,momentum = 0.9, trainable = trainable))]\n",
    "        h2 = self.h[-1]\n",
    "        for size in lshapes:\n",
    "            new_layer = self.h[-1]\n",
    "            new_layer = tf.layers.dense(new_layer, size, name = name_fcn(), reuse = reuse)\n",
    "            new_layer = tf.layers.batch_normalization(new_layer, training = is_train,\n",
    "                    momentum = 0.9, name = name_fcn(), reuse = reuse, trainable = trainable)\n",
    "            new_layer = tf.nn.crelu(new_layer)\n",
    "            new_layer = tf.layers.dense(new_layer, size, name = name_fcn(), reuse = reuse)\n",
    "            new_layer = tf.layers.batch_normalization(new_layer, training = is_train,\n",
    "                    momentum = 0.9, name = name_fcn(), reuse = reuse, trainable = trainable)\n",
    "            new_layer = tf.nn.crelu(new_layer)\n",
    "            new_layer = tf.layers.dense(new_layer, size * 2, name = name_fcn(), reuse = reuse)\n",
    "            new_layer = tf.layers.batch_normalization(new_layer, training = is_train,\n",
    "                    momentum = 0.9, name = name_fcn(), reuse = reuse, trainable = trainable)\n",
    "            \n",
    "            new_layer = new_layer + self.h[-1]\n",
    "            self.h.append(tf.nn.leaky_relu(new_layer, alpha = 0.3))\n",
    "            \n",
    "            h2 = tf.concat(self.h, -1)#self.h[-1]\n",
    "        output = tf.layers.dense(tf.nn.crelu(tf.layers.dense(\n",
    "            h2, lshapes[0]//2, name = name_fcn(), reuse = self.reuse)), \n",
    "                                  output_units, name=name_fcn(), reuse = self.reuse,\n",
    "            bias_initializer = tf.keras.initializers.zeros())\n",
    "#         output = tf.layers.dense(\n",
    "#             h2, output_units, name=name_fcn(), reuse = self.reuse,\n",
    "#             bias_initializer = tf.keras.initializers.zeros())\n",
    "        if output_units == 1 and squeeze:\n",
    "            output = tf.squeeze(output, -1)\n",
    "        self.raw_output = output\n",
    "        if residual is not None:\n",
    "            self.raw_output = self.raw_output + residual\n",
    "        if tanh_out:\n",
    "            self.output = leaky_tanh(self.raw_output)\n",
    "        elif sigmoid:\n",
    "            self.output = tf.nn.sigmoid(self.raw_output) * 2. - 0.5\n",
    "        else:\n",
    "            self.output = self.raw_output\n",
    "            \n",
    "#         h3 = tf.stack(self.h, 0)\n",
    "        output = [tf.layers.dense(tf.nn.leaky_relu(tf.layers.dense(\n",
    "            h3, lshapes[0]//2, name = name_fcn(), reuse = self.reuse)), \n",
    "                                  output_units, name=name_fcn(), reuse = self.reuse,\n",
    "            bias_initializer = tf.keras.initializers.zeros()) for h3 in self.h[:-1]]\n",
    "        output = tf.stack(output, 0)\n",
    "        if output_units == 1 and squeeze:\n",
    "            output = tf.squeeze(output, -1)\n",
    "        if tanh_out:\n",
    "            output = leaky_tanh(output)\n",
    "        elif sigmoid:\n",
    "            output = tf.nn.sigmoid(output) * 2. - 0.5\n",
    "        else:\n",
    "            output = output\n",
    "        self.hidden_output = output\n",
    "    def get_name(self):\n",
    "        self.lidx = self.lidx + 1\n",
    "        return self.namebase + str(self.lidx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_maxmin(x):\n",
    "    y = x.copy()\n",
    "    y[maskh==0] = np.nan\n",
    "    amin, amax = np.nanmin(y, (0, 1)), np.nanmax(y, (0,1))\n",
    "    return amin, amax\n",
    "\n",
    "def make_state(state, action, style = 'np'):\n",
    "    together = FCNS[style]['concat']((state, action), -1)\n",
    "    if style == 'tf':\n",
    "        return together\n",
    "#         expanded = FCNS[style]['expand'](\n",
    "#             together, 1)\n",
    "    else:\n",
    "        expanded = FCNS[style]['expand'](\n",
    "            together, 0)\n",
    "    return expanded\n",
    "    return FCNS[style]['reshape'](\n",
    "        together, (state.shape[0], -1, state.shape[-1] + action.shape[-1]))\n",
    "        \n",
    "    \n",
    "\n",
    "def accumulate_state(state, action, old_state, statedecay, style = 'np'):\n",
    "    new_state = make_state(state, action, style)\n",
    "    new_state_len = new_state.shape[-1]\n",
    "    if style == 'tf':\n",
    "        vel = new_state - old_state[:,:,0,:new_state_len]\n",
    "    else:\n",
    "        vel = new_state - old_state[0,:new_state_len]\n",
    "    new_state = FCNS[style]['concat']((new_state, vel), -1)\n",
    "    if style == 'tf':\n",
    "        return FCNS[style]['concat']((tf.expand_dims(new_state, 2), old_state[:,:,:-1,:]*statedecay), 2)\n",
    "    return FCNS[style]['concat']((new_state, old_state[:-1,:]*statedecay), 0)\n",
    "\n",
    "def leaky_tanh(x):\n",
    "    return tf.log(tf.abs(x)+1) * tf.sign(x)*.7\n",
    "    #return tf.nn.tanh(x*30)/10 + tf.nn.tanh(x*2)/2 + tf.nn.tanh(x/20) * 2 + x * 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_grad_norm(optimizer, loss, optname):\n",
    "    gvs = optimizer.compute_gradients(loss)\n",
    "    grad_norm = tf.reduce_mean(\n",
    "        [tf.reduce_mean(tf.square(grad)) for\n",
    "         grad, var in gvs if grad is not None and optname in var.name])\n",
    "    return grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-d2c8bc8b90ef>:45: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-4-d2c8bc8b90ef>:46: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "class PolicyLearner(object):\n",
    "    def __init__(self, ob_space, ac_space, take_weights_here=None, \n",
    "                 lshapes = [32 * SIZE_MULT] * N_LAYERS, config = None, \n",
    "                 lshapes_big = [64 * SIZE_MULT] * N_LAYERS,\n",
    "                reuse = False):\n",
    "        self.sess = tf.InteractiveSession(config=config)\n",
    "        self.returns = tf.placeholder(tf.float32, (None, None))\n",
    "        self.returnsdecayed = tf.placeholder(tf.float32, (None, None))\n",
    "        self.mask = tf.placeholder(tf.float32, (None, None))\n",
    "        self.lr = tf.placeholder_with_default(1e-3, (None))\n",
    "        self.statesraw = tf.placeholder(tf.float32, (None, None, N_OBS))\n",
    "        self.is_train = tf.placeholder_with_default(True, (None))\n",
    "        self.is_exploit = tf.placeholder(tf.float32, (None))\n",
    "        self.is_exploit2d = tf.expand_dims(self.is_exploit, -1)\n",
    "        self.is_exploit3d = tf.expand_dims(self.is_exploit2d, -1)\n",
    "        self.statesraw_expanded = tf.expand_dims(self.statesraw, -1)\n",
    "        self.maskexpanded = tf.expand_dims(self.mask, -1)\n",
    "        self.maskexpanded2 = tf.expand_dims(self.maskexpanded, -1)\n",
    "        self.obs = tf.placeholder(tf.float32, (None, None, INPUT_UNITS))\n",
    "        is_train = self.is_train\n",
    "        self.actor = MLP(\n",
    "            self.obs, lshapes_big, N_ACT, 'a_', squeeze = False, reuse = reuse,\n",
    "            tanh_out = True, is_train = is_train)\n",
    "        self.explorer = MLP(\n",
    "            self.obs, lshapes, N_ACT, 'e_', squeeze = False, reuse = reuse,\n",
    "            tanh_out = True, is_train = is_train)\n",
    "        self.actions = self.actor.output\n",
    "        self.explorer_actions = self.explorer.output\n",
    "        self.state_value_estimator = MLP(\n",
    "            self.statesraw, lshapes, 1, 'v_', reuse = reuse, sigmoid = True, is_train = is_train)\n",
    "        self.state_value_estimate = self.state_value_estimator.output\n",
    "        self.advantage = ((\n",
    "            self.state_value_estimate[:,1:] * GAMMA + self.returns[:,:-1]) -\n",
    "            self.state_value_estimate[:,:-1])\n",
    "        \n",
    "        \n",
    "        self.actions_for_critic = tf.nn.tanh(self.actions * 10) + self.actions\n",
    "        self.explorer_actions_for_critic = tf.nn.tanh(self.explorer_actions * 10) + self.explorer_actions\n",
    "        self.critic_input = tf.concat((self.obs, self.actions_for_critic), -1)\n",
    "        self.explorer_critic_input = tf.concat((self.obs, self.explorer_actions_for_critic), -1)\n",
    "        \n",
    "        \n",
    "        self.advantage_estimator = MLP(\n",
    "            self.critic_input, lshapes, 1, 'c_', reuse = reuse, is_train = is_train)\n",
    "        self.model_estimator = MLP(\n",
    "            self.critic_input, lshapes_big, N_OBS, 'm_', reuse = reuse,\n",
    "            sigmoid = True, is_train = is_train\n",
    "        )\n",
    "        self.explorer_advantage_estimator = MLP(\n",
    "            self.explorer_critic_input, lshapes, 1, 'c_', reuse = True, is_train = is_train)\n",
    "        self.explorer_model_estimator = MLP(\n",
    "            self.explorer_critic_input, lshapes_big, N_OBS, 'm_', reuse = True,\n",
    "            sigmoid = True, is_train = is_train\n",
    "        )\n",
    "        self.advantage_estimate = self.advantage_estimator.output\n",
    "        self.explorer_advantage_estimate = self.explorer_advantage_estimator.output\n",
    "        self.model_estimate = self.model_estimator.output\n",
    "        \n",
    "        self.loss_input = tf.concat((\n",
    "            self.critic_input, self.model_estimator.output, \n",
    "            tf.expand_dims(self.advantage_estimator.output, -1)), -1)\n",
    "        self.loss_estimator = MLP(\n",
    "            self.loss_input, lshapes, 2, 'l_', reuse = reuse, is_train = is_train)\n",
    "        \n",
    "        self.explorer_loss_input = tf.concat((\n",
    "            self.explorer_critic_input, self.explorer_model_estimator.output, \n",
    "            tf.expand_dims(self.explorer_advantage_estimator.output, -1)), -1)\n",
    "        self.explorer_loss_estimator = MLP(\n",
    "            self.explorer_loss_input, lshapes, 2, 'l_', reuse = True, is_train = is_train)\n",
    "        \n",
    "        self.future_value = MLP(\n",
    "            self.model_estimate, lshapes, 1, 'v_', reuse = True, sigmoid = True, is_train = is_train)\n",
    "        \n",
    "        self.t_vars = tf.trainable_variables()\n",
    "        self.a_vars = [var for var in self.t_vars if 'a_' in var.name]\n",
    "        self.v_vars = [var for var in self.t_vars if 'v_' in var.name]\n",
    "        self.c_vars = [var for var in self.t_vars if 'c_' in var.name]\n",
    "        self.e_vars = [var for var in self.t_vars if 'e_' in var.name]\n",
    "        self.m_vars = [var for var in self.t_vars if 'm_' in var.name]\n",
    "        self.l_vars = [var for var in self.t_vars if 'l_' in var.name]\n",
    "        \n",
    "        self.creg, self.areg, self.vreg, self.mreg, self.ereg = [\n",
    "            tf.reduce_mean([tf.reduce_mean(tf.square(v)) for v in optvars]) * 1e-8\n",
    "            for optvars in \n",
    "            [self.c_vars, self.a_vars, self.v_vars, self.m_vars, self.e_vars]]\n",
    "        \n",
    "        self.frac_not_masked = tf.reduce_mean(self.mask)\n",
    "        \n",
    "\n",
    "        self.model_state_estimate = self.model_estimator.output\n",
    "        \n",
    "        \n",
    "        self.a_loss_critic = -tf.reduce_sum(\n",
    "            self.advantage_estimator.output * self.mask)/self.frac_not_masked\n",
    "        self.a_loss_model = -tf.reduce_sum(\n",
    "            self.future_value.output * self.mask)/self.frac_not_masked\n",
    "        \n",
    "        self.v_loss_ind = tf.square(\n",
    "            self.returnsdecayed - self.state_value_estimate) * self.mask * self.is_exploit2d\n",
    "        self.v_loss_raw = tf.reduce_mean(self.v_loss_ind) / tf.reduce_mean(\n",
    "            self.mask * self.is_exploit2d) * 1e1\n",
    "        \n",
    "        self.m_loss_ind = tf.square(\n",
    "            self.model_estimator.output[:,:-1] - self.statesraw[:,1:]\n",
    "        ) * self.maskexpanded[:,:-1]\n",
    "        self.m_loss_raw = tf.reduce_mean(self.m_loss_ind)\n",
    "        \n",
    "        self.e_m_loss_ind = tf.square(\n",
    "            self.explorer_model_estimator.output[:,:-1] - self.statesraw[:,1:]\n",
    "        ) * self.maskexpanded[:,:-1]\n",
    "        \n",
    "        self.e_c_loss_ind = tf.square(\n",
    "            self.explorer_advantage_estimate[:,:-1] - self.advantage) * self.mask[:,:-1]\n",
    "        self.e_c_loss_raw = tf.reduce_mean(self.e_c_loss_ind) * 1e1\n",
    "        \n",
    "        self.e_l_loss = tf.reduce_mean(\n",
    "            tf.square(self.explorer_loss_estimator.output[:,:-1,0] - tf.reduce_mean(self.e_m_loss_ind, -1)) *\n",
    "            self.mask[:,:-1]\n",
    "        ) + tf.reduce_mean(\n",
    "            tf.square(\n",
    "                self.explorer_loss_estimator.output[:,:-1,1] - self.e_c_loss_ind\n",
    "            ) * self.mask[:,:-1]\n",
    "        )\n",
    "        \n",
    "        self.c_loss_ind = tf.square(\n",
    "            self.advantage_estimate[:,:-1] - self.advantage) * self.mask[:,:-1]\n",
    "        self.c_loss_raw = tf.reduce_mean(self.c_loss_ind) * 1e1\n",
    "        \n",
    "        self.l_loss = tf.reduce_mean(\n",
    "            tf.square(self.loss_estimator.output[:,:-1,0] - tf.reduce_mean(self.m_loss_ind, -1)) *\n",
    "            self.mask[:,:-1]\n",
    "        ) + tf.reduce_mean(\n",
    "            tf.square(\n",
    "                self.loss_estimator.output[:,:-1,1] - self.c_loss_ind\n",
    "            ) * self.mask[:,:-1]\n",
    "        )\n",
    "        \n",
    "        self.e_loss_critic = -tf.reduce_sum(\n",
    "            self.explorer_advantage_estimator.output * self.mask)/self.frac_not_masked\n",
    "        self.e_loss_loss = -self.l_loss * 10\n",
    "        \n",
    "        self.a_meanaction = tf.reduce_mean(\n",
    "            self.actions * self.maskexpanded, [0, 1])/self.frac_not_masked\n",
    "        self.a_meanactionloss = tf.reduce_mean(\n",
    "            tf.square(self.a_meanaction)\n",
    "        ) * 1e5 + tf.reduce_mean(\n",
    "            tf.square(tf.square(self.a_meanaction))\n",
    "        ) * 1e2 + tf.reduce_mean(\n",
    "            tf.abs(self.a_meanaction)\n",
    "        ) * 1e0\n",
    "        \n",
    "        self.e_meanaction = tf.reduce_mean(\n",
    "            self.explorer_actions * self.maskexpanded, [0, 1])/self.frac_not_masked\n",
    "        self.e_meanactionloss = tf.reduce_mean(\n",
    "            tf.square(self.e_meanaction)\n",
    "        ) * 1e5 + tf.reduce_mean(\n",
    "            tf.square(tf.square(self.e_meanaction))\n",
    "        ) * 1e2 + tf.reduce_mean(\n",
    "            tf.abs(self.e_meanaction)\n",
    "        ) * 1e0\n",
    "        \n",
    "        \n",
    "        self.a_mse = tf.reduce_mean((\n",
    "            tf.square(self.actor.raw_output) * 1e2 + tf.square(tf.square(self.actor.raw_output)) * 1.\n",
    "            ) * self.maskexpanded)/tf.reduce_mean(self.maskexpanded)\n",
    "        \n",
    "        \n",
    "        self.e_mse = tf.reduce_mean((\n",
    "            tf.square(self.explorer.raw_output) * 1e2 + tf.square(tf.square(self.explorer.raw_output)) * 1.\n",
    "            ) * self.maskexpanded)/tf.reduce_mean(self.maskexpanded)\n",
    "        \n",
    "        if 0:\n",
    "            optimizer = tf.train.RMSPropOptimizer\n",
    "            self.critic_opt = optimizer(self.lr, momentum= .8)\n",
    "            self.value_opt = optimizer(self.lr, momentum= .8)\n",
    "            self.actor_opt = optimizer(self.lr, momentum= .8)\n",
    "            self.model_opt = optimizer(self.lr, momentum= .8)\n",
    "            self.explorer_opt = optimizer(self.lr, momentum= .8)\n",
    "            self.loss_opt = optimizer(self.lr, momentum= .8)\n",
    "        else:\n",
    "            self.opt = tf.train.AdamOptimizer(self.lr, beta1= .8)\n",
    "        \n",
    "        \n",
    "        self.v_loss =  self.v_loss_raw + self.vreg\n",
    "        self.m_loss = self.m_loss_raw + self.mreg\n",
    "        self.c_loss =  self.c_loss_raw + self.creg\n",
    "        self.aregtotal = self.areg + self.a_mse + self.a_meanactionloss\n",
    "        self.a_loss_raw = self.a_loss_critic + self.a_loss_model\n",
    "        self.a_loss = self.a_loss_raw + self.aregtotal\n",
    "        self.e_loss = self.e_loss_critic - self.e_l_loss\n",
    "        self.l_loss_minimize = self.l_loss\n",
    "        self.e_loss_minimize = self.e_loss + \\\n",
    "            self.e_mse + self.ereg + self.e_meanactionloss\n",
    "        self.a_loss_minimize = self.a_loss\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.c_loss_minimize = self.c_loss + tf.reduce_mean(\n",
    "            tf.square(self.advantage_estimator.hidden_output[:,:,:-1] - tf.expand_dims(self.advantage, 0)\n",
    "                 )) * tf.expand_dims(self.mask[:,:-1], 0) * tf.reshape(\n",
    "            tf.range(N_LAYERS, dtype = tf.float32)/(N_LAYERS * 2) + .1, (-1, 1, 1))\n",
    "        \n",
    "        \n",
    "#         self.v_loss_ind = tf.square(\n",
    "#             self.returnsdecayed - self.state_value_estimate) * self.mask * self.is_exploit2d\n",
    "#         self.v_loss_raw = tf.reduce_mean(self.v_loss_ind) / tf.reduce_mean(\n",
    "#             self.mask * self.is_exploit2d) * 1e1\n",
    "        \n",
    "        \n",
    "        self.v_loss_minimize = self.v_loss + tf.reduce_mean(\n",
    "            tf.square(self.state_value_estimator.hidden_output - tf.expand_dims(self.returnsdecayed, 0)\n",
    "                 )) * tf.expand_dims(self.mask, 0) * tf.expand_dims(self.is_exploit2d, 0) * tf.reshape(\n",
    "            tf.range(N_LAYERS, dtype = tf.float32)/(N_LAYERS * 2) + .1, (-1, 1, 1))\n",
    "        \n",
    "        self.m_loss_minimize = self.m_loss + tf.reduce_mean(\n",
    "            tf.square(self.model_estimator.hidden_output[:,:,:-1] - tf.expand_dims(self.statesraw[:,1:], 0)\n",
    "                 )) * tf.expand_dims(self.maskexpanded[:,:-1], 0) * tf.reshape(\n",
    "            tf.range(N_LAYERS, dtype = tf.float32)/(N_LAYERS * 2) + .1, (-1, 1, 1, 1))\n",
    "        # + self.grad_norm_m + self.grad_m_1\n",
    "        \n",
    "        \n",
    "        self.v_obs_grad = tf.gradients(self.v_loss_minimize, self.statesraw)\n",
    "        self.c_obs_grad = tf.gradients(self.c_loss_minimize, self.critic_input)\n",
    "        self.m_obs_grad = tf.gradients(self.m_loss_minimize, self.critic_input)\n",
    "        self.a_obs_grad = tf.gradients(self.a_loss_minimize, self.obs)\n",
    "        self.e_obs_grad = tf.gradients(self.e_loss_minimize, self.obs)\n",
    "        self.l_obs_grad = tf.gradients(self.l_loss_minimize, self.loss_input)\n",
    "        \n",
    "        if TESTING_GRAD_NORMS:\n",
    "            self.a_grads = [\n",
    "                get_grad_norm(self.actor_opt, l) for l in [\n",
    "                self.a_loss_minimize, self.a_loss_raw, self.a_loss_critic,self.a_loss_model,\n",
    "                self.a_loss_secondaction,\n",
    "                self.areg, self.aregmeanbyaction, self.actstdpenalty, self.a_mse\n",
    "            ]]\n",
    "            self.v_grads = [get_grad_norm(self.value_opt, l) for l in [\n",
    "                self.v_loss_minimize, self.v_loss_raw, \n",
    "                self.vreg, self.grad_norm_v\n",
    "            ]]\n",
    "            self.c_grads = [get_grad_norm(self.critic_opt, l) for l in [\n",
    "                self.c_loss_minimize, self.c_loss_raw, \n",
    "                self.creg, self.grad_norm_c, self.grad_c_1\n",
    "\n",
    "            ]]\n",
    "            self.m_grads = [get_grad_norm(self.critic_opt, l) for l in [\n",
    "                self.m_loss_minimize, self.m_loss_raw, \n",
    "                self.mreg, self.grad_norm_m, self.grad_m_1\n",
    "            ]]\n",
    "        \n",
    "        self.copt, self.c_norm = apply_clipped_optimizer(\n",
    "            self.opt, self.c_loss_minimize, var_list = self.c_vars)\n",
    "        self.vopt, self.v_norm = apply_clipped_optimizer(\n",
    "            self.opt, self.v_loss_minimize, var_list = self.v_vars)\n",
    "        self.aopt, self.a_norm = apply_clipped_optimizer(\n",
    "            self.opt, self.a_loss_minimize, var_list = self.a_vars)\n",
    "        self.mopt, self.m_norm = apply_clipped_optimizer(\n",
    "            self.opt, self.m_loss_minimize, var_list = self.m_vars)\n",
    "        self.eopt, self.e_norm = apply_clipped_optimizer(\n",
    "            self.opt, self.e_loss_minimize, var_list = self.e_vars)\n",
    "        self.lopt, self.l_norm = apply_clipped_optimizer(\n",
    "            self.opt, self.l_loss_minimize, var_list = self.l_vars)\n",
    "\n",
    "    def load_weights(self):\n",
    "        feed_dict = {}\n",
    "        for (var, w), ph in zip(\n",
    "            self.assigns, self.weight_assignment_placeholders):\n",
    "            feed_dict[ph] = w\n",
    "        self.sess.run(self.weight_assignment_nodes, feed_dict=feed_dict)\n",
    "\n",
    "    def act(self, obs, exploit = True):\n",
    "        # Because we need batch dimension, \n",
    "        # data[None] changes shape from [A] to [1,A]\n",
    "        if exploit:\n",
    "            act = self.actions\n",
    "        else:\n",
    "            act = self.explorer_actions\n",
    "        a = self.sess.run(\n",
    "            act, feed_dict={\n",
    "                self.obs:(obs/shdiff) - shmin_g_e,\n",
    "                self.is_train:False\n",
    "            })\n",
    "        return a[0][0]  # return first in batch\n",
    "\n",
    "\n",
    "\n",
    "config = tf.ConfigProto(\n",
    "    inter_op_parallelism_threads=0,\n",
    "    intra_op_parallelism_threads=0,\n",
    "    device_count = { \"GPU\": 0 } )\n",
    "tf.reset_default_graph()\n",
    "\n",
    "pi = PolicyLearner(env.observation_space, env.action_space, config = config)\n",
    "\n",
    "sess = pi.sess\n",
    "self = pi\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()\n",
    "\n",
    "\n",
    "# env = gym.make(envname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING_GRAD_NORMS:\n",
    "    self.actor_current_mult = np.ones_like(self.actor_current_mult,dtype=np.float32)\n",
    "    self.critic_current_mult = np.ones_like(self.critic_current_mult,dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#         self.advantage = ((\n",
    "#             self.stateraw_value_estimate[:,1:] * GAMMA + self.returns) -\n",
    "#             self.state_value_estimate[:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ah, sh, shraw, rh, rdecayedh, maskh = [\n",
    "    np.zeros((0, 0, i)) for i in [N_ACT, INPUT_UNITS, N_OBS, 1, 1, 1]]\n",
    "isexploit = []\n",
    "globalframes = []\n",
    "localframes = []\n",
    "ep = 0\n",
    "trained = 0\n",
    "ongoing = 0\n",
    "exploit = 0\n",
    "printfreq = 20\n",
    "obj_fname = envname + str(PERCENT_CHOOSE_OPTIMAL) + 'saveobjs_unguided.pkl'\n",
    "tffile = \"tmp/\" + envname + str(PERCENT_CHOOSE_OPTIMAL) + \"unguided_trained.ckpt\"\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ongoing = 0\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feed_dict(batch_size, forced_hist, sample_flat):\n",
    "    num_hist = ah.shape[0]\n",
    "    if num_hist >  batch_size:\n",
    "        if sample_flat:\n",
    "            probability = np.ones(maskh.shape[0])\n",
    "        else:\n",
    "            probability = np.square(np.arange(maskh.shape[0])/1000 + .01)\n",
    "        if forced_hist:\n",
    "            probability = probability[:-forced_hist]\n",
    "        probability = np.square(probability)\n",
    "        probability = probability / probability.sum()\n",
    "        rnd = np.random.choice(\n",
    "                num_hist - forced_hist, batch_size - forced_hist, \n",
    "                replace=False, p=probability)\n",
    "        if forced_hist:\n",
    "            samples = np.concatenate((rnd,\n",
    "                np.arange( num_hist - forced_hist, num_hist)))\n",
    "        else:\n",
    "            samples=rnd\n",
    "    else:\n",
    "        samples = np.random.choice(num_hist, num_hist, replace=False)\n",
    "    actions, states, statesraw, returns, returnsdecayed, mask, exploit = [\n",
    "        v[samples] for v in [ah, sh, shraw, rh,rdecayedh, maskh, np.array(isexploit)]]\n",
    "    returns = (returns - vmin_g_e) / vdiff\n",
    "    statesrawactive = (statesraw- shrawmin_g_e) / shrawdiff\n",
    "    rd = (returnsdecayed - vmin_g_e) / vdiff\n",
    "    obs = (states - shmin_g_e)/shdiff\n",
    "\n",
    "    returnsmasked, rdmasked = [\n",
    "        v[mask.astype(bool)] for v in \n",
    "    [returns, rd]]\n",
    "\n",
    "    statesmasked, obsmasked = [\n",
    "        v[np.tile(np.expand_dims(mask, -1), [1,1,v.shape[-1]]).astype(bool)] for v in \n",
    "    [statesrawactive, obs]]\n",
    "\n",
    "    feed_dict={\n",
    "                self.returns:returns,\n",
    "                self.statesraw: statesrawactive,\n",
    "                self.returnsdecayed:rd,\n",
    "                self.lr: .0002,# / np.power(ep + 20, .4),\n",
    "                self.mask:mask,\n",
    "                self.obs: obs,\n",
    "                self.is_exploit:exploit,\n",
    "                self.actions:actions\n",
    "    }\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, opt, grad, loss, inpt, pi, name = ''):\n",
    "        self.opt = opt\n",
    "        self.grad = grad\n",
    "        self.loss = loss\n",
    "        self.inpt = inpt\n",
    "        self.steps = 0\n",
    "        self.loss_mean = [0]\n",
    "        self.loss_pre_mean = [0]\n",
    "        self.diff_loss_mean = [0]\n",
    "        self.name = name\n",
    "    def step(self, feed_dict):\n",
    "        if self.name in ['a', 'e']:\n",
    "            del feed_dict[pi.actions]\n",
    "        grad, loss_pre, inpt = sess.run([self.grad, self.loss, self.inpt], feed_dict)\n",
    "        n_grad = normalize_adv(grad[0], mag = 1., adv_type = 1)\n",
    "        feed_dict[self.inpt] = inpt + n_grad\n",
    "        _, loss = sess.run([self.opt, self.loss], feed_dict)\n",
    "        diff = loss - loss_pre\n",
    "        self.track_losses(loss, loss_pre, diff)\n",
    "        if self.steps % 10 == 9:\n",
    "            print(self.name, 'loss', np.mean(self.loss_mean).round(3), \n",
    "                  'loss_pre', np.mean(self.loss_pre_mean).round(3), \n",
    "                  'loss_diff', np.mean(self.diff_loss_mean).round(3))\n",
    "        self.steps += 1\n",
    "        return loss, loss_pre\n",
    "    def track_losses(self, loss, loss_pre, diff):\n",
    "        self.loss_mean.append(loss)\n",
    "        self.loss_pre_mean.append(loss_pre)\n",
    "        self.diff_loss_mean.append(diff)\n",
    "        self.loss_mean, self.loss_pre_mean, self.diff_loss_mean = [\n",
    "            v[-10:] for v in [self.loss_mean, self.loss_pre_mean, self.diff_loss_mean]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = Trainer(pi.mopt, pi.m_obs_grad, pi.m_loss, pi.critic_input, pi, name = 'm')\n",
    "critic_trainer = Trainer(pi.copt, pi.c_obs_grad, pi.c_loss, pi.critic_input, pi, name = 'c')\n",
    "loss_trainer = Trainer(pi.lopt, pi.l_obs_grad, pi.l_loss, pi.loss_input, pi, name = 'l')\n",
    "value_trainer = Trainer(pi.vopt, pi.v_obs_grad, pi.v_loss, pi.statesraw, pi, name = 'v')\n",
    "actor_trainer = Trainer(pi.aopt, pi.a_obs_grad, pi.a_loss, pi.obs, pi, name = 'a')\n",
    "explorer_trainer = Trainer(pi.eopt, pi.e_obs_grad, pi.e_loss_minimize, pi.obs, pi, name = 'e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(batch_size = None, forced_hist = 0, sample_flat = True, n_steps = None):\n",
    "    if n_steps is None:\n",
    "        n_steps = N_STEPS\n",
    "    if batch_size is None:\n",
    "        batch_size = BATCH_SIZE\n",
    "    for mdl in [model_trainer, value_trainer, critic_trainer, loss_trainer, actor_trainer, explorer_trainer]:\n",
    "        for _ in range(n_steps):\n",
    "            fd= get_feed_dict(batch_size, forced_hist, sample_flat)\n",
    "            mdl.step(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = 0\n",
    "ongoing = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained, ongoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if ongoing:\n",
    "    \n",
    "    save_path = saver.save(sess, tffile)\n",
    "    print('saved at epoch', ep)\n",
    "    with open(obj_fname,\"wb\") as f:\n",
    "        pickle.dump(\n",
    "            [ah, sh, shraw, rh, rdecayedh, maskh, ep, globalframes, isexploit,\n",
    "             shrawmin_g_e, shrawmax_g_e,shmin_g_e, shmax_g_e, vmin_g_e, vmax_g_e, shrawdiff, shdiff, vdiff\n",
    "\n",
    "            ], f)\n",
    "    trained = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# with open(obj_fname, \"rb\") as f:\n",
    "#     ah, sh, shraw, rh, rdecayedh, maskh, ep, globalframes, isexploit, \\\n",
    "#             shrawmin_g_e, shrawmax_g_e,shmin_g_e, shmax_g_e, vmin_g_e, \\\n",
    "#             vmax_g_e, shrawdiff, shdiff, vdiff = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEAVE_ALONE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score 86.71950931666713  frames 20\n",
      "saved at epoch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "m loss 0.186 loss_pre 0.177 loss_diff 0.009\n",
      "m loss 0.245 loss_pre 0.229 loss_diff 0.015\n",
      "m loss 0.161 loss_pre 0.15 loss_diff 0.011\n",
      "m loss 0.121 loss_pre 0.112 loss_diff 0.009\n",
      "m loss 0.102 loss_pre 0.095 loss_diff 0.007\n",
      "m loss 0.078 loss_pre 0.073 loss_diff 0.005\n",
      "m loss 0.069 loss_pre 0.065 loss_diff 0.004\n",
      "m loss 0.062 loss_pre 0.059 loss_diff 0.003\n",
      "m loss 0.051 loss_pre 0.048 loss_diff 0.003\n",
      "m loss 0.047 loss_pre 0.045 loss_diff 0.002\n",
      "v loss 2.485 loss_pre 1.773 loss_diff 0.712\n",
      "v loss 5.157 loss_pre 4.792 loss_diff 0.365\n",
      "v loss 4.491 loss_pre 4.087 loss_diff 0.404\n",
      "v loss 4.283 loss_pre 3.796 loss_diff 0.487\n",
      "v loss 3.228 loss_pre 2.738 loss_diff 0.491\n",
      "v loss 2.622 loss_pre 2.156 loss_diff 0.466\n",
      "v loss 2.405 loss_pre 1.962 loss_diff 0.443\n",
      "v loss 1.656 loss_pre 1.303 loss_diff 0.353\n",
      "v loss 1.806 loss_pre 1.48 loss_diff 0.326\n",
      "v loss 1.787 loss_pre 1.494 loss_diff 0.293\n",
      "c loss 42.872 loss_pre 32.57 loss_diff 10.303\n",
      "c loss 498.824 loss_pre 461.099 loss_diff 37.725\n",
      "c loss 133.895 loss_pre 117.913 loss_diff 15.982\n",
      "c loss 88.572 loss_pre 77.002 loss_diff 11.57\n",
      "c loss 63.255 loss_pre 54.673 loss_diff 8.582\n",
      "c loss 38.883 loss_pre 32.854 loss_diff 6.03\n",
      "c loss 34.274 loss_pre 29.211 loss_diff 5.063\n",
      "c loss 32.363 loss_pre 27.848 loss_diff 4.515\n",
      "c loss 23.721 loss_pre 20.17 loss_diff 3.551\n",
      "c loss 22.075 loss_pre 18.837 loss_diff 3.237\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not LEAVE_ALONE:\n",
    "    [[shrawmin_g, shrawmax_g],\n",
    "        [shmin_g, shmax_g],\n",
    "        [vmin_g, vmax_g]] = [[\n",
    "        np.ones(i) * 1000, np.zeros(i) * -1000] for i in [N_OBS, N_STATE * N_HISTORY, 1]]\n",
    "    if trained:\n",
    "        try:\n",
    "            saver.restore(sess, tffile)\n",
    "            with open(obj_fname, \"rb\") as f:\n",
    "                ah, sh, shraw, rh, rdecayedh, maskh, ep, globalframes, isexploit, \\\n",
    "                    shrawmin_g_e, shrawmax_g_e,shmin_g_e, shmax_g_e, vmin_g_e, \\\n",
    "                    vmax_g_e, shrawdiff, shdiff, vdiff = pickle.load(f)\n",
    "            print('restored from save file')\n",
    "            reinit = 1\n",
    "        except:\n",
    "            print('no save file detected')\n",
    "            trained = 0\n",
    "            reinit = 0\n",
    "    else:\n",
    "\n",
    "        reinit = 0\n",
    "        [[shrawmin_g, shrawmax_g],\n",
    "            [shmin_g, shmax_g],\n",
    "            [vmin_g, vmax_g]] = [[\n",
    "            np.ones(i) * 1000, np.zeros(i) * -1000] for i in [N_OBS, N_STATE * N_HISTORY, 1]]\n",
    "MAX_SEQ_LEN = 5000\n",
    "for ep in range(ep, 10000000):\n",
    "    if ep % 100 == 0 and trained and ep > 0:\n",
    "        save_path = saver.save(sess, tffile)\n",
    "        print('saved at epoch', ep)\n",
    "        with open(obj_fname,\"wb\") as f:\n",
    "            pickle.dump(\n",
    "                [ah[-NUM_KEEP:], sh[-NUM_KEEP:], shraw[-NUM_KEEP:],\n",
    "                 rh[-NUM_KEEP:], rdecayedh[-NUM_KEEP:], maskh[-NUM_KEEP:], ep, globalframes, isexploit[-NUM_KEEP:], \n",
    "                shrawmin_g_e, shrawmax_g_e,shmin_g_e, shmax_g_e, vmin_g_e, \n",
    "                vmax_g_e, shrawdiff, shdiff, vdiff\n",
    "                ], f)\n",
    "    if ep < 10000 and ep > 1:\n",
    "        reinit = 0\n",
    "        shrawmin, shrawmax = make_maxmin(shraw)\n",
    "        shmin, shmax = make_maxmin(sh)\n",
    "        vmin, vmax = make_maxmin(rdecayedh)\n",
    "        shrawmin_g, shmin_g, vmin_g = [\n",
    "            np.minimum(g, n) for g, n in zip(\n",
    "                [shrawmin_g, shmin_g, vmin_g], [shrawmin, shmin, vmin])]\n",
    "        shrawmax_g, shmax_g, vmax_g = [\n",
    "            np.maximum(g, n) for g, n in zip(\n",
    "                [shrawmax_g, shmax_g, vmax_g], [shrawmax, shmax, vmax])]\n",
    "\n",
    "        [shrawmin_g_e, shrawmax_g_e,shmin_g_e, shmax_g_e] = [\n",
    "            np.reshape(v, (1, 1, -1)) for v in [shrawmin_g, shrawmax_g,shmin_g, shmax_g]]\n",
    "        vmin_g_e, vmax_g_e = [np.reshape(v, (1, 1)) for v in [vmin_g, vmax_g]]\n",
    "\n",
    "        shrawdiff = shrawmax_g_e - shrawmin_g_e\n",
    "        shdiff = shmax_g_e - shmin_g_e\n",
    "        vdiff = vmax_g_e - vmin_g_e\n",
    "    trained = 1\n",
    "    ongoing = 1\n",
    "    \n",
    "    an, sn, snraw, rn, rdecayedn, maskn = [\n",
    "        np.zeros((0, i)) for i in [N_ACT, INPUT_UNITS, N_OBS, 1, 1, 1]]\n",
    "    frame = 0\n",
    "    score = 0\n",
    "    restart_delay = 5\n",
    "    obs = env.reset()\n",
    "    obsraw = obs\n",
    "    snraw = np.concatenate((snraw, obs.reshape(1, -1)), 0)\n",
    "    obs = np.concatenate((obs, np.zeros(N_ACT)))\n",
    "    obs = np.concatenate((obs, np.zeros_like(obs)))\n",
    "    obs_mat = np.concatenate((\n",
    "        obs[None,:],np.zeros((NUM_HISTORY-1, N_STATE))), 0)\n",
    "    rn = [0]\n",
    "    done_ctr = 0\n",
    "    sn = np.concatenate((sn, obs_mat.reshape(1, -1)), 0)\n",
    "    step_num = 0\n",
    "    step_shifted = -1\n",
    "    show_shift = 0\n",
    "    if exploit or ep < 5:\n",
    "        exploit = 0\n",
    "    else:\n",
    "        exploit = 1\n",
    "        if np.random.rand() > .5:\n",
    "            exploit = 0\n",
    "    while 1:\n",
    "        step_num += 1\n",
    "        if ep < 5:\n",
    "            a = np.random.randn(N_ACT) * .1\n",
    "        else:\n",
    "            if exploit:\n",
    "                a = pi.act(obs_mat.flatten(), exploit = exploit)\n",
    "            else:\n",
    "                if np.random.rand() < .4:\n",
    "                    a = pi.act(obs_mat.flatten(), exploit = exploit)\n",
    "                elif np.random.rand() < .6:\n",
    "                    a = pi.act(obs_mat.flatten(), exploit = 1)\n",
    "                else:\n",
    "                    a = np.random.randn(N_ACT) * 1.\n",
    "        an = np.concatenate((an, a[None,:]), 0)\n",
    "        snraw = np.concatenate((snraw, obsraw[None,:]), 0)\n",
    "        last_obs = obs\n",
    "        obs, r, done, _ = env.step(a)\n",
    "        obsraw = obs\n",
    "        r = r + 1 * REWARD_MULT\n",
    "\n",
    "        obs_mat = accumulate_state(\n",
    "            obs, a, obs_mat, STATE_DECAY, style = 'np')\n",
    "        \n",
    "        rn.append(r)\n",
    "        sn = np.concatenate((sn, obs_mat.reshape(1, -1)), 0)\n",
    "        score += r\n",
    "        frame += 1\n",
    "        if ep > INIT_LEN:\n",
    "            still_open = env.render(\"human\")\n",
    "        else:\n",
    "            still_open = 1\n",
    "        if done:\n",
    "            done_ctr += 1\n",
    "            if done_ctr > 3:\n",
    "                if ep % MAX_SEQ_LEN == 0:\n",
    "                    print('score', score, ' frames', frame)\n",
    "                break\n",
    "        if still_open==False:\n",
    "            crashhere\n",
    "        if not done: continue\n",
    "        if restart_delay==0:\n",
    "            print(\"score=%0.2f in %i frames\" % (score, frame))\n",
    "            if still_open!=True:      # not True in multiplayer or non-Roboschool \n",
    "                break\n",
    "            restart_delay = 2000*2  # 2 sec at 60 fps\n",
    "        restart_delay -= 1\n",
    "        if restart_delay==0: \n",
    "            break\n",
    "    if ep < INIT_LEN:\n",
    "        a = np.random.randn(N_ACT)\n",
    "    else:\n",
    "        a = pi.act(obs_mat.flatten())\n",
    "    an = np.concatenate((an, a[None,:]), 0)\n",
    "    localframes.append(frame)\n",
    "    rn = np.array(rn)\n",
    "    rn[-1] = rn[-1] - 20 * REWARD_MULT\n",
    "    rn[-2] = rn[-2] - 10 * REWARD_MULT\n",
    "    rn[-3] = rn[-3] - 5 * REWARD_MULT\n",
    "    rewards = [0]\n",
    "    for ir in rn[::-1]:\n",
    "        rewards.append(rewards[-1] * GAMMA + ir)\n",
    "    rdecayedn = np.array(rewards)[:0:-1]\n",
    "    lenrdec = len(rdecayedn)\n",
    "#     rdecayedn = rdecayedn + lenrdec\n",
    "#     rdecayedn = rdecayedn - np.arange(lenrdec) * 1.8\n",
    "    maskn = np.ones_like(rn)\n",
    "    if step_shifted > -1:\n",
    "        if step_shifted == 0:\n",
    "            raise ValueError('step shifted not allowed 0')\n",
    "        maskn[:step_shifted - 1] = 0\n",
    "    if ep == 0:\n",
    "        ah, sh, shraw, rh, rdecayedh, maskh = [\n",
    "            np.expand_dims(v, 0) for v in [an, sn, snraw, rn,rdecayedn, maskn]]\n",
    "        isexploit = [exploit]\n",
    "    else:\n",
    "        def get_updated_h(h, n, third_dim):\n",
    "            hshape = h.shape[1]\n",
    "            nshape = n.shape[0]\n",
    "            if third_dim:\n",
    "                if hshape > nshape:\n",
    "                    n = np.concatenate((n, np.zeros((hshape - nshape, n.shape[-1]))), 0)\n",
    "                if nshape > hshape:\n",
    "                    h = np.concatenate((h, np.zeros((\n",
    "                        h.shape[0], nshape - hshape, h.shape[-1]))), 1)\n",
    "            else:\n",
    "                if hshape > nshape:\n",
    "                    n = np.concatenate((n, np.zeros((hshape - nshape))), 0)\n",
    "                if nshape > hshape:\n",
    "                    h = np.concatenate((h, np.zeros((h.shape[0], nshape - hshape))), 1)\n",
    "            h = np.concatenate((h, np.expand_dims(n, 0)), 0)\n",
    "            return h\n",
    "            \n",
    "        ah, sh, shraw = [get_updated_h(h, n, 1) for  h, n in zip(\n",
    "            [ah, sh, shraw], [an, sn, snraw])]\n",
    "        \n",
    "        rh, rdecayedh, maskh = [\n",
    "            get_updated_h(h, n, 0) for h, n in zip(\n",
    "                [rh, rdecayedh, maskh], [rn, rdecayedn, maskn])]\n",
    "        isexploit.append(exploit)\n",
    "    if ep % 1 == 0 and ep > INIT_LEN:\n",
    "        ah, sh, shraw, rh,rdecayedh, maskh, isexploit = [\n",
    "            v[-NUM_KEEP:] for v in [ah, sh, shraw, rh,rdecayedh, maskh, isexploit]]\n",
    "        globalframes.append(np.mean(localframes))\n",
    "        localframes = []\n",
    "        batch_size = BATCH_SIZE\n",
    "        if ep < batch_size:\n",
    "            batch_size = ep\n",
    "        num_hist = ah.shape[0]\n",
    "    if ep % N_EPISODES == 0 and ep > 0:\n",
    "        print(np.mean(globalframes[-100:]))\n",
    "        train_all()\n",
    "        ysmoothed = gaussian_filter1d(globalframes, sigma=4)\n",
    "        plt.plot(ysmoothed)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N_EPISODES = 4\n",
    "N_STEPS = 1000\n",
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.model_estimator.hidden_output[:,:-1], feed_dict).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(\n",
    "            tf.square(self.model_estimator.hidden_output[:,:-1] - tf.expand_dims(self.statesraw[:,1:], -1)\n",
    "                 )) * tf.expand_dims(self.maskexpanded[:,:-1], -1) * tf.reshape(\n",
    "            tf.range(N_LAYERS, dtype = tf.float32)/(N_LAYERS * 2) + .1, (1, 1, 1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 1002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = train(actor = True, value = True, n_steps = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feed_dict[self.obs][:,:7,:].min(0).min(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.critic_input[:,:7,0], feed_dict).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ah[-11::2,5:10].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isexploit[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.loss_estimator.h[0], feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.gradients(self.loss_estimator.output, self.loss_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        self.l_loss = tf.reduce_mean(\n",
    "            tf.square(self.loss_estimator.output[:,:-1,0] - tf.reduce_mean(self.m_loss_ind, -1)) * self.mask[:,:-1]\n",
    "        ) + tf.reduce_mean(\n",
    "            tf.square(\n",
    "                self.loss_estimator.output[:,:-1,1] - self.c_loss_ind\n",
    "            ) * self.mask[:,:-1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.reduce_mean(\n",
    "            tf.square(self.loss_estimator.output[:,:-1,0] - tf.reduce_mean(self.m_loss_ind, -1)) * self.mask[:,:-1]\n",
    "        ) + tf.reduce_mean(\n",
    "            tf.square(\n",
    "                self.loss_estimator.output[:,:-1,1] - self.c_loss_ind\n",
    "            ) * self.mask[:,:-1]\n",
    "        ), feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.reduce_mean(self.c_loss_ind, -1), feed_dict).shape\n",
    "        self.l_loss = tf.reduce_mean(\n",
    "            tf.square(self.loss_estimator.output[:,:-1,0] - tf.reduce_mean(self.m_loss_ind, -1)) * self.mask[:,:-1]\n",
    "        ) + tf.reduce_mean(\n",
    "            tf.square(\n",
    "                self.loss_estimator.output[:,:-1,1] - self.c_loss_ind\n",
    "            ) * self.mask[:,:-1]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mvars2 = sess.run(self.m_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m1, m2 in zip(mvars, mvars2):\n",
    "    print(np.square(m1 - m2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STATE * N_HISTORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.m_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.model_estimate, feed_dict)[0,:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.statesraw[:,1:], feed_dict)[0,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.critic_input, feed_dict)[:,5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict[self.lr] = .01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = get_feed_dict(4, 0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _ in range(100):\n",
    "    print(sess.run([self.mopt, self.m_loss], feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.statesraw[:,1:], feed_dict)[:,:10, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_adv(sess.run(self.m_obs_grad, feed_dict), adv_type = 1)[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.model_estimate, feed_dict)[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_ACT + N_OBS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskh.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.critic_input, feed_dict)[:,:7][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.model_estimate, feed_dict)[2,5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sess.run(self.statesraw[:,1:], feed_dict)[2,5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.model_estimate, feed_dict)[2,5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(self.actions, feed_dict)[:,5:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict[self.lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict[self.lr]# = .0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(200):\n",
    "    print(sess.run([self.mopt, self.m_loss], feed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = 560"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(30):\n",
    "    train(actor = True, value = True, n_steps = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
